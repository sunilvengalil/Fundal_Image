{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scikit learn\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"mask/\"\n",
    "path = os.listdir(directory)\n",
    "\n",
    "for i in path:\n",
    "    \n",
    "    img = cv2.imread(\"mask/\" + i)\n",
    "    cv2.imwrite(\"new_mask/\" + i[:-4] + '.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir1 = \"new_mask/\"\n",
    "\n",
    "dir2 = \"results1/\"\n",
    "\n",
    "path = os.listdir(dir1)\n",
    "\n",
    "path_list = []\n",
    "    \n",
    "for i in path:\n",
    "    \n",
    "    path_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 20\n",
      "new_mask/01_test.png | results1/01_test.png\n",
      "new_mask/02_test.png | results1/02_test.png\n",
      "new_mask/03_test.png | results1/03_test.png\n",
      "new_mask/04_test.png | results1/04_test.png\n",
      "new_mask/05_test.png | results1/05_test.png\n",
      "new_mask/06_test.png | results1/06_test.png\n",
      "new_mask/07_test.png | results1/07_test.png\n",
      "new_mask/08_test.png | results1/08_test.png\n",
      "new_mask/09_test.png | results1/09_test.png\n",
      "new_mask/10_test.png | results1/10_test.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "input_dir = dir1\n",
    "target_dir = dir2\n",
    "img_size = (512, 512)\n",
    "num_classes = 2\n",
    "batch_size = 4\n",
    "\n",
    "input_img_paths = sorted(\n",
    "    [\n",
    "        os.path.join(input_dir, fname)\n",
    "        for fname in os.listdir(input_dir)\n",
    "        if fname.endswith(\".png\")\n",
    "    ]\n",
    ")\n",
    "target_img_paths = sorted(\n",
    "    [\n",
    "        os.path.join(target_dir, fname)\n",
    "        for fname in os.listdir(target_dir)\n",
    "        if fname.endswith(\".png\") and not fname.startswith(\".\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Number of samples:\", len(input_img_paths))\n",
    "\n",
    "for input_path, target_path in zip(input_img_paths[:10], target_img_paths[:10]):\n",
    "    print(input_path, \"|\", target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(512, 512)\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# load the image and convert into numpy array\n",
    "\n",
    "img1 = Image.open(dir1 + \"01_test.png\")\n",
    "img2 = Image.open(dir2 + \"01_test.png\")\n",
    "  \n",
    "# asarray() class is used to convert\n",
    "# PIL images into NumPy arrays\n",
    "numpy_data1 = np.asarray(img1)\n",
    "numpy_data2 = np.asarray(img2)\n",
    "\n",
    "# Consider only the first two channels\n",
    "numpy_data1 = numpy_data1[:,:,0] # Discard the last channel \n",
    "numpy_data2 = numpy_data2[:,:,0] # Discard the last channel \n",
    "\n",
    "# Alternative\n",
    "# numpy_data1 = numpy_data1[:,:,0] and then numpy_data1 = numpy_data1[:,:,1]\n",
    "  \n",
    "# <class 'numpy.ndarray'>\n",
    "print(type(numpy_data1))\n",
    "  \n",
    "#  shape\n",
    "print(numpy_data1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 512, 512)\n",
      "(20, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "data1 = []\n",
    "data2 = []\n",
    "\n",
    "for i in range(20):\n",
    "    img1 = Image.open(dir1 + path_list[i])\n",
    "    img2 = Image.open(dir2 + path_list[i])\n",
    "    \n",
    "    np_data1 = np.asarray(img1)\n",
    "    np_data2 = np.asarray(img2)\n",
    "    \n",
    "    # Consider only the first two channels\n",
    "    np_data1 = np_data1[:,:,0] # Discard the last channel \n",
    "    np_data2 = np_data2[:,:,0] # Discard the last channel \n",
    "    \n",
    "    data1.append(np_data1)\n",
    "    data2.append(np_data2)\n",
    "    \n",
    "data1 = np.array(data1)\n",
    "data2 = np.array(data2)\n",
    "\n",
    "print(data1.shape)\n",
    "print(data2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(np.array_equal(numpy_data1, numpy_data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(np.array_equiv(numpy_data1, numpy_data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_shape = numpy_data1.shape[0]*numpy_data1.shape[1]\n",
    "\n",
    "a = np.reshape(numpy_data1, final_shape)\n",
    "b = np.reshape(numpy_data2, final_shape)\n",
    "\n",
    "y_score = np.empty((a.shape[0]))\n",
    "\n",
    "for i in range(a.shape[0]):\n",
    "    if a[i] == b[i]:\n",
    "        y_score[i] = 1\n",
    "    else:\n",
    "        y_score[i] = 0\n",
    "        \n",
    "y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_value = 0.5\n",
    "y_true = np.empty((a.shape[0]))\n",
    "\n",
    "for i in range(a.shape[0]):\n",
    "    if np.float32(int(a[i]))/255.0 > 0.5:\n",
    "        y_true[i] = 0\n",
    "    else:\n",
    "        y_true[i] = 1\n",
    "        \n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Confusion Matrix = \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[     0,      0],\n",
       "       [ 62069, 200075]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The Confusion Matrix = \")\n",
    "confusion_matrix(y_true, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(y_true, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 0.7632255554199219\n",
      "Precision: 1.0\n",
      "\n",
      "F1 score (F-measure): 0.8657151696490192\n"
     ]
    }
   ],
   "source": [
    "# confusion = confusion_matrix(y_true, y_score)\n",
    "\n",
    "specificity = 0\n",
    "if float(confusion[0,0]+confusion[0,1])!=0:\n",
    "    specificity = float(confusion[0,0])/float(confusion[0,0]+confusion[0,1])\n",
    "# print(\"Specificity: \" +str(specificity))\n",
    "\n",
    "sensitivity = 0\n",
    "if float(confusion[1,1]+confusion[1,0])!=0:\n",
    "    sensitivity = float(confusion[1,1])/float(confusion[1,1]+confusion[1,0])\n",
    "print(\"Sensitivity: \" +str(sensitivity))\n",
    "\n",
    "precision = 0\n",
    "if float(confusion[1,1]+confusion[0,1])!=0:\n",
    "    precision = float(confusion[1,1])/float(confusion[1,1]+confusion[0,1])\n",
    "    \n",
    "print(\"Precision: \" +str(precision))\n",
    "\n",
    "# F1 score\n",
    "F1_score = f1_score(y_true, y_score, labels=None, average='binary', sample_weight=None)\n",
    "print(\"\\nF1 score (F-measure): \" +str(F1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute The IoU Scores:\n",
    "\n",
    "intersection_values = 0\n",
    "union_values = 0\n",
    "\n",
    "for i, j in zip(y_true, y_score):\n",
    "    if i and j == 1:\n",
    "        intersection_values += 1\n",
    "        \n",
    "for i, j in zip(y_true, y_score):\n",
    "    if i or j == 1:\n",
    "        union_values += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The IoU Score for the single image =  0.76322556\n"
     ]
    }
   ],
   "source": [
    "print(\"The IoU Score for the single image = \", np.float32(intersection_values/union_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Blocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns = ['Recall', 'Precision', 'Accuracy', 'F1-Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Image1\n",
      "Sensitivity: 0.7632255554199219\n",
      "Precision: 1.0\n",
      "Accuracy: 0.7632255554199219\n",
      "F1 score (F-measure): 0.8657151696490192\n",
      "\n",
      " Image2\n",
      "Sensitivity: 0.7551689147949219\n",
      "Precision: 1.0\n",
      "Accuracy: 0.7551689147949219\n",
      "F1 score (F-measure): 0.8605085338845094\n",
      "\n",
      " Image3\n",
      "Sensitivity: 0.7672080993652344\n",
      "Precision: 1.0\n",
      "Accuracy: 0.7672080993652344\n",
      "F1 score (F-measure): 0.8682713706900832\n",
      "\n",
      " Image4\n",
      "Sensitivity: 0.7722740173339844\n",
      "Precision: 1.0\n",
      "Accuracy: 0.7722740173339844\n",
      "F1 score (F-measure): 0.8715063356802004\n",
      "\n",
      " Image5\n",
      "Sensitivity: 0.7597885131835938\n",
      "Precision: 1.0\n",
      "Accuracy: 0.7597885131835938\n",
      "F1 score (F-measure): 0.8634997984037042\n",
      "\n",
      " Image6\n",
      "Sensitivity: 0.7586936950683594\n",
      "Precision: 1.0\n",
      "Accuracy: 0.7586936950683594\n",
      "F1 score (F-measure): 0.8627923068080021\n",
      "\n",
      " Image7\n",
      "Sensitivity: 0.7643318176269531\n",
      "Precision: 1.0\n",
      "Accuracy: 0.7643318176269531\n",
      "F1 score (F-measure): 0.8664263830541676\n",
      "\n",
      " Image8\n",
      "Sensitivity: 0.7823066711425781\n",
      "Precision: 1.0\n",
      "Accuracy: 0.7823066711425781\n",
      "F1 score (F-measure): 0.8778586578942299\n",
      "\n",
      " Image9\n",
      "Sensitivity: 0.7741165161132812\n",
      "Precision: 1.0\n",
      "Accuracy: 0.7741165161132812\n",
      "F1 score (F-measure): 0.8726783264598752\n",
      "\n",
      " Image10\n",
      "Sensitivity: 0.7757301330566406\n",
      "Precision: 1.0\n",
      "Accuracy: 0.7757301330566406\n",
      "F1 score (F-measure): 0.8737027306298429\n",
      "\n",
      " Image11\n",
      "Sensitivity: 0.7518119812011719\n",
      "Precision: 1.0\n",
      "Accuracy: 0.7518119812011719\n",
      "F1 score (F-measure): 0.8583249678263691\n",
      "\n",
      " Image12\n",
      "Sensitivity: 0.7735366821289062\n",
      "Precision: 1.0\n",
      "Accuracy: 0.7735366821289062\n",
      "F1 score (F-measure): 0.8723097637883344\n",
      "\n",
      " Image13\n",
      "Sensitivity: 0.7507553100585938\n",
      "Precision: 1.0\n",
      "Accuracy: 0.7507553100585938\n",
      "F1 score (F-measure): 0.857635908050986\n",
      "\n",
      " Image14\n",
      "Sensitivity: 0.7723846435546875\n",
      "Precision: 1.0\n",
      "Accuracy: 0.7723846435546875\n",
      "F1 score (F-measure): 0.871576772416168\n",
      "\n",
      " Image15\n",
      "Sensitivity: 0.7946662902832031\n",
      "Precision: 1.0\n",
      "Accuracy: 0.7946662902832031\n",
      "F1 score (F-measure): 0.8855866905014443\n",
      "\n",
      " Image16\n",
      "Sensitivity: 0.7681846618652344\n",
      "Precision: 1.0\n",
      "Accuracy: 0.7681846618652344\n",
      "F1 score (F-measure): 0.868896420642951\n",
      "\n",
      " Image17\n",
      "Sensitivity: 0.7774124145507812\n",
      "Precision: 1.0\n",
      "Accuracy: 0.7774124145507812\n",
      "F1 score (F-measure): 0.8747687460563423\n",
      "\n",
      " Image18\n",
      "Sensitivity: 0.7866363525390625\n",
      "Precision: 1.0\n",
      "Accuracy: 0.7866363525390625\n",
      "F1 score (F-measure): 0.8805780218466295\n",
      "\n",
      " Image19\n",
      "Sensitivity: 0.7763290405273438\n",
      "Precision: 1.0\n",
      "Accuracy: 0.7763290405273438\n",
      "F1 score (F-measure): 0.8740824732526726\n",
      "\n",
      " Image20\n",
      "Sensitivity: 0.8030662536621094\n",
      "Precision: 1.0\n",
      "Accuracy: 0.8030662536621094\n",
      "F1 score (F-measure): 0.8907784192966236\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for i, j in zip(os.listdir(dir1), os.listdir(dir2)):\n",
    "    \n",
    "    append_list = []\n",
    "    \n",
    "    img1 = Image.open(dir1 + i)\n",
    "    img2 = Image.open(dir2 + j)\n",
    "\n",
    "    numpy_data1 = np.asarray(img1)\n",
    "    numpy_data2 = np.asarray(img2)\n",
    "#     print(numpy_data1.shape)\n",
    "    \n",
    "    # Consider only the first two channels\n",
    "    numpy_data1 = numpy_data1[:,:,0] # Discard the last channel \n",
    "    numpy_data2 = numpy_data2[:,:,0] # Discard the last channel \n",
    "#     print(numpy_data1.shape)\n",
    "    \n",
    "    final_shape = numpy_data1.shape[0]*numpy_data1.shape[1]\n",
    "#     print(final_shape)\n",
    "\n",
    "    a = np.reshape(numpy_data1, final_shape)\n",
    "    b = np.reshape(numpy_data2, final_shape)\n",
    "\n",
    "    y_score = np.empty((a.shape[0]))\n",
    "\n",
    "    for i in range(a.shape[0]):\n",
    "        if a[i] == b[i]:\n",
    "            y_score[i] = 1\n",
    "        else:\n",
    "            y_score[i] = 0\n",
    "\n",
    "    threshold_value = 0.5\n",
    "    y_true = np.empty((a.shape[0]))\n",
    "\n",
    "    for i in range(a.shape[0]):\n",
    "        if np.float32(int(a[i])-int(b[i]))/255.0 > 0.5:\n",
    "            y_true[i] = 0\n",
    "        else:\n",
    "            y_true[i] = 1\n",
    "            \n",
    "    count += 1\n",
    "    \n",
    "    print(f\"\\n Image{count}\")\n",
    "            \n",
    "#     print(\"The Confusion Matrix = \")\n",
    "#     print(confusion_matrix(y_true, y_score))\n",
    "    \n",
    "    confusion = confusion_matrix(y_true, y_score)\n",
    "    \n",
    "    # confusion = confusion_matrix(y_true, y_score)\n",
    "\n",
    "    specificity = 0\n",
    "    if float(confusion[0,0]+confusion[0,1])!=0:\n",
    "        specificity = float(confusion[0,0])/float(confusion[0,0]+confusion[0,1])\n",
    "#     print(\"Specificity: \" +str(specificity))\n",
    "\n",
    "    sensitivity = 0\n",
    "    if float(confusion[1,1]+confusion[1,0])!=0:\n",
    "        sensitivity = float(confusion[1,1])/float(confusion[1,1]+confusion[1,0])\n",
    "    print(\"Sensitivity: \" +str(sensitivity))\n",
    "    append_list.append(sensitivity)\n",
    "    \n",
    "    precision = 0\n",
    "    if float(confusion[1,1]+confusion[0,1])!=0:\n",
    "        precision = float(confusion[1,1])/float(confusion[1,1]+confusion[0,1])\n",
    "\n",
    "    print(\"Precision: \" +str(precision))\n",
    "    append_list.append(precision)\n",
    "    \n",
    "    # Accuracy\n",
    "    \n",
    "    accuracy = 0\n",
    "\n",
    "    accuracy = float(confusion[0,0]+confusion[1,1])/float(confusion[0,0]+confusion[0,1]+confusion[1,0]+confusion[1,1])\n",
    "    print(\"Accuracy: \" +str(accuracy))\n",
    "    append_list.append(accuracy)\n",
    "\n",
    "    # F1 score\n",
    "    F1_score = f1_score(y_true, y_score, labels=None, average='binary', sample_weight=None)\n",
    "    print(\"F1 score (F-measure): \" +str(F1_score))\n",
    "    append_list.append(F1_score)\n",
    "    \n",
    "    df.loc[len(df)] = append_list\n",
    "        \n",
    "#     if count == 10:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('values-0.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLOBAL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_shape = data1.shape[0]*data1.shape[1]*data1.shape[2]\n",
    "\n",
    "c = np.reshape(data1, final_shape)\n",
    "d = np.reshape(data2, final_shape)\n",
    "\n",
    "y_score_all = np.empty((c.shape[0]))\n",
    "\n",
    "for i in range(c.shape[0]):\n",
    "    if c[i] == d[i]:\n",
    "        y_score_all[i] = 1\n",
    "    else:\n",
    "        y_score_all[i] = 0\n",
    "        \n",
    "y_score_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_value = 0.5\n",
    "y_true_all = np.empty((c.shape[0]))\n",
    "\n",
    "for i in range(c.shape[0]):\n",
    "    if np.float32(int(c[i]))/255.0 > 0.5:\n",
    "        y_true_all[i] = 0\n",
    "    else:\n",
    "        y_true_all[i] = 1\n",
    "        \n",
    "y_true_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Global Confusion Matrix = \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[      0,       0],\n",
       "       [1198620, 4044260]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The Global Confusion Matrix = \")\n",
    "confusion_matrix(y_true_all, y_score_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(y_true_all, y_score_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 0.7713813781738281\n",
      "Precision: 1.0\n",
      "\n",
      "F1 score (F-measure): 0.8907784192966236\n"
     ]
    }
   ],
   "source": [
    "# confusion = confusion_matrix(y_true, y_score)\n",
    "\n",
    "specificity = 0\n",
    "if float(confusion[0,0]+confusion[0,1])!=0:\n",
    "    specificity = float(confusion[0,0])/float(confusion[0,0]+confusion[0,1])\n",
    "# print(\"Specificity: \" +str(specificity))\n",
    "\n",
    "sensitivity = 0\n",
    "if float(confusion[1,1]+confusion[1,0])!=0:\n",
    "    sensitivity = float(confusion[1,1])/float(confusion[1,1]+confusion[1,0])\n",
    "print(\"Sensitivity: \" +str(sensitivity))\n",
    "\n",
    "precision = 0\n",
    "if float(confusion[1,1]+confusion[0,1])!=0:\n",
    "    precision = float(confusion[1,1])/float(confusion[1,1]+confusion[0,1])\n",
    "    \n",
    "print(\"Precision: \" +str(precision))\n",
    "\n",
    "# F1 score\n",
    "F1_score = f1_score(y_true, y_score, labels=None, average='binary', sample_weight=None)\n",
    "print(\"\\nF1 score (F-measure): \" +str(F1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7713813781738281\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "\n",
    "accuracy = float(confusion[1,1]+confusion[0,0])/float(confusion[0,0]+confusion[0,1]+confusion[1,0]+confusion[1,1])\n",
    "print(\"Accuracy: \" +str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The IoU Score for the images =  0.7713814\n"
     ]
    }
   ],
   "source": [
    "# Compute The IoU Scores:\n",
    "\n",
    "intersection_values = 0\n",
    "union_values = 0\n",
    "\n",
    "for i, j in zip(y_true_all, y_score_all):\n",
    "    if i and j == 1:\n",
    "        intersection_values += 1\n",
    "        \n",
    "for i, j in zip(y_true_all, y_score_all):\n",
    "    if i or j == 1:\n",
    "        union_values += 1\n",
    "        \n",
    "print(\"The IoU Score for the images = \", np.float32(intersection_values/union_values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
