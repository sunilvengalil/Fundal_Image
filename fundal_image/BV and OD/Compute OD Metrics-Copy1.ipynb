{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scikit learn\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"mask/\"\n",
    "path = os.listdir(directory)\n",
    "\n",
    "for i in path:\n",
    "    \n",
    "    img = cv2.imread(\"mask/\" + i)\n",
    "    cv2.imwrite(\"new_mask/\" + i[:-4] + '.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir1 = \"new_mask/\"\n",
    "\n",
    "dir2 = \"results1/\"\n",
    "\n",
    "path = os.listdir(dir1)\n",
    "\n",
    "path_list = []\n",
    "    \n",
    "for i in path:\n",
    "    \n",
    "    path_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 20\n",
      "new_mask/01_test.png | results1/01_test.png\n",
      "new_mask/02_test.png | results1/02_test.png\n",
      "new_mask/03_test.png | results1/03_test.png\n",
      "new_mask/04_test.png | results1/04_test.png\n",
      "new_mask/05_test.png | results1/05_test.png\n",
      "new_mask/06_test.png | results1/06_test.png\n",
      "new_mask/07_test.png | results1/07_test.png\n",
      "new_mask/08_test.png | results1/08_test.png\n",
      "new_mask/09_test.png | results1/09_test.png\n",
      "new_mask/10_test.png | results1/10_test.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "input_dir = dir1\n",
    "target_dir = dir2\n",
    "img_size = (512, 512)\n",
    "num_classes = 2\n",
    "batch_size = 4\n",
    "\n",
    "input_img_paths = sorted(\n",
    "    [\n",
    "        os.path.join(input_dir, fname)\n",
    "        for fname in os.listdir(input_dir)\n",
    "        if fname.endswith(\".png\")\n",
    "    ]\n",
    ")\n",
    "target_img_paths = sorted(\n",
    "    [\n",
    "        os.path.join(target_dir, fname)\n",
    "        for fname in os.listdir(target_dir)\n",
    "        if fname.endswith(\".png\") and not fname.startswith(\".\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Number of samples:\", len(input_img_paths))\n",
    "\n",
    "for input_path, target_path in zip(input_img_paths[:10], target_img_paths[:10]):\n",
    "    print(input_path, \"|\", target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(512, 512)\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# load the image and convert into numpy array\n",
    "\n",
    "img1 = Image.open(dir1 + \"01_test.png\")\n",
    "img2 = Image.open(dir2 + \"01_test.png\")\n",
    "  \n",
    "# asarray() class is used to convert\n",
    "# PIL images into NumPy arrays\n",
    "numpy_data1 = np.asarray(img1)\n",
    "numpy_data2 = np.asarray(img2)\n",
    "\n",
    "# Consider only the first two channels\n",
    "numpy_data1 = numpy_data1[:,:,1] # Discard the last channel \n",
    "numpy_data2 = numpy_data2[:,:,1] # Discard the last channel \n",
    "\n",
    "# Alternative\n",
    "# numpy_data1 = numpy_data1[:,:,0] and then numpy_data1 = numpy_data1[:,:,1]\n",
    "  \n",
    "# <class 'numpy.ndarray'>\n",
    "print(type(numpy_data1))\n",
    "  \n",
    "#  shape\n",
    "print(numpy_data1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 512, 512)\n",
      "(20, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "data1 = []\n",
    "data2 = []\n",
    "\n",
    "for i in range(20):\n",
    "    img1 = Image.open(dir1 + path_list[i])\n",
    "    img2 = Image.open(dir2 + path_list[i])\n",
    "    \n",
    "    np_data1 = np.asarray(img1)\n",
    "    np_data2 = np.asarray(img2)\n",
    "    \n",
    "    # Consider only the first two channels\n",
    "    np_data1 = np_data1[:,:,1] # Discard the last channel \n",
    "    np_data2 = np_data2[:,:,1] # Discard the last channel \n",
    "    \n",
    "    data1.append(np_data1)\n",
    "    data2.append(np_data2)\n",
    "    \n",
    "data1 = np.array(data1)\n",
    "data2 = np.array(data2)\n",
    "\n",
    "print(data1.shape)\n",
    "print(data2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(np.array_equal(numpy_data1, numpy_data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(np.array_equiv(numpy_data1, numpy_data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_shape = numpy_data1.shape[0]*numpy_data1.shape[1]\n",
    "\n",
    "a = np.reshape(numpy_data1, final_shape)\n",
    "b = np.reshape(numpy_data2, final_shape)\n",
    "\n",
    "y_score = np.empty((a.shape[0]))\n",
    "\n",
    "for i in range(a.shape[0]):\n",
    "    if a[i] == b[i]:\n",
    "        y_score[i] = 1\n",
    "    else:\n",
    "        y_score[i] = 0\n",
    "        \n",
    "y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_value = 0.5\n",
    "y_true = np.empty((a.shape[0]))\n",
    "\n",
    "for i in range(a.shape[0]):\n",
    "    if np.float32(int(a[i]))/255.0 > 0.5:\n",
    "        y_true[i] = 0\n",
    "    else:\n",
    "        y_true[i] = 1\n",
    "        \n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Confusion Matrix = \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 22673,     43],\n",
       "       [ 73354, 166074]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The Confusion Matrix = \")\n",
    "confusion_matrix(y_true, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(y_true, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 0.6936281470838832\n",
      "Precision: 0.999741146300499\n",
      "\n",
      "F1 score (F-measure): 0.819016385357975\n"
     ]
    }
   ],
   "source": [
    "# confusion = confusion_matrix(y_true, y_score)\n",
    "\n",
    "specificity = 0\n",
    "if float(confusion[0,0]+confusion[0,1])!=0:\n",
    "    specificity = float(confusion[0,0])/float(confusion[0,0]+confusion[0,1])\n",
    "# print(\"Specificity: \" +str(specificity))\n",
    "\n",
    "sensitivity = 0\n",
    "if float(confusion[1,1]+confusion[1,0])!=0:\n",
    "    sensitivity = float(confusion[1,1])/float(confusion[1,1]+confusion[1,0])\n",
    "print(\"Sensitivity: \" +str(sensitivity))\n",
    "\n",
    "precision = 0\n",
    "if float(confusion[1,1]+confusion[0,1])!=0:\n",
    "    precision = float(confusion[1,1])/float(confusion[1,1]+confusion[0,1])\n",
    "    \n",
    "print(\"Precision: \" +str(precision))\n",
    "\n",
    "# F1 score\n",
    "F1_score = f1_score(y_true, y_score, labels=None, average='binary', sample_weight=None)\n",
    "print(\"\\nF1 score (F-measure): \" +str(F1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute The IoU Scores:\n",
    "\n",
    "intersection_values = 0\n",
    "union_values = 0\n",
    "\n",
    "for i, j in zip(y_true, y_score):\n",
    "    if i and j == 1:\n",
    "        intersection_values += 1\n",
    "        \n",
    "for i, j in zip(y_true, y_score):\n",
    "    if i or j == 1:\n",
    "        union_values += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The IoU Score for the single image =  0.6935036\n"
     ]
    }
   ],
   "source": [
    "print(\"The IoU Score for the single image = \", np.float32(intersection_values/union_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Blocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns = ['Recall', 'Precision', 'Accuracy', 'F1-Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Image1\n",
      "Sensitivity: 0.6442264063136258\n",
      "Precision: 1.0\n",
      "Accuracy: 0.6500473022460938\n",
      "F1 score (F-measure): 0.7836225033728642\n",
      "\n",
      " Image2\n",
      "Sensitivity: 0.6332635299246434\n",
      "Precision: 1.0\n",
      "Accuracy: 0.6405830383300781\n",
      "F1 score (F-measure): 0.7754578710930518\n",
      "\n",
      " Image3\n",
      "Sensitivity: 0.6775761279152663\n",
      "Precision: 1.0\n",
      "Accuracy: 0.6980781555175781\n",
      "F1 score (F-measure): 0.8078037313958374\n",
      "\n",
      " Image4\n",
      "Sensitivity: 0.6577507148234688\n",
      "Precision: 1.0\n",
      "Accuracy: 0.6653060913085938\n",
      "F1 score (F-measure): 0.7935459884793493\n",
      "\n",
      " Image5\n",
      "Sensitivity: 0.6446528386941968\n",
      "Precision: 1.0\n",
      "Accuracy: 0.6553955078125\n",
      "F1 score (F-measure): 0.7839378907539308\n",
      "\n",
      " Image6\n",
      "Sensitivity: 0.6364122653828606\n",
      "Precision: 1.0\n",
      "Accuracy: 0.647369384765625\n",
      "F1 score (F-measure): 0.7778140983732647\n",
      "\n",
      " Image7\n",
      "Sensitivity: 0.6554045038185914\n",
      "Precision: 1.0\n",
      "Accuracy: 0.6650505065917969\n",
      "F1 score (F-measure): 0.7918360766891018\n",
      "\n",
      " Image8\n",
      "Sensitivity: 0.6805995771303927\n",
      "Precision: 1.0\n",
      "Accuracy: 0.6905479431152344\n",
      "F1 score (F-measure): 0.8099485283609433\n",
      "\n",
      " Image9\n",
      "Sensitivity: 0.6698891770808771\n",
      "Precision: 1.0\n",
      "Accuracy: 0.6795654296875\n",
      "F1 score (F-measure): 0.8023157300197685\n",
      "\n",
      " Image10\n",
      "Sensitivity: 0.6635542027992714\n",
      "Precision: 1.0\n",
      "Accuracy: 0.6702537536621094\n",
      "F1 score (F-measure): 0.7977548332151789\n",
      "\n",
      " Image11\n",
      "Sensitivity: 0.6224231422472225\n",
      "Precision: 1.0\n",
      "Accuracy: 0.6302528381347656\n",
      "F1 score (F-measure): 0.7672759664721037\n",
      "\n",
      " Image12\n",
      "Sensitivity: 0.6639546476395269\n",
      "Precision: 1.0\n",
      "Accuracy: 0.672119140625\n",
      "F1 score (F-measure): 0.798044163741371\n",
      "\n",
      " Image13\n",
      "Sensitivity: 0.6227106083632319\n",
      "Precision: 1.0\n",
      "Accuracy: 0.6325492858886719\n",
      "F1 score (F-measure): 0.7674943457617954\n",
      "\n",
      " Image14\n",
      "Sensitivity: 0.6640735199829023\n",
      "Precision: 1.0\n",
      "Accuracy: 0.6702232360839844\n",
      "F1 score (F-measure): 0.7981300249158768\n",
      "\n",
      " Image15\n",
      "Sensitivity: 0.6939708536277724\n",
      "Precision: 1.0\n",
      "Accuracy: 0.6991996765136719\n",
      "F1 score (F-measure): 0.8193421417394272\n",
      "\n",
      " Image16\n",
      "Sensitivity: 0.6571199530745918\n",
      "Precision: 1.0\n",
      "Accuracy: 0.6655158996582031\n",
      "F1 score (F-measure): 0.793086767020556\n",
      "\n",
      " Image17\n",
      "Sensitivity: 0.6793528590039397\n",
      "Precision: 1.0\n",
      "Accuracy: 0.6882820129394531\n",
      "F1 score (F-measure): 0.809065057842434\n",
      "\n",
      " Image18\n",
      "Sensitivity: 0.6865270111021522\n",
      "Precision: 1.0\n",
      "Accuracy: 0.6915206909179688\n",
      "F1 score (F-measure): 0.8141310593697566\n",
      "\n",
      " Image19\n",
      "Sensitivity: 0.6595499334734569\n",
      "Precision: 1.0\n",
      "Accuracy: 0.6632499694824219\n",
      "F1 score (F-measure): 0.794853978383177\n",
      "\n",
      " Image20\n",
      "Sensitivity: 0.7094478651458564\n",
      "Precision: 1.0\n",
      "Accuracy: 0.7145042419433594\n",
      "F1 score (F-measure): 0.8300315904461043\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for i, j in zip(os.listdir(dir1), os.listdir(dir2)):\n",
    "    \n",
    "    append_list = []\n",
    "    \n",
    "    img1 = Image.open(dir1 + i)\n",
    "    img2 = Image.open(dir2 + j)\n",
    "\n",
    "    numpy_data1 = np.asarray(img1)\n",
    "    numpy_data2 = np.asarray(img2)\n",
    "#     print(numpy_data1.shape)\n",
    "    \n",
    "    # Consider only the first two channels\n",
    "    numpy_data1 = numpy_data1[:,:,1] # Discard the last channel \n",
    "    numpy_data2 = numpy_data2[:,:,1] # Discard the last channel \n",
    "#     print(numpy_data1.shape)\n",
    "    \n",
    "    final_shape = numpy_data1.shape[0]*numpy_data1.shape[1]\n",
    "#     print(final_shape)\n",
    "\n",
    "    a = np.reshape(numpy_data1, final_shape)\n",
    "    b = np.reshape(numpy_data2, final_shape)\n",
    "\n",
    "    y_score = np.empty((a.shape[0]))\n",
    "\n",
    "    for i in range(a.shape[0]):\n",
    "        if a[i] == b[i]:\n",
    "            y_score[i] = 1\n",
    "        else:\n",
    "            y_score[i] = 0\n",
    "\n",
    "    threshold_value = 0.5\n",
    "    y_true = np.empty((a.shape[0]))\n",
    "\n",
    "    for i in range(a.shape[0]):\n",
    "        if np.float32(int(a[i])-int(b[i]))/255.0 > 0.5:\n",
    "            y_true[i] = 0\n",
    "        else:\n",
    "            y_true[i] = 1\n",
    "            \n",
    "    count += 1\n",
    "    \n",
    "    print(f\"\\n Image{count}\")\n",
    "            \n",
    "#     print(\"The Confusion Matrix = \")\n",
    "#     print(confusion_matrix(y_true, y_score))\n",
    "    \n",
    "    confusion = confusion_matrix(y_true, y_score)\n",
    "    \n",
    "    # confusion = confusion_matrix(y_true, y_score)\n",
    "\n",
    "    specificity = 0\n",
    "    if float(confusion[0,0]+confusion[0,1])!=0:\n",
    "        specificity = float(confusion[0,0])/float(confusion[0,0]+confusion[0,1])\n",
    "#     print(\"Specificity: \" +str(specificity))\n",
    "\n",
    "    sensitivity = 0\n",
    "    if float(confusion[1,1]+confusion[1,0])!=0:\n",
    "        sensitivity = float(confusion[1,1])/float(confusion[1,1]+confusion[1,0])\n",
    "    print(\"Sensitivity: \" +str(sensitivity))\n",
    "    append_list.append(sensitivity)\n",
    "    \n",
    "    precision = 0\n",
    "    if float(confusion[1,1]+confusion[0,1])!=0:\n",
    "        precision = float(confusion[1,1])/float(confusion[1,1]+confusion[0,1])\n",
    "\n",
    "    print(\"Precision: \" +str(precision))\n",
    "    append_list.append(precision)\n",
    "    \n",
    "    # Accuracy\n",
    "    \n",
    "    accuracy = 0\n",
    "\n",
    "    accuracy = float(confusion[0,0]+confusion[1,1])/float(confusion[0,0]+confusion[0,1]+confusion[1,0]+confusion[1,1])\n",
    "    print(\"Accuracy: \" +str(accuracy))\n",
    "    append_list.append(accuracy)\n",
    "\n",
    "    # F1 score\n",
    "    F1_score = f1_score(y_true, y_score, labels=None, average='binary', sample_weight=None)\n",
    "    print(\"F1 score (F-measure): \" +str(F1_score))\n",
    "    append_list.append(F1_score)\n",
    "    \n",
    "    df.loc[len(df)] = append_list\n",
    "        \n",
    "#     if count == 10:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('values-1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLOBAL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_shape = data1.shape[0]*data1.shape[1]*data1.shape[2]\n",
    "\n",
    "c = np.reshape(data1, final_shape)\n",
    "d = np.reshape(data2, final_shape)\n",
    "\n",
    "y_score_all = np.empty((c.shape[0]))\n",
    "\n",
    "for i in range(c.shape[0]):\n",
    "    if c[i] == d[i]:\n",
    "        y_score_all[i] = 1\n",
    "    else:\n",
    "        y_score_all[i] = 0\n",
    "        \n",
    "y_score_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_value = 0.5\n",
    "y_true_all = np.empty((c.shape[0]))\n",
    "\n",
    "for i in range(c.shape[0]):\n",
    "    if np.float32(int(c[i]))/255.0 > 0.5:\n",
    "        y_true_all[i] = 0\n",
    "    else:\n",
    "        y_true_all[i] = 1\n",
    "        \n",
    "y_true_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Global Confusion Matrix = \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 443419,     514],\n",
       "       [1418888, 3380059]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The Global Confusion Matrix = \")\n",
    "confusion_matrix(y_true_all, y_score_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(y_true_all, y_score_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 0.7043334714886411\n",
      "Precision: 0.9998479547697979\n",
      "\n",
      "F1 score (F-measure): 0.8300315904461043\n"
     ]
    }
   ],
   "source": [
    "# confusion = confusion_matrix(y_true, y_score)\n",
    "\n",
    "specificity = 0\n",
    "if float(confusion[0,0]+confusion[0,1])!=0:\n",
    "    specificity = float(confusion[0,0])/float(confusion[0,0]+confusion[0,1])\n",
    "# print(\"Specificity: \" +str(specificity))\n",
    "\n",
    "sensitivity = 0\n",
    "if float(confusion[1,1]+confusion[1,0])!=0:\n",
    "    sensitivity = float(confusion[1,1])/float(confusion[1,1]+confusion[1,0])\n",
    "print(\"Sensitivity: \" +str(sensitivity))\n",
    "\n",
    "precision = 0\n",
    "if float(confusion[1,1]+confusion[0,1])!=0:\n",
    "    precision = float(confusion[1,1])/float(confusion[1,1]+confusion[0,1])\n",
    "    \n",
    "print(\"Precision: \" +str(precision))\n",
    "\n",
    "# F1 score\n",
    "F1_score = f1_score(y_true, y_score, labels=None, average='binary', sample_weight=None)\n",
    "print(\"\\nF1 score (F-measure): \" +str(F1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7292705535888672\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "\n",
    "accuracy = float(confusion[1,1]+confusion[0,0])/float(confusion[0,0]+confusion[0,1]+confusion[1,0]+confusion[1,1])\n",
    "print(\"Accuracy: \" +str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The IoU Score for the images =  0.704258\n"
     ]
    }
   ],
   "source": [
    "# Compute The IoU Scores:\n",
    "\n",
    "intersection_values = 0\n",
    "union_values = 0\n",
    "\n",
    "for i, j in zip(y_true_all, y_score_all):\n",
    "    if i and j == 1:\n",
    "        intersection_values += 1\n",
    "        \n",
    "for i, j in zip(y_true_all, y_score_all):\n",
    "    if i or j == 1:\n",
    "        union_values += 1\n",
    "        \n",
    "print(\"The IoU Score for the images = \", np.float32(intersection_values/union_values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
