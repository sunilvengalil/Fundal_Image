{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIUz94YO5Y0x"
      },
      "source": [
        "### Import the required libraries and modules:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RN5vXWIK27Lr"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import Recall, Precision\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DguMtoH4ZJA9",
        "outputId": "70cdbf11-9ffc-4996-d921-a8470fa5d509"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/Blood_Vessel_Results/ALL_BEST_RESULTS/HRF_BV_FULL2\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "%cd /content/gdrive/MyDrive/Blood_Vessel_Results/ALL_BEST_RESULTS/HRF_BV_FULL2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQcINXFE59yv"
      },
      "source": [
        "### Unzip the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mA5voGSj58wH"
      },
      "outputs": [],
      "source": [
        "# !unzip new_data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WctlpFt6hx4"
      },
      "source": [
        "### Construct the Model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epeNiZGQ5gSW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad0838d0-e5f7-4dc7-9bb2-d033925371d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"UNET\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 512, 512, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 512, 512, 64  1792        ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 512, 512, 64  256        ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 512, 512, 64  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 512, 512, 64  36928       ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 512, 512, 64  256        ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 512, 512, 64  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 256, 256, 64  0           ['activation_1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 256, 256, 12  73856       ['max_pooling2d[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 256, 256, 12  512        ['conv2d_2[0][0]']               \n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 256, 256, 12  0           ['batch_normalization_2[0][0]']  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 256, 256, 12  147584      ['activation_2[0][0]']           \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 256, 256, 12  512        ['conv2d_3[0][0]']               \n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 256, 256, 12  0           ['batch_normalization_3[0][0]']  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 12  0          ['activation_3[0][0]']           \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 128, 128, 25  295168      ['max_pooling2d_1[0][0]']        \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 128, 128, 25  1024       ['conv2d_4[0][0]']               \n",
            " rmalization)                   6)                                                                \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 128, 128, 25  0           ['batch_normalization_4[0][0]']  \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 128, 128, 25  590080      ['activation_4[0][0]']           \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 128, 128, 25  1024       ['conv2d_5[0][0]']               \n",
            " rmalization)                   6)                                                                \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 128, 128, 25  0           ['batch_normalization_5[0][0]']  \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 256)  0          ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 64, 64, 512)  1180160     ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 64, 64, 512)  2048       ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 64, 64, 512)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 64, 64, 512)  2359808     ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 64, 64, 512)  2048       ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 64, 64, 512)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 512)  0          ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 32, 32, 1024  4719616     ['max_pooling2d_3[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 32, 32, 1024  4096       ['conv2d_8[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 32, 32, 1024  0           ['batch_normalization_8[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 32, 32, 1024  9438208     ['activation_8[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 32, 32, 1024  4096       ['conv2d_9[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 32, 32, 1024  0           ['batch_normalization_9[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTransp  (None, 64, 64, 512)  2097664    ['activation_9[0][0]']           \n",
            " ose)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 64, 64, 1024  0           ['conv2d_transpose[0][0]',       \n",
            "                                )                                 'activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 64, 64, 512)  4719104     ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 64, 64, 512)  2048       ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 64, 64, 512)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 64, 64, 512)  2359808     ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 64, 64, 512)  2048       ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 64, 64, 512)  0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, 128, 128, 25  524544     ['activation_11[0][0]']          \n",
            " spose)                         6)                                                                \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 128, 128, 51  0           ['conv2d_transpose_1[0][0]',     \n",
            "                                2)                                'activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 128, 128, 25  1179904     ['concatenate_1[0][0]']          \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 128, 128, 25  1024       ['conv2d_12[0][0]']              \n",
            " ormalization)                  6)                                                                \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 128, 128, 25  0           ['batch_normalization_12[0][0]'] \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 128, 128, 25  590080      ['activation_12[0][0]']          \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 128, 128, 25  1024       ['conv2d_13[0][0]']              \n",
            " ormalization)                  6)                                                                \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 128, 128, 25  0           ['batch_normalization_13[0][0]'] \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, 256, 256, 12  131200     ['activation_13[0][0]']          \n",
            " spose)                         8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 256, 256, 25  0           ['conv2d_transpose_2[0][0]',     \n",
            "                                6)                                'activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 256, 256, 12  295040      ['concatenate_2[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 256, 256, 12  512        ['conv2d_14[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 256, 256, 12  0           ['batch_normalization_14[0][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 256, 256, 12  147584      ['activation_14[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 256, 256, 12  512        ['conv2d_15[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 256, 256, 12  0           ['batch_normalization_15[0][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2DTran  (None, 512, 512, 64  32832      ['activation_15[0][0]']          \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 512, 512, 12  0           ['conv2d_transpose_3[0][0]',     \n",
            "                                8)                                'activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 512, 512, 64  73792       ['concatenate_3[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 512, 512, 64  256        ['conv2d_16[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 512, 512, 64  0           ['batch_normalization_16[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 512, 512, 64  36928       ['activation_16[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 512, 512, 64  256        ['conv2d_17[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 512, 512, 64  0           ['batch_normalization_17[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 512, 512, 1)  65          ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31,055,297\n",
            "Trainable params: 31,043,521\n",
            "Non-trainable params: 11,776\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def conv_block(inputs, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def encoder_block(inputs, num_filters, strides=2):\n",
        "    x = conv_block(inputs, num_filters)\n",
        "    p = MaxPool2D(strides)(x)\n",
        "    return x, p\n",
        "\n",
        "def decoder_block(inputs, skip_features, num_filters, strides=2):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=strides, padding=\"same\")(inputs)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "def build_unet(input_shape, num_filters=[64, 128, 256, 512, 1024], strides=[2, 2, 2, 2]):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    s1, p1 = encoder_block(inputs, num_filters[0], strides=strides[0])\n",
        "    s2, p2 = encoder_block(p1, num_filters[1], strides=strides[1])\n",
        "    s3, p3 = encoder_block(p2, num_filters[2], strides=strides[2])\n",
        "    s4, p4 = encoder_block(p3, num_filters[3], strides=strides[3])\n",
        "\n",
        "    b1 = conv_block(p4, num_filters[4])\n",
        "\n",
        "    d1 = decoder_block(b1, s4, num_filters[3], strides=strides[3])\n",
        "    d2 = decoder_block(d1, s3, num_filters[2], strides=strides[2])\n",
        "    d3 = decoder_block(d2, s2, num_filters[1], strides=strides[1])\n",
        "    d4 = decoder_block(d3, s1, num_filters[0], strides=strides[0])\n",
        "\n",
        "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"UNET\")\n",
        "    return model\n",
        "\n",
        "input_shape = (512, 512, 3)\n",
        "model = build_unet(input_shape)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWKUCE3_6vBv"
      },
      "source": [
        "### Adding the Metrics:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5HXET5Z6uZX"
      },
      "outputs": [],
      "source": [
        "def iou(y_true, y_pred):\n",
        "    def f(y_true, y_pred):\n",
        "        intersection = (y_true * y_pred).sum()\n",
        "        union = y_true.sum() + y_pred.sum() - intersection\n",
        "        x = (intersection + 1e-15) / (union + 1e-15)\n",
        "        x = x.astype(np.float32)\n",
        "        return x\n",
        "    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n",
        "\n",
        "smooth = 1e-15\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true = tf.keras.layers.Flatten()(y_true)\n",
        "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coef(y_true, y_pred)\n",
        "\n",
        "def DiceBCELoss(y_true, y_pred):\n",
        "\n",
        "    inputs = tf.keras.layers.Flatten()(y_true)\n",
        "    targets = tf.keras.layers.Flatten()(y_pred)\n",
        "\n",
        "    intersection = tf.reduce_sum(inputs * targets)\n",
        "    dice_loss = 1 - (2.*intersection + smooth)/(tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
        "    BCE = tf.keras.losses.BinaryCrossentropy()\n",
        "    Dice_BCE = BCE(inputs, targets) + dice_loss\n",
        "\n",
        "    return Dice_BCE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuGIkqEH65dX"
      },
      "source": [
        "\n",
        "\n",
        "### Training the Model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNdxwX_-5udw"
      },
      "outputs": [],
      "source": [
        "H = 512\n",
        "W = 512\n",
        "\n",
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "def load_data(path):\n",
        "    x = sorted(glob(os.path.join(path, \"image\", \"*.png\")))\n",
        "    y = sorted(glob(os.path.join(path, \"mask\", \"*.png\")))\n",
        "    return x, y\n",
        "\n",
        "def shuffling(x, y):\n",
        "    x, y = shuffle(x, y, random_state=42)\n",
        "    return x, y\n",
        "\n",
        "def read_image(path):\n",
        "    path = path.decode()\n",
        "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    # x = cv2.resize(x, (W, H))\n",
        "    x = x/255.0\n",
        "    x = x.astype(np.float32)\n",
        "    return x\n",
        "\n",
        "def read_mask(path):\n",
        "    path = path.decode()\n",
        "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  ## (512, 512)\n",
        "    # x = cv2.resize(x, (W, H))\n",
        "    x = x/255.0\n",
        "    x = x.astype(np.float32)\n",
        "    x = np.expand_dims(x, axis=-1)              ## (512, 512, 1)\n",
        "    return x\n",
        "\n",
        "def tf_parse(x, y):\n",
        "    def _parse(x, y):\n",
        "        x = read_image(x)\n",
        "        y = read_mask(y)\n",
        "        return x, y\n",
        "\n",
        "    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n",
        "    x.set_shape([H, W, 3])\n",
        "    y.set_shape([H, W, 1])\n",
        "    return x, y\n",
        "\n",
        "def tf_dataset(X, Y, batch_size=2):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
        "    dataset = dataset.map(tf_parse)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(4)\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxrCn-AZiSo7",
        "outputId": "b1c96742-c01f-4d19-973a-4fdc3d8ce8f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 252 - 252\n",
            "Valid: 9 - 9\n",
            "Epoch 1/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.9422 - dice_coef: 0.3472 - iou: 0.2132 - recall_1: 0.6148 - precision_1: 0.5216\n",
            "Epoch 1: val_loss improved from inf to 1.36603, saving model to files/model1.h5\n",
            "63/63 [==============================] - 251s 3s/step - loss: 0.9422 - dice_coef: 0.3472 - iou: 0.2132 - recall_1: 0.6148 - precision_1: 0.5216 - val_loss: 1.3660 - val_dice_coef: 0.1258 - val_iou: 0.0671 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 2/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.6849 - dice_coef: 0.4885 - iou: 0.3239 - recall_1: 0.6721 - precision_1: 0.7542\n",
            "Epoch 2: val_loss improved from 1.36603 to 1.20989, saving model to files/model1.h5\n",
            "63/63 [==============================] - 196s 3s/step - loss: 0.6849 - dice_coef: 0.4885 - iou: 0.3239 - recall_1: 0.6721 - precision_1: 0.7542 - val_loss: 1.2099 - val_dice_coef: 0.1107 - val_iou: 0.0586 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 3/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.6107 - dice_coef: 0.5415 - iou: 0.3719 - recall_1: 0.6972 - precision_1: 0.7868\n",
            "Epoch 3: val_loss improved from 1.20989 to 1.18711, saving model to files/model1.h5\n",
            "63/63 [==============================] - 198s 3s/step - loss: 0.6107 - dice_coef: 0.5415 - iou: 0.3719 - recall_1: 0.6972 - precision_1: 0.7868 - val_loss: 1.1871 - val_dice_coef: 0.0816 - val_iou: 0.0425 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 4/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.5603 - dice_coef: 0.5787 - iou: 0.4078 - recall_1: 0.7141 - precision_1: 0.8064\n",
            "Epoch 4: val_loss did not improve from 1.18711\n",
            "63/63 [==============================] - 196s 3s/step - loss: 0.5603 - dice_coef: 0.5787 - iou: 0.4078 - recall_1: 0.7141 - precision_1: 0.8064 - val_loss: 1.2030 - val_dice_coef: 0.0655 - val_iou: 0.0339 - val_recall_1: 4.9359e-05 - val_precision_1: 1.0000 - lr: 1.0000e-04\n",
            "Epoch 5/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.5193 - dice_coef: 0.6093 - iou: 0.4387 - recall_1: 0.7267 - precision_1: 0.8215\n",
            "Epoch 5: val_loss did not improve from 1.18711\n",
            "63/63 [==============================] - 196s 3s/step - loss: 0.5193 - dice_coef: 0.6093 - iou: 0.4387 - recall_1: 0.7267 - precision_1: 0.8215 - val_loss: 1.1871 - val_dice_coef: 0.0728 - val_iou: 0.0378 - val_recall_1: 0.0073 - val_precision_1: 0.6706 - lr: 1.0000e-04\n",
            "Epoch 6/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.4883 - dice_coef: 0.6328 - iou: 0.4634 - recall_1: 0.7357 - precision_1: 0.8315\n",
            "Epoch 6: val_loss improved from 1.18711 to 0.93921, saving model to files/model1.h5\n",
            "63/63 [==============================] - 198s 3s/step - loss: 0.4883 - dice_coef: 0.6328 - iou: 0.4634 - recall_1: 0.7357 - precision_1: 0.8315 - val_loss: 0.9392 - val_dice_coef: 0.2548 - val_iou: 0.1463 - val_recall_1: 0.1634 - val_precision_1: 0.7968 - lr: 1.0000e-04\n",
            "Epoch 7/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.4616 - dice_coef: 0.6535 - iou: 0.4859 - recall_1: 0.7433 - precision_1: 0.8389\n",
            "Epoch 7: val_loss improved from 0.93921 to 0.75504, saving model to files/model1.h5\n",
            "63/63 [==============================] - 198s 3s/step - loss: 0.4616 - dice_coef: 0.6535 - iou: 0.4859 - recall_1: 0.7433 - precision_1: 0.8389 - val_loss: 0.7550 - val_dice_coef: 0.4026 - val_iou: 0.2522 - val_recall_1: 0.3216 - val_precision_1: 0.8663 - lr: 1.0000e-04\n",
            "Epoch 8/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.4401 - dice_coef: 0.6704 - iou: 0.5048 - recall_1: 0.7482 - precision_1: 0.8449\n",
            "Epoch 8: val_loss improved from 0.75504 to 0.56662, saving model to files/model1.h5\n",
            "63/63 [==============================] - 199s 3s/step - loss: 0.4401 - dice_coef: 0.6704 - iou: 0.5048 - recall_1: 0.7482 - precision_1: 0.8449 - val_loss: 0.5666 - val_dice_coef: 0.5549 - val_iou: 0.3841 - val_recall_1: 0.5113 - val_precision_1: 0.8973 - lr: 1.0000e-04\n",
            "Epoch 9/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.4218 - dice_coef: 0.6850 - iou: 0.5214 - recall_1: 0.7518 - precision_1: 0.8504\n",
            "Epoch 9: val_loss improved from 0.56662 to 0.47097, saving model to files/model1.h5\n",
            "63/63 [==============================] - 198s 3s/step - loss: 0.4218 - dice_coef: 0.6850 - iou: 0.5214 - recall_1: 0.7518 - precision_1: 0.8504 - val_loss: 0.4710 - val_dice_coef: 0.6366 - val_iou: 0.4669 - val_recall_1: 0.6162 - val_precision_1: 0.9067 - lr: 1.0000e-04\n",
            "Epoch 10/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.4056 - dice_coef: 0.6980 - iou: 0.5367 - recall_1: 0.7551 - precision_1: 0.8552\n",
            "Epoch 10: val_loss improved from 0.47097 to 0.42496, saving model to files/model1.h5\n",
            "63/63 [==============================] - 198s 3s/step - loss: 0.4056 - dice_coef: 0.6980 - iou: 0.5367 - recall_1: 0.7551 - precision_1: 0.8552 - val_loss: 0.4250 - val_dice_coef: 0.6784 - val_iou: 0.5134 - val_recall_1: 0.6827 - val_precision_1: 0.8846 - lr: 1.0000e-04\n",
            "Epoch 11/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.3911 - dice_coef: 0.7097 - iou: 0.5505 - recall_1: 0.7575 - precision_1: 0.8595\n",
            "Epoch 11: val_loss improved from 0.42496 to 0.40614, saving model to files/model1.h5\n",
            "63/63 [==============================] - 199s 3s/step - loss: 0.3911 - dice_coef: 0.7097 - iou: 0.5505 - recall_1: 0.7575 - precision_1: 0.8595 - val_loss: 0.4061 - val_dice_coef: 0.6949 - val_iou: 0.5326 - val_recall_1: 0.6935 - val_precision_1: 0.8841 - lr: 1.0000e-04\n",
            "Epoch 12/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.3775 - dice_coef: 0.7208 - iou: 0.5639 - recall_1: 0.7601 - precision_1: 0.8645\n",
            "Epoch 12: val_loss improved from 0.40614 to 0.39876, saving model to files/model1.h5\n",
            "63/63 [==============================] - 198s 3s/step - loss: 0.3775 - dice_coef: 0.7208 - iou: 0.5639 - recall_1: 0.7601 - precision_1: 0.8645 - val_loss: 0.3988 - val_dice_coef: 0.7040 - val_iou: 0.5434 - val_recall_1: 0.7053 - val_precision_1: 0.8751 - lr: 1.0000e-04\n",
            "Epoch 13/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.3649 - dice_coef: 0.7310 - iou: 0.5765 - recall_1: 0.7629 - precision_1: 0.8691\n",
            "Epoch 13: val_loss improved from 0.39876 to 0.39399, saving model to files/model1.h5\n",
            "63/63 [==============================] - 198s 3s/step - loss: 0.3649 - dice_coef: 0.7310 - iou: 0.5765 - recall_1: 0.7629 - precision_1: 0.8691 - val_loss: 0.3940 - val_dice_coef: 0.7093 - val_iou: 0.5497 - val_recall_1: 0.7040 - val_precision_1: 0.8742 - lr: 1.0000e-04\n",
            "Epoch 14/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.3520 - dice_coef: 0.7414 - iou: 0.5895 - recall_1: 0.7662 - precision_1: 0.8749\n",
            "Epoch 14: val_loss improved from 0.39399 to 0.38858, saving model to files/model1.h5\n",
            "63/63 [==============================] - 198s 3s/step - loss: 0.3520 - dice_coef: 0.7414 - iou: 0.5895 - recall_1: 0.7662 - precision_1: 0.8749 - val_loss: 0.3886 - val_dice_coef: 0.7162 - val_iou: 0.5581 - val_recall_1: 0.6991 - val_precision_1: 0.8759 - lr: 1.0000e-04\n",
            "Epoch 15/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.3411 - dice_coef: 0.7503 - iou: 0.6008 - recall_1: 0.7683 - precision_1: 0.8801\n",
            "Epoch 15: val_loss improved from 0.38858 to 0.38441, saving model to files/model1.h5\n",
            "63/63 [==============================] - 198s 3s/step - loss: 0.3411 - dice_coef: 0.7503 - iou: 0.6008 - recall_1: 0.7683 - precision_1: 0.8801 - val_loss: 0.3844 - val_dice_coef: 0.7232 - val_iou: 0.5667 - val_recall_1: 0.7092 - val_precision_1: 0.8658 - lr: 1.0000e-04\n",
            "Epoch 16/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.3352 - dice_coef: 0.7556 - iou: 0.6076 - recall_1: 0.7678 - precision_1: 0.8812\n",
            "Epoch 16: val_loss improved from 0.38441 to 0.38265, saving model to files/model1.h5\n",
            "63/63 [==============================] - 198s 3s/step - loss: 0.3352 - dice_coef: 0.7556 - iou: 0.6076 - recall_1: 0.7678 - precision_1: 0.8812 - val_loss: 0.3827 - val_dice_coef: 0.7300 - val_iou: 0.5752 - val_recall_1: 0.7401 - val_precision_1: 0.8408 - lr: 1.0000e-04\n",
            "Epoch 17/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.3288 - dice_coef: 0.7610 - iou: 0.6147 - recall_1: 0.7685 - precision_1: 0.8830\n",
            "Epoch 17: val_loss improved from 0.38265 to 0.37293, saving model to files/model1.h5\n",
            "63/63 [==============================] - 198s 3s/step - loss: 0.3288 - dice_coef: 0.7610 - iou: 0.6147 - recall_1: 0.7685 - precision_1: 0.8830 - val_loss: 0.3729 - val_dice_coef: 0.7380 - val_iou: 0.5853 - val_recall_1: 0.7390 - val_precision_1: 0.8478 - lr: 1.0000e-04\n",
            "Epoch 18/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.3214 - dice_coef: 0.7671 - iou: 0.6227 - recall_1: 0.7707 - precision_1: 0.8856\n",
            "Epoch 18: val_loss improved from 0.37293 to 0.36885, saving model to files/model1.h5\n",
            "63/63 [==============================] - 199s 3s/step - loss: 0.3214 - dice_coef: 0.7671 - iou: 0.6227 - recall_1: 0.7707 - precision_1: 0.8856 - val_loss: 0.3688 - val_dice_coef: 0.7428 - val_iou: 0.5912 - val_recall_1: 0.7414 - val_precision_1: 0.8470 - lr: 1.0000e-04\n",
            "Epoch 19/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.3141 - dice_coef: 0.7731 - iou: 0.6305 - recall_1: 0.7726 - precision_1: 0.8887\n",
            "Epoch 19: val_loss improved from 0.36885 to 0.36870, saving model to files/model1.h5\n",
            "63/63 [==============================] - 199s 3s/step - loss: 0.3141 - dice_coef: 0.7731 - iou: 0.6305 - recall_1: 0.7726 - precision_1: 0.8887 - val_loss: 0.3687 - val_dice_coef: 0.7445 - val_iou: 0.5934 - val_recall_1: 0.7406 - val_precision_1: 0.8474 - lr: 1.0000e-04\n",
            "Epoch 20/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.3031 - dice_coef: 0.7815 - iou: 0.6418 - recall_1: 0.7759 - precision_1: 0.8957\n",
            "Epoch 20: val_loss did not improve from 0.36870\n",
            "63/63 [==============================] - 196s 3s/step - loss: 0.3031 - dice_coef: 0.7815 - iou: 0.6418 - recall_1: 0.7759 - precision_1: 0.8957 - val_loss: 0.3727 - val_dice_coef: 0.7472 - val_iou: 0.5969 - val_recall_1: 0.7611 - val_precision_1: 0.8259 - lr: 1.0000e-04\n",
            "Epoch 21/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.2924 - dice_coef: 0.7899 - iou: 0.6531 - recall_1: 0.7796 - precision_1: 0.9021\n",
            "Epoch 21: val_loss did not improve from 0.36870\n",
            "63/63 [==============================] - 197s 3s/step - loss: 0.2924 - dice_coef: 0.7899 - iou: 0.6531 - recall_1: 0.7796 - precision_1: 0.9021 - val_loss: 0.3798 - val_dice_coef: 0.7478 - val_iou: 0.5979 - val_recall_1: 0.7721 - val_precision_1: 0.8097 - lr: 1.0000e-04\n",
            "Epoch 22/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.2940 - dice_coef: 0.7897 - iou: 0.6530 - recall_1: 0.7761 - precision_1: 0.8998\n",
            "Epoch 22: val_loss did not improve from 0.36870\n",
            "63/63 [==============================] - 197s 3s/step - loss: 0.2940 - dice_coef: 0.7897 - iou: 0.6530 - recall_1: 0.7761 - precision_1: 0.8998 - val_loss: 0.3820 - val_dice_coef: 0.7477 - val_iou: 0.5977 - val_recall_1: 0.7603 - val_precision_1: 0.8126 - lr: 1.0000e-04\n",
            "Epoch 23/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.2976 - dice_coef: 0.7875 - iou: 0.6498 - recall_1: 0.7731 - precision_1: 0.8951\n",
            "Epoch 23: val_loss did not improve from 0.36870\n",
            "63/63 [==============================] - 197s 3s/step - loss: 0.2976 - dice_coef: 0.7875 - iou: 0.6498 - recall_1: 0.7731 - precision_1: 0.8951 - val_loss: 0.3787 - val_dice_coef: 0.7481 - val_iou: 0.5982 - val_recall_1: 0.7564 - val_precision_1: 0.8128 - lr: 1.0000e-04\n",
            "Epoch 24/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.2828 - dice_coef: 0.7984 - iou: 0.6647 - recall_1: 0.7805 - precision_1: 0.9040\n",
            "Epoch 24: val_loss did not improve from 0.36870\n",
            "\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "63/63 [==============================] - 196s 3s/step - loss: 0.2828 - dice_coef: 0.7984 - iou: 0.6647 - recall_1: 0.7805 - precision_1: 0.9040 - val_loss: 0.3692 - val_dice_coef: 0.7498 - val_iou: 0.6000 - val_recall_1: 0.7254 - val_precision_1: 0.8451 - lr: 1.0000e-04\n",
            "Epoch 25/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.2657 - dice_coef: 0.8096 - iou: 0.6804 - recall_1: 0.7898 - precision_1: 0.9143\n",
            "Epoch 25: val_loss improved from 0.36870 to 0.35427, saving model to files/model1.h5\n",
            "63/63 [==============================] - 199s 3s/step - loss: 0.2657 - dice_coef: 0.8096 - iou: 0.6804 - recall_1: 0.7898 - precision_1: 0.9143 - val_loss: 0.3543 - val_dice_coef: 0.7614 - val_iou: 0.6152 - val_recall_1: 0.7412 - val_precision_1: 0.8483 - lr: 1.0000e-05\n",
            "Epoch 26/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.2560 - dice_coef: 0.8165 - iou: 0.6902 - recall_1: 0.7940 - precision_1: 0.9220\n",
            "Epoch 26: val_loss did not improve from 0.35427\n",
            "63/63 [==============================] - 197s 3s/step - loss: 0.2560 - dice_coef: 0.8165 - iou: 0.6902 - recall_1: 0.7940 - precision_1: 0.9220 - val_loss: 0.3558 - val_dice_coef: 0.7614 - val_iou: 0.6151 - val_recall_1: 0.7387 - val_precision_1: 0.8484 - lr: 1.0000e-05\n",
            "Epoch 27/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.2513 - dice_coef: 0.8201 - iou: 0.6954 - recall_1: 0.7962 - precision_1: 0.9259\n",
            "Epoch 27: val_loss did not improve from 0.35427\n",
            "63/63 [==============================] - 197s 3s/step - loss: 0.2513 - dice_coef: 0.8201 - iou: 0.6954 - recall_1: 0.7962 - precision_1: 0.9259 - val_loss: 0.3575 - val_dice_coef: 0.7607 - val_iou: 0.6142 - val_recall_1: 0.7358 - val_precision_1: 0.8490 - lr: 1.0000e-05\n",
            "Epoch 28/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.2474 - dice_coef: 0.8230 - iou: 0.6996 - recall_1: 0.7979 - precision_1: 0.9290\n",
            "Epoch 28: val_loss did not improve from 0.35427\n",
            "63/63 [==============================] - 197s 3s/step - loss: 0.2474 - dice_coef: 0.8230 - iou: 0.6996 - recall_1: 0.7979 - precision_1: 0.9290 - val_loss: 0.3592 - val_dice_coef: 0.7601 - val_iou: 0.6135 - val_recall_1: 0.7334 - val_precision_1: 0.8490 - lr: 1.0000e-05\n",
            "Epoch 29/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.2439 - dice_coef: 0.8257 - iou: 0.7034 - recall_1: 0.7995 - precision_1: 0.9319\n",
            "Epoch 29: val_loss did not improve from 0.35427\n",
            "63/63 [==============================] - 197s 3s/step - loss: 0.2439 - dice_coef: 0.8257 - iou: 0.7034 - recall_1: 0.7995 - precision_1: 0.9319 - val_loss: 0.3610 - val_dice_coef: 0.7596 - val_iou: 0.6128 - val_recall_1: 0.7316 - val_precision_1: 0.8487 - lr: 1.0000e-05\n",
            "Epoch 30/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.2407 - dice_coef: 0.8281 - iou: 0.7069 - recall_1: 0.8009 - precision_1: 0.9345\n",
            "Epoch 30: val_loss did not improve from 0.35427\n",
            "\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "63/63 [==============================] - 197s 3s/step - loss: 0.2407 - dice_coef: 0.8281 - iou: 0.7069 - recall_1: 0.8009 - precision_1: 0.9345 - val_loss: 0.3626 - val_dice_coef: 0.7591 - val_iou: 0.6121 - val_recall_1: 0.7292 - val_precision_1: 0.8488 - lr: 1.0000e-05\n",
            "Epoch 31/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.2371 - dice_coef: 0.8303 - iou: 0.7101 - recall_1: 0.8011 - precision_1: 0.9376\n",
            "Epoch 31: val_loss did not improve from 0.35427\n",
            "63/63 [==============================] - 197s 3s/step - loss: 0.2371 - dice_coef: 0.8303 - iou: 0.7101 - recall_1: 0.8011 - precision_1: 0.9376 - val_loss: 0.3637 - val_dice_coef: 0.7596 - val_iou: 0.6129 - val_recall_1: 0.7326 - val_precision_1: 0.8462 - lr: 1.0000e-06\n",
            "Epoch 32/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.2361 - dice_coef: 0.8312 - iou: 0.7114 - recall_1: 0.8027 - precision_1: 0.9378\n",
            "Epoch 32: val_loss did not improve from 0.35427\n",
            "63/63 [==============================] - 196s 3s/step - loss: 0.2361 - dice_coef: 0.8312 - iou: 0.7114 - recall_1: 0.8027 - precision_1: 0.9378 - val_loss: 0.3642 - val_dice_coef: 0.7595 - val_iou: 0.6126 - val_recall_1: 0.7317 - val_precision_1: 0.8461 - lr: 1.0000e-06\n",
            "Epoch 33/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.2356 - dice_coef: 0.8315 - iou: 0.7119 - recall_1: 0.8030 - precision_1: 0.9382\n",
            "Epoch 33: val_loss did not improve from 0.35427\n",
            "63/63 [==============================] - 197s 3s/step - loss: 0.2356 - dice_coef: 0.8315 - iou: 0.7119 - recall_1: 0.8030 - precision_1: 0.9382 - val_loss: 0.3646 - val_dice_coef: 0.7593 - val_iou: 0.6124 - val_recall_1: 0.7312 - val_precision_1: 0.8463 - lr: 1.0000e-06\n",
            "Epoch 34/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.2352 - dice_coef: 0.8318 - iou: 0.7124 - recall_1: 0.8032 - precision_1: 0.9385\n",
            "Epoch 34: val_loss did not improve from 0.35427\n",
            "63/63 [==============================] - 196s 3s/step - loss: 0.2352 - dice_coef: 0.8318 - iou: 0.7124 - recall_1: 0.8032 - precision_1: 0.9385 - val_loss: 0.3650 - val_dice_coef: 0.7592 - val_iou: 0.6122 - val_recall_1: 0.7307 - val_precision_1: 0.8463 - lr: 1.0000e-06\n",
            "Epoch 35/50\n",
            "63/63 [==============================] - ETA: 0s - loss: 0.2349 - dice_coef: 0.8321 - iou: 0.7128 - recall_1: 0.8034 - precision_1: 0.9387\n",
            "Epoch 35: val_loss did not improve from 0.35427\n",
            "63/63 [==============================] - 197s 3s/step - loss: 0.2349 - dice_coef: 0.8321 - iou: 0.7128 - recall_1: 0.8034 - precision_1: 0.9387 - val_loss: 0.3653 - val_dice_coef: 0.7591 - val_iou: 0.6121 - val_recall_1: 0.7304 - val_precision_1: 0.8464 - lr: 1.0000e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1bbc5405d0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "\"\"\" Seeding \"\"\"\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "\"\"\" Directory to save files \"\"\"\n",
        "create_dir(\"files\")\n",
        "\n",
        "\"\"\" Hyperparameters \"\"\"\n",
        "batch_size = 4\n",
        "lr = 1e-4\n",
        "num_epochs = 50\n",
        "model_path = os.path.join(\"files\", \"model1.h5\")\n",
        "csv_path = os.path.join(\"files\", \"data1.csv\")\n",
        "\n",
        "\"\"\" Dataset \"\"\"\n",
        "dataset_path = \"new_data\"\n",
        "train_path = os.path.join(dataset_path, \"train\")\n",
        "valid_path = os.path.join(dataset_path, \"test\")\n",
        "\n",
        "train_x, train_y = load_data(train_path)\n",
        "train_x, train_y = shuffling(train_x, train_y)\n",
        "valid_x, valid_y = load_data(valid_path)\n",
        "\n",
        "print(f\"Train: {len(train_x)} - {len(train_y)}\")\n",
        "print(f\"Valid: {len(valid_x)} - {len(valid_y)}\")\n",
        "\n",
        "train_dataset = tf_dataset(train_x, train_y, batch_size=batch_size)\n",
        "valid_dataset = tf_dataset(valid_x, valid_y, batch_size=batch_size)\n",
        "\n",
        "train_steps = len(train_x)//batch_size\n",
        "valid_setps = len(valid_x)//batch_size\n",
        "\n",
        "if len(train_x) % batch_size != 0:\n",
        "    train_steps += 1\n",
        "if len(valid_x) % batch_size != 0:\n",
        "    valid_setps += 1\n",
        "\n",
        "\"\"\" Model \"\"\"\n",
        "model1 = build_unet((H, W, 3), num_filters=[64, 128, 256, 512, 384], strides=[1, 2, 2, 2])\n",
        "\n",
        "model1.compile(loss=DiceBCELoss, optimizer=Adam(lr), metrics=[dice_coef, iou, Recall(), Precision()])\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
        "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5, min_lr=1e-6, verbose=1),\n",
        "    CSVLogger(csv_path),\n",
        "    TensorBoard(),\n",
        "    EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=False)\n",
        "]\n",
        "\n",
        "model1.fit(\n",
        "    train_dataset,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=valid_dataset,\n",
        "    steps_per_epoch=train_steps,\n",
        "    validation_steps=valid_setps,\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOkUPBQXiS3z",
        "outputId": "645aed5c-1ccc-417b-ebdb-a8ebb88c0574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 252 - 252\n",
            "Valid: 9 - 9\n",
            "Epoch 1/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.8263 - dice_coef: 0.4106 - iou: 0.2628 - recall_3: 0.6454 - precision_3: 0.6108\n",
            "Epoch 1: val_loss improved from inf to 1.19483, saving model to files/model2.h5\n",
            "126/126 [==============================] - 210s 1s/step - loss: 0.8263 - dice_coef: 0.4106 - iou: 0.2628 - recall_3: 0.6454 - precision_3: 0.6108 - val_loss: 1.1948 - val_dice_coef: 0.1020 - val_iou: 0.0538 - val_recall_3: 0.0000e+00 - val_precision_3: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 2/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.5938 - dice_coef: 0.5533 - iou: 0.3837 - recall_3: 0.6997 - precision_3: 0.7918\n",
            "Epoch 2: val_loss did not improve from 1.19483\n",
            "126/126 [==============================] - 181s 1s/step - loss: 0.5938 - dice_coef: 0.5533 - iou: 0.3837 - recall_3: 0.6997 - precision_3: 0.7918 - val_loss: 1.1956 - val_dice_coef: 0.0692 - val_iou: 0.0359 - val_recall_3: 3.8500e-04 - val_precision_3: 0.9630 - lr: 1.0000e-04\n",
            "Epoch 3/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.5162 - dice_coef: 0.6115 - iou: 0.4417 - recall_3: 0.7251 - precision_3: 0.8190\n",
            "Epoch 3: val_loss improved from 1.19483 to 0.97514, saving model to files/model2.h5\n",
            "126/126 [==============================] - 184s 1s/step - loss: 0.5162 - dice_coef: 0.6115 - iou: 0.4417 - recall_3: 0.7251 - precision_3: 0.8190 - val_loss: 0.9751 - val_dice_coef: 0.2356 - val_iou: 0.1339 - val_recall_3: 0.1372 - val_precision_3: 0.7349 - lr: 1.0000e-04\n",
            "Epoch 4/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.4651 - dice_coef: 0.6514 - iou: 0.4842 - recall_3: 0.7374 - precision_3: 0.8338\n",
            "Epoch 4: val_loss improved from 0.97514 to 0.55238, saving model to files/model2.h5\n",
            "126/126 [==============================] - 184s 1s/step - loss: 0.4651 - dice_coef: 0.6514 - iou: 0.4842 - recall_3: 0.7374 - precision_3: 0.8338 - val_loss: 0.5524 - val_dice_coef: 0.5682 - val_iou: 0.3973 - val_recall_3: 0.5372 - val_precision_3: 0.9162 - lr: 1.0000e-04\n",
            "Epoch 5/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.4306 - dice_coef: 0.6793 - iou: 0.5155 - recall_3: 0.7420 - precision_3: 0.8426\n",
            "Epoch 5: val_loss improved from 0.55238 to 0.43447, saving model to files/model2.h5\n",
            "126/126 [==============================] - 183s 1s/step - loss: 0.4306 - dice_coef: 0.6793 - iou: 0.5155 - recall_3: 0.7420 - precision_3: 0.8426 - val_loss: 0.4345 - val_dice_coef: 0.6691 - val_iou: 0.5033 - val_recall_3: 0.6841 - val_precision_3: 0.8758 - lr: 1.0000e-04\n",
            "Epoch 6/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.4049 - dice_coef: 0.7005 - iou: 0.5402 - recall_3: 0.7454 - precision_3: 0.8489\n",
            "Epoch 6: val_loss improved from 0.43447 to 0.41355, saving model to files/model2.h5\n",
            "126/126 [==============================] - 183s 1s/step - loss: 0.4049 - dice_coef: 0.7005 - iou: 0.5402 - recall_3: 0.7454 - precision_3: 0.8489 - val_loss: 0.4136 - val_dice_coef: 0.6898 - val_iou: 0.5273 - val_recall_3: 0.7081 - val_precision_3: 0.8640 - lr: 1.0000e-04\n",
            "Epoch 7/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.3822 - dice_coef: 0.7190 - iou: 0.5624 - recall_3: 0.7501 - precision_3: 0.8552\n",
            "Epoch 7: val_loss improved from 0.41355 to 0.39179, saving model to files/model2.h5\n",
            "126/126 [==============================] - 183s 1s/step - loss: 0.3822 - dice_coef: 0.7190 - iou: 0.5624 - recall_3: 0.7501 - precision_3: 0.8552 - val_loss: 0.3918 - val_dice_coef: 0.7096 - val_iou: 0.5508 - val_recall_3: 0.7147 - val_precision_3: 0.8651 - lr: 1.0000e-04\n",
            "Epoch 8/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.3653 - dice_coef: 0.7330 - iou: 0.5797 - recall_3: 0.7532 - precision_3: 0.8602\n",
            "Epoch 8: val_loss improved from 0.39179 to 0.37774, saving model to files/model2.h5\n",
            "126/126 [==============================] - 184s 1s/step - loss: 0.3653 - dice_coef: 0.7330 - iou: 0.5797 - recall_3: 0.7532 - precision_3: 0.8602 - val_loss: 0.3777 - val_dice_coef: 0.7230 - val_iou: 0.5671 - val_recall_3: 0.7243 - val_precision_3: 0.8626 - lr: 1.0000e-04\n",
            "Epoch 9/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.3516 - dice_coef: 0.7445 - iou: 0.5941 - recall_3: 0.7560 - precision_3: 0.8646\n",
            "Epoch 9: val_loss improved from 0.37774 to 0.37042, saving model to files/model2.h5\n",
            "126/126 [==============================] - 183s 1s/step - loss: 0.3516 - dice_coef: 0.7445 - iou: 0.5941 - recall_3: 0.7560 - precision_3: 0.8646 - val_loss: 0.3704 - val_dice_coef: 0.7307 - val_iou: 0.5766 - val_recall_3: 0.7216 - val_precision_3: 0.8653 - lr: 1.0000e-04\n",
            "Epoch 10/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.3395 - dice_coef: 0.7546 - iou: 0.6070 - recall_3: 0.7590 - precision_3: 0.8692\n",
            "Epoch 10: val_loss improved from 0.37042 to 0.36337, saving model to files/model2.h5\n",
            "126/126 [==============================] - 184s 1s/step - loss: 0.3395 - dice_coef: 0.7546 - iou: 0.6070 - recall_3: 0.7590 - precision_3: 0.8692 - val_loss: 0.3634 - val_dice_coef: 0.7388 - val_iou: 0.5868 - val_recall_3: 0.7346 - val_precision_3: 0.8568 - lr: 1.0000e-04\n",
            "Epoch 11/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.3295 - dice_coef: 0.7630 - iou: 0.6179 - recall_3: 0.7616 - precision_3: 0.8732\n",
            "Epoch 11: val_loss improved from 0.36337 to 0.35560, saving model to files/model2.h5\n",
            "126/126 [==============================] - 183s 1s/step - loss: 0.3295 - dice_coef: 0.7630 - iou: 0.6179 - recall_3: 0.7616 - precision_3: 0.8732 - val_loss: 0.3556 - val_dice_coef: 0.7464 - val_iou: 0.5964 - val_recall_3: 0.7397 - val_precision_3: 0.8553 - lr: 1.0000e-04\n",
            "Epoch 12/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.3198 - dice_coef: 0.7710 - iou: 0.6284 - recall_3: 0.7646 - precision_3: 0.8777\n",
            "Epoch 12: val_loss did not improve from 0.35560\n",
            "126/126 [==============================] - 181s 1s/step - loss: 0.3198 - dice_coef: 0.7710 - iou: 0.6284 - recall_3: 0.7646 - precision_3: 0.8777 - val_loss: 0.3570 - val_dice_coef: 0.7509 - val_iou: 0.6021 - val_recall_3: 0.7533 - val_precision_3: 0.8398 - lr: 1.0000e-04\n",
            "Epoch 13/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.3091 - dice_coef: 0.7796 - iou: 0.6398 - recall_3: 0.7686 - precision_3: 0.8833\n",
            "Epoch 13: val_loss did not improve from 0.35560\n",
            "126/126 [==============================] - 181s 1s/step - loss: 0.3091 - dice_coef: 0.7796 - iou: 0.6398 - recall_3: 0.7686 - precision_3: 0.8833 - val_loss: 0.3613 - val_dice_coef: 0.7506 - val_iou: 0.6019 - val_recall_3: 0.7420 - val_precision_3: 0.8416 - lr: 1.0000e-04\n",
            "Epoch 14/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.3082 - dice_coef: 0.7813 - iou: 0.6421 - recall_3: 0.7666 - precision_3: 0.8831\n",
            "Epoch 14: val_loss did not improve from 0.35560\n",
            "126/126 [==============================] - 182s 1s/step - loss: 0.3082 - dice_coef: 0.7813 - iou: 0.6421 - recall_3: 0.7666 - precision_3: 0.8831 - val_loss: 0.4306 - val_dice_coef: 0.7084 - val_iou: 0.5514 - val_recall_3: 0.7521 - val_precision_3: 0.7684 - lr: 1.0000e-04\n",
            "Epoch 15/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2991 - dice_coef: 0.7882 - iou: 0.6514 - recall_3: 0.7704 - precision_3: 0.8872\n",
            "Epoch 15: val_loss improved from 0.35560 to 0.34815, saving model to files/model2.h5\n",
            "126/126 [==============================] - 184s 1s/step - loss: 0.2991 - dice_coef: 0.7882 - iou: 0.6514 - recall_3: 0.7704 - precision_3: 0.8872 - val_loss: 0.3482 - val_dice_coef: 0.7603 - val_iou: 0.6143 - val_recall_3: 0.7567 - val_precision_3: 0.8397 - lr: 1.0000e-04\n",
            "Epoch 16/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2863 - dice_coef: 0.7981 - iou: 0.6649 - recall_3: 0.7765 - precision_3: 0.8954\n",
            "Epoch 16: val_loss did not improve from 0.34815\n",
            "126/126 [==============================] - 181s 1s/step - loss: 0.2863 - dice_coef: 0.7981 - iou: 0.6649 - recall_3: 0.7765 - precision_3: 0.8954 - val_loss: 0.3513 - val_dice_coef: 0.7604 - val_iou: 0.6144 - val_recall_3: 0.7533 - val_precision_3: 0.8368 - lr: 1.0000e-04\n",
            "Epoch 17/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2788 - dice_coef: 0.8041 - iou: 0.6732 - recall_3: 0.7787 - precision_3: 0.9003\n",
            "Epoch 17: val_loss did not improve from 0.34815\n",
            "126/126 [==============================] - 182s 1s/step - loss: 0.2788 - dice_coef: 0.8041 - iou: 0.6732 - recall_3: 0.7787 - precision_3: 0.9003 - val_loss: 0.3599 - val_dice_coef: 0.7573 - val_iou: 0.6104 - val_recall_3: 0.7563 - val_precision_3: 0.8236 - lr: 1.0000e-04\n",
            "Epoch 18/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2810 - dice_coef: 0.8030 - iou: 0.6716 - recall_3: 0.7768 - precision_3: 0.8971\n",
            "Epoch 18: val_loss did not improve from 0.34815\n",
            "126/126 [==============================] - 182s 1s/step - loss: 0.2810 - dice_coef: 0.8030 - iou: 0.6716 - recall_3: 0.7768 - precision_3: 0.8971 - val_loss: 0.3562 - val_dice_coef: 0.7619 - val_iou: 0.6164 - val_recall_3: 0.7649 - val_precision_3: 0.8211 - lr: 1.0000e-04\n",
            "Epoch 19/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2758 - dice_coef: 0.8069 - iou: 0.6771 - recall_3: 0.7788 - precision_3: 0.8997\n",
            "Epoch 19: val_loss did not improve from 0.34815\n",
            "126/126 [==============================] - 181s 1s/step - loss: 0.2758 - dice_coef: 0.8069 - iou: 0.6771 - recall_3: 0.7788 - precision_3: 0.8997 - val_loss: 0.3532 - val_dice_coef: 0.7636 - val_iou: 0.6186 - val_recall_3: 0.7604 - val_precision_3: 0.8247 - lr: 1.0000e-04\n",
            "Epoch 20/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2624 - dice_coef: 0.8169 - iou: 0.6912 - recall_3: 0.7854 - precision_3: 0.9086\n",
            "Epoch 20: val_loss did not improve from 0.34815\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "126/126 [==============================] - 182s 1s/step - loss: 0.2624 - dice_coef: 0.8169 - iou: 0.6912 - recall_3: 0.7854 - precision_3: 0.9086 - val_loss: 0.3606 - val_dice_coef: 0.7590 - val_iou: 0.6125 - val_recall_3: 0.7439 - val_precision_3: 0.8296 - lr: 1.0000e-04\n",
            "Epoch 21/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2477 - dice_coef: 0.8267 - iou: 0.7053 - recall_3: 0.7929 - precision_3: 0.9165\n",
            "Epoch 21: val_loss improved from 0.34815 to 0.34461, saving model to files/model2.h5\n",
            "126/126 [==============================] - 184s 1s/step - loss: 0.2477 - dice_coef: 0.8267 - iou: 0.7053 - recall_3: 0.7929 - precision_3: 0.9165 - val_loss: 0.3446 - val_dice_coef: 0.7687 - val_iou: 0.6250 - val_recall_3: 0.7400 - val_precision_3: 0.8471 - lr: 1.0000e-05\n",
            "Epoch 22/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2356 - dice_coef: 0.8352 - iou: 0.7177 - recall_3: 0.7978 - precision_3: 0.9262\n",
            "Epoch 22: val_loss did not improve from 0.34461\n",
            "126/126 [==============================] - 182s 1s/step - loss: 0.2356 - dice_coef: 0.8352 - iou: 0.7177 - recall_3: 0.7978 - precision_3: 0.9262 - val_loss: 0.3466 - val_dice_coef: 0.7684 - val_iou: 0.6246 - val_recall_3: 0.7348 - val_precision_3: 0.8493 - lr: 1.0000e-05\n",
            "Epoch 23/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2294 - dice_coef: 0.8398 - iou: 0.7244 - recall_3: 0.8008 - precision_3: 0.9310\n",
            "Epoch 23: val_loss did not improve from 0.34461\n",
            "126/126 [==============================] - 182s 1s/step - loss: 0.2294 - dice_coef: 0.8398 - iou: 0.7244 - recall_3: 0.8008 - precision_3: 0.9310 - val_loss: 0.3493 - val_dice_coef: 0.7678 - val_iou: 0.6238 - val_recall_3: 0.7336 - val_precision_3: 0.8486 - lr: 1.0000e-05\n",
            "Epoch 24/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2244 - dice_coef: 0.8436 - iou: 0.7301 - recall_3: 0.8032 - precision_3: 0.9350\n",
            "Epoch 24: val_loss did not improve from 0.34461\n",
            "126/126 [==============================] - 182s 1s/step - loss: 0.2244 - dice_coef: 0.8436 - iou: 0.7301 - recall_3: 0.8032 - precision_3: 0.9350 - val_loss: 0.3516 - val_dice_coef: 0.7674 - val_iou: 0.6233 - val_recall_3: 0.7323 - val_precision_3: 0.8480 - lr: 1.0000e-05\n",
            "Epoch 25/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2198 - dice_coef: 0.8471 - iou: 0.7352 - recall_3: 0.8054 - precision_3: 0.9385\n",
            "Epoch 25: val_loss did not improve from 0.34461\n",
            "126/126 [==============================] - 182s 1s/step - loss: 0.2198 - dice_coef: 0.8471 - iou: 0.7352 - recall_3: 0.8054 - precision_3: 0.9385 - val_loss: 0.3540 - val_dice_coef: 0.7669 - val_iou: 0.6226 - val_recall_3: 0.7309 - val_precision_3: 0.8473 - lr: 1.0000e-05\n",
            "Epoch 26/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2156 - dice_coef: 0.8503 - iou: 0.7401 - recall_3: 0.8073 - precision_3: 0.9418\n",
            "Epoch 26: val_loss did not improve from 0.34461\n",
            "\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "126/126 [==============================] - 182s 1s/step - loss: 0.2156 - dice_coef: 0.8503 - iou: 0.7401 - recall_3: 0.8073 - precision_3: 0.9418 - val_loss: 0.3562 - val_dice_coef: 0.7665 - val_iou: 0.6220 - val_recall_3: 0.7299 - val_precision_3: 0.8466 - lr: 1.0000e-05\n",
            "Epoch 27/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2130 - dice_coef: 0.8520 - iou: 0.7427 - recall_3: 0.8085 - precision_3: 0.9428\n",
            "Epoch 27: val_loss did not improve from 0.34461\n",
            "126/126 [==============================] - 182s 1s/step - loss: 0.2130 - dice_coef: 0.8520 - iou: 0.7427 - recall_3: 0.8085 - precision_3: 0.9428 - val_loss: 0.3539 - val_dice_coef: 0.7668 - val_iou: 0.6224 - val_recall_3: 0.7244 - val_precision_3: 0.8534 - lr: 1.0000e-06\n",
            "Epoch 28/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2114 - dice_coef: 0.8531 - iou: 0.7444 - recall_3: 0.8087 - precision_3: 0.9444\n",
            "Epoch 28: val_loss did not improve from 0.34461\n",
            "126/126 [==============================] - 182s 1s/step - loss: 0.2114 - dice_coef: 0.8531 - iou: 0.7444 - recall_3: 0.8087 - precision_3: 0.9444 - val_loss: 0.3543 - val_dice_coef: 0.7667 - val_iou: 0.6223 - val_recall_3: 0.7239 - val_precision_3: 0.8534 - lr: 1.0000e-06\n",
            "Epoch 29/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2107 - dice_coef: 0.8536 - iou: 0.7452 - recall_3: 0.8090 - precision_3: 0.9449\n",
            "Epoch 29: val_loss did not improve from 0.34461\n",
            "126/126 [==============================] - 182s 1s/step - loss: 0.2107 - dice_coef: 0.8536 - iou: 0.7452 - recall_3: 0.8090 - precision_3: 0.9449 - val_loss: 0.3547 - val_dice_coef: 0.7667 - val_iou: 0.6223 - val_recall_3: 0.7241 - val_precision_3: 0.8531 - lr: 1.0000e-06\n",
            "Epoch 30/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2101 - dice_coef: 0.8541 - iou: 0.7459 - recall_3: 0.8093 - precision_3: 0.9454\n",
            "Epoch 30: val_loss did not improve from 0.34461\n",
            "126/126 [==============================] - 182s 1s/step - loss: 0.2101 - dice_coef: 0.8541 - iou: 0.7459 - recall_3: 0.8093 - precision_3: 0.9454 - val_loss: 0.3550 - val_dice_coef: 0.7667 - val_iou: 0.6222 - val_recall_3: 0.7242 - val_precision_3: 0.8530 - lr: 1.0000e-06\n",
            "Epoch 31/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2096 - dice_coef: 0.8545 - iou: 0.7465 - recall_3: 0.8095 - precision_3: 0.9458\n",
            "Epoch 31: val_loss did not improve from 0.34461\n",
            "126/126 [==============================] - 182s 1s/step - loss: 0.2096 - dice_coef: 0.8545 - iou: 0.7465 - recall_3: 0.8095 - precision_3: 0.9458 - val_loss: 0.3554 - val_dice_coef: 0.7666 - val_iou: 0.6222 - val_recall_3: 0.7240 - val_precision_3: 0.8528 - lr: 1.0000e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1bb825e6d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "\"\"\" Seeding \"\"\"\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "\"\"\" Directory to save files \"\"\"\n",
        "create_dir(\"files\")\n",
        "\n",
        "\"\"\" Hyperparameters \"\"\"\n",
        "batch_size = 2\n",
        "lr = 1e-4\n",
        "num_epochs = 50\n",
        "model_path = os.path.join(\"files\", \"model2.h5\")\n",
        "csv_path = os.path.join(\"files\", \"data2.csv\")\n",
        "\n",
        "\"\"\" Dataset \"\"\"\n",
        "dataset_path = \"new_data\"\n",
        "train_path = os.path.join(dataset_path, \"train\")\n",
        "valid_path = os.path.join(dataset_path, \"test\")\n",
        "\n",
        "train_x, train_y = load_data(train_path)\n",
        "train_x, train_y = shuffling(train_x, train_y)\n",
        "valid_x, valid_y = load_data(valid_path)\n",
        "\n",
        "print(f\"Train: {len(train_x)} - {len(train_y)}\")\n",
        "print(f\"Valid: {len(valid_x)} - {len(valid_y)}\")\n",
        "\n",
        "train_dataset = tf_dataset(train_x, train_y, batch_size=batch_size)\n",
        "valid_dataset = tf_dataset(valid_x, valid_y, batch_size=batch_size)\n",
        "\n",
        "train_steps = len(train_x)//batch_size\n",
        "valid_setps = len(valid_x)//batch_size\n",
        "\n",
        "if len(train_x) % batch_size != 0:\n",
        "    train_steps += 1\n",
        "if len(valid_x) % batch_size != 0:\n",
        "    valid_setps += 1\n",
        "\n",
        "\"\"\" Model \"\"\"\n",
        "model2 = build_unet((H, W, 3), num_filters=[64, 128, 256, 512, 512], strides=[1, 2, 2, 2])\n",
        "\n",
        "model2.compile(loss=DiceBCELoss, optimizer=Adam(lr), metrics=[dice_coef, iou, Recall(), Precision()])\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
        "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5, min_lr=1e-6, verbose=1),\n",
        "    CSVLogger(csv_path),\n",
        "    TensorBoard(),\n",
        "    EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=False)\n",
        "]\n",
        "\n",
        "model2.fit(\n",
        "    train_dataset,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=valid_dataset,\n",
        "    steps_per_epoch=train_steps,\n",
        "    validation_steps=valid_setps,\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rS5aP9vGXDCt",
        "outputId": "a2ad24f1-79e0-4269-e41d-a20db30f5ea2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 252 - 252\n",
            "Valid: 9 - 9\n",
            "Epoch 1/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.8270 - dice_coef: 0.4102 - iou: 0.2624 - recall_4: 0.6450 - precision_4: 0.6110\n",
            "Epoch 1: val_loss improved from inf to 1.19073, saving model to files/model3.h5\n",
            "126/126 [==============================] - 195s 1s/step - loss: 0.8270 - dice_coef: 0.4102 - iou: 0.2624 - recall_4: 0.6450 - precision_4: 0.6110 - val_loss: 1.1907 - val_dice_coef: 0.1011 - val_iou: 0.0533 - val_recall_4: 0.0000e+00 - val_precision_4: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 2/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.5965 - dice_coef: 0.5516 - iou: 0.3821 - recall_4: 0.6967 - precision_4: 0.7913\n",
            "Epoch 2: val_loss did not improve from 1.19073\n",
            "126/126 [==============================] - 186s 1s/step - loss: 0.5965 - dice_coef: 0.5516 - iou: 0.3821 - recall_4: 0.6967 - precision_4: 0.7913 - val_loss: 1.1982 - val_dice_coef: 0.0678 - val_iou: 0.0351 - val_recall_4: 2.0731e-04 - val_precision_4: 0.9545 - lr: 1.0000e-04\n",
            "Epoch 3/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.5193 - dice_coef: 0.6094 - iou: 0.4395 - recall_4: 0.7207 - precision_4: 0.8180\n",
            "Epoch 3: val_loss improved from 1.19073 to 0.94872, saving model to files/model3.h5\n",
            "126/126 [==============================] - 190s 2s/step - loss: 0.5193 - dice_coef: 0.6094 - iou: 0.4395 - recall_4: 0.7207 - precision_4: 0.8180 - val_loss: 0.9487 - val_dice_coef: 0.2546 - val_iou: 0.1465 - val_recall_4: 0.1544 - val_precision_4: 0.7390 - lr: 1.0000e-04\n",
            "Epoch 4/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.4679 - dice_coef: 0.6495 - iou: 0.4822 - recall_4: 0.7334 - precision_4: 0.8333\n",
            "Epoch 4: val_loss improved from 0.94872 to 0.57815, saving model to files/model3.h5\n",
            "126/126 [==============================] - 189s 1s/step - loss: 0.4679 - dice_coef: 0.6495 - iou: 0.4822 - recall_4: 0.7334 - precision_4: 0.8333 - val_loss: 0.5782 - val_dice_coef: 0.5491 - val_iou: 0.3790 - val_recall_4: 0.5065 - val_precision_4: 0.9082 - lr: 1.0000e-04\n",
            "Epoch 5/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.4304 - dice_coef: 0.6794 - iou: 0.5156 - recall_4: 0.7414 - precision_4: 0.8436\n",
            "Epoch 5: val_loss improved from 0.57815 to 0.44863, saving model to files/model3.h5\n",
            "126/126 [==============================] - 189s 1s/step - loss: 0.4304 - dice_coef: 0.6794 - iou: 0.5156 - recall_4: 0.7414 - precision_4: 0.8436 - val_loss: 0.4486 - val_dice_coef: 0.6561 - val_iou: 0.4889 - val_recall_4: 0.6566 - val_precision_4: 0.8783 - lr: 1.0000e-04\n",
            "Epoch 6/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.4043 - dice_coef: 0.7009 - iou: 0.5406 - recall_4: 0.7452 - precision_4: 0.8497\n",
            "Epoch 6: val_loss improved from 0.44863 to 0.41069, saving model to files/model3.h5\n",
            "126/126 [==============================] - 189s 1s/step - loss: 0.4043 - dice_coef: 0.7009 - iou: 0.5406 - recall_4: 0.7452 - precision_4: 0.8497 - val_loss: 0.4107 - val_dice_coef: 0.6922 - val_iou: 0.5300 - val_recall_4: 0.7153 - val_precision_4: 0.8579 - lr: 1.0000e-04\n",
            "Epoch 7/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.3834 - dice_coef: 0.7182 - iou: 0.5614 - recall_4: 0.7484 - precision_4: 0.8554\n",
            "Epoch 7: val_loss improved from 0.41069 to 0.39143, saving model to files/model3.h5\n",
            "126/126 [==============================] - 189s 1s/step - loss: 0.3834 - dice_coef: 0.7182 - iou: 0.5614 - recall_4: 0.7484 - precision_4: 0.8554 - val_loss: 0.3914 - val_dice_coef: 0.7133 - val_iou: 0.5554 - val_recall_4: 0.7457 - val_precision_4: 0.8387 - lr: 1.0000e-04\n",
            "Epoch 8/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.3671 - dice_coef: 0.7318 - iou: 0.5782 - recall_4: 0.7512 - precision_4: 0.8600\n",
            "Epoch 8: val_loss improved from 0.39143 to 0.37755, saving model to files/model3.h5\n",
            "126/126 [==============================] - 189s 2s/step - loss: 0.3671 - dice_coef: 0.7318 - iou: 0.5782 - recall_4: 0.7512 - precision_4: 0.8600 - val_loss: 0.3776 - val_dice_coef: 0.7242 - val_iou: 0.5686 - val_recall_4: 0.7365 - val_precision_4: 0.8524 - lr: 1.0000e-04\n",
            "Epoch 9/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.3535 - dice_coef: 0.7431 - iou: 0.5924 - recall_4: 0.7539 - precision_4: 0.8641\n",
            "Epoch 9: val_loss improved from 0.37755 to 0.36521, saving model to files/model3.h5\n",
            "126/126 [==============================] - 188s 1s/step - loss: 0.3535 - dice_coef: 0.7431 - iou: 0.5924 - recall_4: 0.7539 - precision_4: 0.8641 - val_loss: 0.3652 - val_dice_coef: 0.7372 - val_iou: 0.5849 - val_recall_4: 0.7506 - val_precision_4: 0.8461 - lr: 1.0000e-04\n",
            "Epoch 10/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.3428 - dice_coef: 0.7522 - iou: 0.6039 - recall_4: 0.7561 - precision_4: 0.8676\n",
            "Epoch 10: val_loss improved from 0.36521 to 0.36200, saving model to files/model3.h5\n",
            "126/126 [==============================] - 190s 2s/step - loss: 0.3428 - dice_coef: 0.7522 - iou: 0.6039 - recall_4: 0.7561 - precision_4: 0.8676 - val_loss: 0.3620 - val_dice_coef: 0.7426 - val_iou: 0.5918 - val_recall_4: 0.7592 - val_precision_4: 0.8367 - lr: 1.0000e-04\n",
            "Epoch 11/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.3375 - dice_coef: 0.7576 - iou: 0.6110 - recall_4: 0.7559 - precision_4: 0.8696\n",
            "Epoch 11: val_loss did not improve from 0.36200\n",
            "126/126 [==============================] - 188s 1s/step - loss: 0.3375 - dice_coef: 0.7576 - iou: 0.6110 - recall_4: 0.7559 - precision_4: 0.8696 - val_loss: 0.9632 - val_dice_coef: 0.3379 - val_iou: 0.2038 - val_recall_4: 0.1967 - val_precision_4: 0.8857 - lr: 1.0000e-04\n",
            "Epoch 12/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.3474 - dice_coef: 0.7518 - iou: 0.6034 - recall_4: 0.7435 - precision_4: 0.8621\n",
            "Epoch 12: val_loss improved from 0.36200 to 0.35377, saving model to files/model3.h5\n",
            "126/126 [==============================] - 190s 2s/step - loss: 0.3474 - dice_coef: 0.7518 - iou: 0.6034 - recall_4: 0.7435 - precision_4: 0.8621 - val_loss: 0.3538 - val_dice_coef: 0.7469 - val_iou: 0.5972 - val_recall_4: 0.7493 - val_precision_4: 0.8460 - lr: 1.0000e-04\n",
            "Epoch 13/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.3297 - dice_coef: 0.7646 - iou: 0.6200 - recall_4: 0.7552 - precision_4: 0.8687\n",
            "Epoch 13: val_loss improved from 0.35377 to 0.34390, saving model to files/model3.h5\n",
            "126/126 [==============================] - 190s 1s/step - loss: 0.3297 - dice_coef: 0.7646 - iou: 0.6200 - recall_4: 0.7552 - precision_4: 0.8687 - val_loss: 0.3439 - val_dice_coef: 0.7541 - val_iou: 0.6062 - val_recall_4: 0.7365 - val_precision_4: 0.8624 - lr: 1.0000e-04\n",
            "Epoch 14/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.3211 - dice_coef: 0.7715 - iou: 0.6290 - recall_4: 0.7589 - precision_4: 0.8726\n",
            "Epoch 14: val_loss improved from 0.34390 to 0.33954, saving model to files/model3.h5\n",
            "126/126 [==============================] - 189s 2s/step - loss: 0.3211 - dice_coef: 0.7715 - iou: 0.6290 - recall_4: 0.7589 - precision_4: 0.8726 - val_loss: 0.3395 - val_dice_coef: 0.7587 - val_iou: 0.6121 - val_recall_4: 0.7412 - val_precision_4: 0.8620 - lr: 1.0000e-04\n",
            "Epoch 15/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.3148 - dice_coef: 0.7766 - iou: 0.6359 - recall_4: 0.7616 - precision_4: 0.8758\n",
            "Epoch 15: val_loss improved from 0.33954 to 0.33681, saving model to files/model3.h5\n",
            "126/126 [==============================] - 190s 2s/step - loss: 0.3148 - dice_coef: 0.7766 - iou: 0.6359 - recall_4: 0.7616 - precision_4: 0.8758 - val_loss: 0.3368 - val_dice_coef: 0.7640 - val_iou: 0.6192 - val_recall_4: 0.7580 - val_precision_4: 0.8493 - lr: 1.0000e-04\n",
            "Epoch 16/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.3054 - dice_coef: 0.7839 - iou: 0.6456 - recall_4: 0.7660 - precision_4: 0.8813\n",
            "Epoch 16: val_loss did not improve from 0.33681\n",
            "126/126 [==============================] - 187s 1s/step - loss: 0.3054 - dice_coef: 0.7839 - iou: 0.6456 - recall_4: 0.7660 - precision_4: 0.8813 - val_loss: 0.3390 - val_dice_coef: 0.7652 - val_iou: 0.6208 - val_recall_4: 0.7599 - val_precision_4: 0.8438 - lr: 1.0000e-04\n",
            "Epoch 17/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2965 - dice_coef: 0.7908 - iou: 0.6550 - recall_4: 0.7703 - precision_4: 0.8868\n",
            "Epoch 17: val_loss did not improve from 0.33681\n",
            "126/126 [==============================] - 187s 1s/step - loss: 0.2965 - dice_coef: 0.7908 - iou: 0.6550 - recall_4: 0.7703 - precision_4: 0.8868 - val_loss: 0.3423 - val_dice_coef: 0.7659 - val_iou: 0.6217 - val_recall_4: 0.7609 - val_precision_4: 0.8383 - lr: 1.0000e-04\n",
            "Epoch 18/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2901 - dice_coef: 0.7960 - iou: 0.6620 - recall_4: 0.7731 - precision_4: 0.8907\n",
            "Epoch 18: val_loss did not improve from 0.33681\n",
            "126/126 [==============================] - 187s 1s/step - loss: 0.2901 - dice_coef: 0.7960 - iou: 0.6620 - recall_4: 0.7731 - precision_4: 0.8907 - val_loss: 0.3450 - val_dice_coef: 0.7654 - val_iou: 0.6210 - val_recall_4: 0.7578 - val_precision_4: 0.8369 - lr: 1.0000e-04\n",
            "Epoch 19/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2842 - dice_coef: 0.8006 - iou: 0.6683 - recall_4: 0.7753 - precision_4: 0.8937\n",
            "Epoch 19: val_loss did not improve from 0.33681\n",
            "126/126 [==============================] - 187s 1s/step - loss: 0.2842 - dice_coef: 0.8006 - iou: 0.6683 - recall_4: 0.7753 - precision_4: 0.8937 - val_loss: 0.3536 - val_dice_coef: 0.7638 - val_iou: 0.6190 - val_recall_4: 0.7702 - val_precision_4: 0.8191 - lr: 1.0000e-04\n",
            "Epoch 20/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2773 - dice_coef: 0.8059 - iou: 0.6757 - recall_4: 0.7783 - precision_4: 0.8981\n",
            "Epoch 20: val_loss did not improve from 0.33681\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "126/126 [==============================] - 187s 1s/step - loss: 0.2773 - dice_coef: 0.8059 - iou: 0.6757 - recall_4: 0.7783 - precision_4: 0.8981 - val_loss: 0.3582 - val_dice_coef: 0.7639 - val_iou: 0.6191 - val_recall_4: 0.7700 - val_precision_4: 0.8160 - lr: 1.0000e-04\n",
            "Epoch 21/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2652 - dice_coef: 0.8140 - iou: 0.6871 - recall_4: 0.7857 - precision_4: 0.9036\n",
            "Epoch 21: val_loss did not improve from 0.33681\n",
            "126/126 [==============================] - 187s 1s/step - loss: 0.2652 - dice_coef: 0.8140 - iou: 0.6871 - recall_4: 0.7857 - precision_4: 0.9036 - val_loss: 0.3390 - val_dice_coef: 0.7694 - val_iou: 0.6260 - val_recall_4: 0.7445 - val_precision_4: 0.8495 - lr: 1.0000e-05\n",
            "Epoch 22/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2543 - dice_coef: 0.8216 - iou: 0.6979 - recall_4: 0.7897 - precision_4: 0.9128\n",
            "Epoch 22: val_loss did not improve from 0.33681\n",
            "126/126 [==============================] - 187s 1s/step - loss: 0.2543 - dice_coef: 0.8216 - iou: 0.6979 - recall_4: 0.7897 - precision_4: 0.9128 - val_loss: 0.3408 - val_dice_coef: 0.7689 - val_iou: 0.6253 - val_recall_4: 0.7398 - val_precision_4: 0.8507 - lr: 1.0000e-05\n",
            "Epoch 23/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2480 - dice_coef: 0.8263 - iou: 0.7046 - recall_4: 0.7928 - precision_4: 0.9178\n",
            "Epoch 23: val_loss did not improve from 0.33681\n",
            "126/126 [==============================] - 187s 1s/step - loss: 0.2480 - dice_coef: 0.8263 - iou: 0.7046 - recall_4: 0.7928 - precision_4: 0.9178 - val_loss: 0.3435 - val_dice_coef: 0.7684 - val_iou: 0.6247 - val_recall_4: 0.7387 - val_precision_4: 0.8493 - lr: 1.0000e-05\n",
            "Epoch 24/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2426 - dice_coef: 0.8303 - iou: 0.7105 - recall_4: 0.7954 - precision_4: 0.9221\n",
            "Epoch 24: val_loss did not improve from 0.33681\n",
            "126/126 [==============================] - 187s 1s/step - loss: 0.2426 - dice_coef: 0.8303 - iou: 0.7105 - recall_4: 0.7954 - precision_4: 0.9221 - val_loss: 0.3458 - val_dice_coef: 0.7681 - val_iou: 0.6242 - val_recall_4: 0.7384 - val_precision_4: 0.8476 - lr: 1.0000e-05\n",
            "Epoch 25/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2377 - dice_coef: 0.8340 - iou: 0.7159 - recall_4: 0.7977 - precision_4: 0.9259\n",
            "Epoch 25: val_loss did not improve from 0.33681\n",
            "\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "126/126 [==============================] - 187s 1s/step - loss: 0.2377 - dice_coef: 0.8340 - iou: 0.7159 - recall_4: 0.7977 - precision_4: 0.9259 - val_loss: 0.3479 - val_dice_coef: 0.7678 - val_iou: 0.6239 - val_recall_4: 0.7378 - val_precision_4: 0.8463 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1adcf19f50>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "\"\"\" Seeding \"\"\"\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "\"\"\" Directory to save files \"\"\"\n",
        "create_dir(\"files\")\n",
        "\n",
        "\"\"\" Hyperparameters \"\"\"\n",
        "batch_size = 2\n",
        "lr = 1e-4\n",
        "num_epochs = 50\n",
        "model_path = os.path.join(\"files\", \"model3.h5\")\n",
        "csv_path = os.path.join(\"files\", \"data3.csv\")\n",
        "\n",
        "\"\"\" Dataset \"\"\"\n",
        "dataset_path = \"new_data\"\n",
        "train_path = os.path.join(dataset_path, \"train\")\n",
        "valid_path = os.path.join(dataset_path, \"test\")\n",
        "\n",
        "train_x, train_y = load_data(train_path)\n",
        "train_x, train_y = shuffling(train_x, train_y)\n",
        "valid_x, valid_y = load_data(valid_path)\n",
        "\n",
        "print(f\"Train: {len(train_x)} - {len(train_y)}\")\n",
        "print(f\"Valid: {len(valid_x)} - {len(valid_y)}\")\n",
        "\n",
        "train_dataset = tf_dataset(train_x, train_y, batch_size=batch_size)\n",
        "valid_dataset = tf_dataset(valid_x, valid_y, batch_size=batch_size)\n",
        "\n",
        "train_steps = len(train_x)//batch_size\n",
        "valid_setps = len(valid_x)//batch_size\n",
        "\n",
        "if len(train_x) % batch_size != 0:\n",
        "    train_steps += 1\n",
        "if len(valid_x) % batch_size != 0:\n",
        "    valid_setps += 1\n",
        "\n",
        "\"\"\" Model \"\"\"\n",
        "model3 = build_unet((H, W, 3), num_filters=[64, 128, 256, 512, 768], strides=[1, 2, 2, 2])\n",
        "\n",
        "model3.compile(loss=DiceBCELoss, optimizer=Adam(lr), metrics=[dice_coef, iou, Recall(), Precision()])\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
        "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5, min_lr=1e-6, verbose=1),\n",
        "    CSVLogger(csv_path),\n",
        "    TensorBoard(),\n",
        "    EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=False)\n",
        "]\n",
        "\n",
        "model3.fit(\n",
        "    train_dataset,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=valid_dataset,\n",
        "    steps_per_epoch=train_steps,\n",
        "    validation_steps=valid_setps,\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrax1mIMiS_a",
        "outputId": "e33c1a19-e874-485c-c7a7-dc80fe4d08f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 252 - 252\n",
            "Valid: 9 - 9\n",
            "Epoch 1/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.8232 - dice_coef: 0.4123 - iou: 0.2642 - recall_5: 0.6439 - precision_5: 0.6127\n",
            "Epoch 1: val_loss improved from inf to 1.19082, saving model to files/model4.h5\n",
            "126/126 [==============================] - 201s 2s/step - loss: 0.8232 - dice_coef: 0.4123 - iou: 0.2642 - recall_5: 0.6439 - precision_5: 0.6127 - val_loss: 1.1908 - val_dice_coef: 0.0992 - val_iou: 0.0522 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 2/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.5933 - dice_coef: 0.5538 - iou: 0.3842 - recall_5: 0.6996 - precision_5: 0.7922\n",
            "Epoch 2: val_loss did not improve from 1.19082\n",
            "126/126 [==============================] - 191s 2s/step - loss: 0.5933 - dice_coef: 0.5538 - iou: 0.3842 - recall_5: 0.6996 - precision_5: 0.7922 - val_loss: 1.1978 - val_dice_coef: 0.0680 - val_iou: 0.0352 - val_recall_5: 2.6160e-04 - val_precision_5: 0.9464 - lr: 1.0000e-04\n",
            "Epoch 3/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.5163 - dice_coef: 0.6116 - iou: 0.4417 - recall_5: 0.7240 - precision_5: 0.8189\n",
            "Epoch 3: val_loss improved from 1.19082 to 0.93880, saving model to files/model4.h5\n",
            "126/126 [==============================] - 196s 2s/step - loss: 0.5163 - dice_coef: 0.6116 - iou: 0.4417 - recall_5: 0.7240 - precision_5: 0.8189 - val_loss: 0.9388 - val_dice_coef: 0.2652 - val_iou: 0.1533 - val_recall_5: 0.1653 - val_precision_5: 0.7383 - lr: 1.0000e-04\n",
            "Epoch 4/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.4646 - dice_coef: 0.6518 - iou: 0.4847 - recall_5: 0.7368 - precision_5: 0.8344\n",
            "Epoch 4: val_loss improved from 0.93880 to 0.54617, saving model to files/model4.h5\n",
            "126/126 [==============================] - 195s 2s/step - loss: 0.4646 - dice_coef: 0.6518 - iou: 0.4847 - recall_5: 0.7368 - precision_5: 0.8344 - val_loss: 0.5462 - val_dice_coef: 0.5756 - val_iou: 0.4045 - val_recall_5: 0.5443 - val_precision_5: 0.9039 - lr: 1.0000e-04\n",
            "Epoch 5/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.4282 - dice_coef: 0.6810 - iou: 0.5174 - recall_5: 0.7438 - precision_5: 0.8439\n",
            "Epoch 5: val_loss improved from 0.54617 to 0.43139, saving model to files/model4.h5\n",
            "126/126 [==============================] - 195s 2s/step - loss: 0.4282 - dice_coef: 0.6810 - iou: 0.5174 - recall_5: 0.7438 - precision_5: 0.8439 - val_loss: 0.4314 - val_dice_coef: 0.6723 - val_iou: 0.5070 - val_recall_5: 0.6942 - val_precision_5: 0.8669 - lr: 1.0000e-04\n",
            "Epoch 6/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.4008 - dice_coef: 0.7034 - iou: 0.5436 - recall_5: 0.7481 - precision_5: 0.8511\n",
            "Epoch 6: val_loss improved from 0.43139 to 0.40590, saving model to files/model4.h5\n",
            "126/126 [==============================] - 195s 2s/step - loss: 0.4008 - dice_coef: 0.7034 - iou: 0.5436 - recall_5: 0.7481 - precision_5: 0.8511 - val_loss: 0.4059 - val_dice_coef: 0.6960 - val_iou: 0.5346 - val_recall_5: 0.7175 - val_precision_5: 0.8616 - lr: 1.0000e-04\n",
            "Epoch 7/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.3798 - dice_coef: 0.7207 - iou: 0.5645 - recall_5: 0.7514 - precision_5: 0.8570\n",
            "Epoch 7: val_loss improved from 0.40590 to 0.38770, saving model to files/model4.h5\n",
            "126/126 [==============================] - 196s 2s/step - loss: 0.3798 - dice_coef: 0.7207 - iou: 0.5645 - recall_5: 0.7514 - precision_5: 0.8570 - val_loss: 0.3877 - val_dice_coef: 0.7136 - val_iou: 0.5557 - val_recall_5: 0.7319 - val_precision_5: 0.8568 - lr: 1.0000e-04\n",
            "Epoch 8/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.3637 - dice_coef: 0.7342 - iou: 0.5811 - recall_5: 0.7540 - precision_5: 0.8616\n",
            "Epoch 8: val_loss improved from 0.38770 to 0.38041, saving model to files/model4.h5\n",
            "126/126 [==============================] - 196s 2s/step - loss: 0.3637 - dice_coef: 0.7342 - iou: 0.5811 - recall_5: 0.7540 - precision_5: 0.8616 - val_loss: 0.3804 - val_dice_coef: 0.7216 - val_iou: 0.5655 - val_recall_5: 0.7208 - val_precision_5: 0.8622 - lr: 1.0000e-04\n",
            "Epoch 9/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.3613 - dice_coef: 0.7380 - iou: 0.5860 - recall_5: 0.7479 - precision_5: 0.8599\n",
            "Epoch 9: val_loss did not improve from 0.38041\n",
            "126/126 [==============================] - 191s 2s/step - loss: 0.3613 - dice_coef: 0.7380 - iou: 0.5860 - recall_5: 0.7479 - precision_5: 0.8599 - val_loss: 0.3908 - val_dice_coef: 0.7241 - val_iou: 0.5689 - val_recall_5: 0.7815 - val_precision_5: 0.7992 - lr: 1.0000e-04\n",
            "Epoch 10/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.3483 - dice_coef: 0.7485 - iou: 0.5991 - recall_5: 0.7525 - precision_5: 0.8636\n",
            "Epoch 10: val_loss improved from 0.38041 to 0.35751, saving model to files/model4.h5\n",
            "126/126 [==============================] - 195s 2s/step - loss: 0.3483 - dice_coef: 0.7485 - iou: 0.5991 - recall_5: 0.7525 - precision_5: 0.8636 - val_loss: 0.3575 - val_dice_coef: 0.7408 - val_iou: 0.5894 - val_recall_5: 0.7412 - val_precision_5: 0.8576 - lr: 1.0000e-04\n",
            "Epoch 11/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.3358 - dice_coef: 0.7585 - iou: 0.6120 - recall_5: 0.7574 - precision_5: 0.8683\n",
            "Epoch 11: val_loss improved from 0.35751 to 0.34894, saving model to files/model4.h5\n",
            "126/126 [==============================] - 195s 2s/step - loss: 0.3358 - dice_coef: 0.7585 - iou: 0.6120 - recall_5: 0.7574 - precision_5: 0.8683 - val_loss: 0.3489 - val_dice_coef: 0.7487 - val_iou: 0.5994 - val_recall_5: 0.7445 - val_precision_5: 0.8584 - lr: 1.0000e-04\n",
            "Epoch 12/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.3299 - dice_coef: 0.7638 - iou: 0.6189 - recall_5: 0.7579 - precision_5: 0.8704\n",
            "Epoch 12: val_loss improved from 0.34894 to 0.34538, saving model to files/model4.h5\n",
            "126/126 [==============================] - 195s 2s/step - loss: 0.3299 - dice_coef: 0.7638 - iou: 0.6189 - recall_5: 0.7579 - precision_5: 0.8704 - val_loss: 0.3454 - val_dice_coef: 0.7545 - val_iou: 0.6069 - val_recall_5: 0.7583 - val_precision_5: 0.8495 - lr: 1.0000e-04\n",
            "Epoch 13/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.3183 - dice_coef: 0.7728 - iou: 0.6308 - recall_5: 0.7631 - precision_5: 0.8760\n",
            "Epoch 13: val_loss improved from 0.34538 to 0.34011, saving model to files/model4.h5\n",
            "126/126 [==============================] - 195s 2s/step - loss: 0.3183 - dice_coef: 0.7728 - iou: 0.6308 - recall_5: 0.7631 - precision_5: 0.8760 - val_loss: 0.3401 - val_dice_coef: 0.7606 - val_iou: 0.6148 - val_recall_5: 0.7546 - val_precision_5: 0.8522 - lr: 1.0000e-04\n",
            "Epoch 14/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.3074 - dice_coef: 0.7815 - iou: 0.6423 - recall_5: 0.7682 - precision_5: 0.8823\n",
            "Epoch 14: val_loss did not improve from 0.34011\n",
            "126/126 [==============================] - 192s 2s/step - loss: 0.3074 - dice_coef: 0.7815 - iou: 0.6423 - recall_5: 0.7682 - precision_5: 0.8823 - val_loss: 0.3413 - val_dice_coef: 0.7633 - val_iou: 0.6184 - val_recall_5: 0.7663 - val_precision_5: 0.8412 - lr: 1.0000e-04\n",
            "Epoch 15/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2964 - dice_coef: 0.7901 - iou: 0.6539 - recall_5: 0.7729 - precision_5: 0.8889\n",
            "Epoch 15: val_loss did not improve from 0.34011\n",
            "126/126 [==============================] - 193s 2s/step - loss: 0.2964 - dice_coef: 0.7901 - iou: 0.6539 - recall_5: 0.7729 - precision_5: 0.8889 - val_loss: 0.3478 - val_dice_coef: 0.7614 - val_iou: 0.6159 - val_recall_5: 0.7715 - val_precision_5: 0.8286 - lr: 1.0000e-04\n",
            "Epoch 16/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2894 - dice_coef: 0.7958 - iou: 0.6617 - recall_5: 0.7752 - precision_5: 0.8928\n",
            "Epoch 16: val_loss did not improve from 0.34011\n",
            "126/126 [==============================] - 194s 2s/step - loss: 0.2894 - dice_coef: 0.7958 - iou: 0.6617 - recall_5: 0.7752 - precision_5: 0.8928 - val_loss: 0.3529 - val_dice_coef: 0.7593 - val_iou: 0.6130 - val_recall_5: 0.7711 - val_precision_5: 0.8237 - lr: 1.0000e-04\n",
            "Epoch 17/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2862 - dice_coef: 0.7986 - iou: 0.6656 - recall_5: 0.7755 - precision_5: 0.8940\n",
            "Epoch 17: val_loss did not improve from 0.34011\n",
            "126/126 [==============================] - 192s 2s/step - loss: 0.2862 - dice_coef: 0.7986 - iou: 0.6656 - recall_5: 0.7755 - precision_5: 0.8940 - val_loss: 0.3558 - val_dice_coef: 0.7605 - val_iou: 0.6146 - val_recall_5: 0.7584 - val_precision_5: 0.8264 - lr: 1.0000e-04\n",
            "Epoch 18/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2821 - dice_coef: 0.8021 - iou: 0.6704 - recall_5: 0.7770 - precision_5: 0.8957\n",
            "Epoch 18: val_loss did not improve from 0.34011\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "126/126 [==============================] - 192s 2s/step - loss: 0.2821 - dice_coef: 0.8021 - iou: 0.6704 - recall_5: 0.7770 - precision_5: 0.8957 - val_loss: 0.3495 - val_dice_coef: 0.7654 - val_iou: 0.6210 - val_recall_5: 0.7555 - val_precision_5: 0.8356 - lr: 1.0000e-04\n",
            "Epoch 19/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2606 - dice_coef: 0.8167 - iou: 0.6910 - recall_5: 0.7898 - precision_5: 0.9075\n",
            "Epoch 19: val_loss did not improve from 0.34011\n",
            "126/126 [==============================] - 192s 2s/step - loss: 0.2606 - dice_coef: 0.8167 - iou: 0.6910 - recall_5: 0.7898 - precision_5: 0.9075 - val_loss: 0.3402 - val_dice_coef: 0.7684 - val_iou: 0.6245 - val_recall_5: 0.7398 - val_precision_5: 0.8540 - lr: 1.0000e-05\n",
            "Epoch 20/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2488 - dice_coef: 0.8249 - iou: 0.7027 - recall_5: 0.7935 - precision_5: 0.9177\n",
            "Epoch 20: val_loss did not improve from 0.34011\n",
            "126/126 [==============================] - 192s 2s/step - loss: 0.2488 - dice_coef: 0.8249 - iou: 0.7027 - recall_5: 0.7935 - precision_5: 0.9177 - val_loss: 0.3427 - val_dice_coef: 0.7676 - val_iou: 0.6234 - val_recall_5: 0.7334 - val_precision_5: 0.8563 - lr: 1.0000e-05\n",
            "Epoch 21/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2419 - dice_coef: 0.8300 - iou: 0.7101 - recall_5: 0.7968 - precision_5: 0.9233\n",
            "Epoch 21: val_loss did not improve from 0.34011\n",
            "126/126 [==============================] - 192s 2s/step - loss: 0.2419 - dice_coef: 0.8300 - iou: 0.7101 - recall_5: 0.7968 - precision_5: 0.9233 - val_loss: 0.3452 - val_dice_coef: 0.7671 - val_iou: 0.6228 - val_recall_5: 0.7320 - val_precision_5: 0.8556 - lr: 1.0000e-05\n",
            "Epoch 22/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2359 - dice_coef: 0.8345 - iou: 0.7166 - recall_5: 0.7996 - precision_5: 0.9280\n",
            "Epoch 22: val_loss did not improve from 0.34011\n",
            "126/126 [==============================] - 192s 2s/step - loss: 0.2359 - dice_coef: 0.8345 - iou: 0.7166 - recall_5: 0.7996 - precision_5: 0.9280 - val_loss: 0.3476 - val_dice_coef: 0.7666 - val_iou: 0.6221 - val_recall_5: 0.7304 - val_precision_5: 0.8548 - lr: 1.0000e-05\n",
            "Epoch 23/50\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2304 - dice_coef: 0.8386 - iou: 0.7226 - recall_5: 0.8022 - precision_5: 0.9323\n",
            "Epoch 23: val_loss did not improve from 0.34011\n",
            "\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "126/126 [==============================] - 192s 2s/step - loss: 0.2304 - dice_coef: 0.8386 - iou: 0.7226 - recall_5: 0.8022 - precision_5: 0.9323 - val_loss: 0.3498 - val_dice_coef: 0.7663 - val_iou: 0.6217 - val_recall_5: 0.7295 - val_precision_5: 0.8541 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1bf40c62d0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "\"\"\" Seeding \"\"\"\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "\"\"\" Directory to save files \"\"\"\n",
        "create_dir(\"files\")\n",
        "\n",
        "\"\"\" Hyperparameters \"\"\"\n",
        "batch_size = 2\n",
        "lr = 1e-4\n",
        "num_epochs = 50\n",
        "model_path = os.path.join(\"files\", \"model4.h5\")\n",
        "csv_path = os.path.join(\"files\", \"data4.csv\")\n",
        "\n",
        "\"\"\" Dataset \"\"\"\n",
        "dataset_path = \"new_data\"\n",
        "train_path = os.path.join(dataset_path, \"train\")\n",
        "valid_path = os.path.join(dataset_path, \"test\")\n",
        "\n",
        "train_x, train_y = load_data(train_path)\n",
        "train_x, train_y = shuffling(train_x, train_y)\n",
        "valid_x, valid_y = load_data(valid_path)\n",
        "\n",
        "print(f\"Train: {len(train_x)} - {len(train_y)}\")\n",
        "print(f\"Valid: {len(valid_x)} - {len(valid_y)}\")\n",
        "\n",
        "train_dataset = tf_dataset(train_x, train_y, batch_size=batch_size)\n",
        "valid_dataset = tf_dataset(valid_x, valid_y, batch_size=batch_size)\n",
        "\n",
        "train_steps = len(train_x)//batch_size\n",
        "valid_setps = len(valid_x)//batch_size\n",
        "\n",
        "if len(train_x) % batch_size != 0:\n",
        "    train_steps += 1\n",
        "if len(valid_x) % batch_size != 0:\n",
        "    valid_setps += 1\n",
        "\n",
        "\"\"\" Model \"\"\"\n",
        "model4 = build_unet((H, W, 3), num_filters=[64, 128, 256, 512, 1024], strides=[1, 2, 2, 2])\n",
        "\n",
        "model4.compile(loss=DiceBCELoss, optimizer=Adam(lr), metrics=[dice_coef, iou, Recall(), Precision()])\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
        "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5, min_lr=1e-6, verbose=1),\n",
        "    CSVLogger(csv_path),\n",
        "    TensorBoard(),\n",
        "    EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=False)\n",
        "]\n",
        "\n",
        "model4.fit(\n",
        "    train_dataset,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=valid_dataset,\n",
        "    steps_per_epoch=train_steps,\n",
        "    validation_steps=valid_setps,\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoCZ3iJekG5i",
        "outputId": "4ef7c30b-7496-4726-d19b-4bee50e794f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 252 - 252\n",
            "Valid: 9 - 9\n",
            "Epoch 1/50\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.7225 - dice_coef: 0.4751 - iou: 0.3176 - recall_6: 0.6733 - precision_6: 0.6854\n",
            "Epoch 1: val_loss improved from inf to 1.20069, saving model to files/model5.h5\n",
            "252/252 [==============================] - 223s 829ms/step - loss: 0.7225 - dice_coef: 0.4751 - iou: 0.3176 - recall_6: 0.6733 - precision_6: 0.6854 - val_loss: 1.2007 - val_dice_coef: 0.0664 - val_iou: 0.0344 - val_recall_6: 0.0000e+00 - val_precision_6: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 2/50\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.5077 - dice_coef: 0.6182 - iou: 0.4498 - recall_6: 0.7227 - precision_6: 0.8219\n",
            "Epoch 2: val_loss improved from 1.20069 to 0.65374, saving model to files/model5.h5\n",
            "252/252 [==============================] - 211s 838ms/step - loss: 0.5077 - dice_coef: 0.6182 - iou: 0.4498 - recall_6: 0.7227 - precision_6: 0.8219 - val_loss: 0.6537 - val_dice_coef: 0.4902 - val_iou: 0.3281 - val_recall_6: 0.4315 - val_precision_6: 0.9175 - lr: 1.0000e-04\n",
            "Epoch 3/50\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.4322 - dice_coef: 0.6783 - iou: 0.5153 - recall_6: 0.7356 - precision_6: 0.8422\n",
            "Epoch 3: val_loss improved from 0.65374 to 0.45556, saving model to files/model5.h5\n",
            "252/252 [==============================] - 211s 837ms/step - loss: 0.4322 - dice_coef: 0.6783 - iou: 0.5153 - recall_6: 0.7356 - precision_6: 0.8422 - val_loss: 0.4556 - val_dice_coef: 0.6565 - val_iou: 0.4910 - val_recall_6: 0.7034 - val_precision_6: 0.8318 - lr: 1.0000e-04\n",
            "Epoch 4/50\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3886 - dice_coef: 0.7143 - iou: 0.5576 - recall_6: 0.7425 - precision_6: 0.8534\n",
            "Epoch 4: val_loss improved from 0.45556 to 0.42839, saving model to files/model5.h5\n",
            "252/252 [==============================] - 212s 838ms/step - loss: 0.3886 - dice_coef: 0.7143 - iou: 0.5576 - recall_6: 0.7425 - precision_6: 0.8534 - val_loss: 0.4284 - val_dice_coef: 0.6849 - val_iou: 0.5231 - val_recall_6: 0.7362 - val_precision_6: 0.8097 - lr: 1.0000e-04\n",
            "Epoch 5/50\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3617 - dice_coef: 0.7369 - iou: 0.5854 - recall_6: 0.7470 - precision_6: 0.8608\n",
            "Epoch 5: val_loss improved from 0.42839 to 0.40859, saving model to files/model5.h5\n",
            "252/252 [==============================] - 212s 843ms/step - loss: 0.3617 - dice_coef: 0.7369 - iou: 0.5854 - recall_6: 0.7470 - precision_6: 0.8608 - val_loss: 0.4086 - val_dice_coef: 0.7036 - val_iou: 0.5447 - val_recall_6: 0.7456 - val_precision_6: 0.8068 - lr: 1.0000e-04\n",
            "Epoch 6/50\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3443 - dice_coef: 0.7517 - iou: 0.6042 - recall_6: 0.7505 - precision_6: 0.8658\n",
            "Epoch 6: val_loss improved from 0.40859 to 0.40106, saving model to files/model5.h5\n",
            "252/252 [==============================] - 213s 844ms/step - loss: 0.3443 - dice_coef: 0.7517 - iou: 0.6042 - recall_6: 0.7505 - precision_6: 0.8658 - val_loss: 0.4011 - val_dice_coef: 0.7115 - val_iou: 0.5541 - val_recall_6: 0.7419 - val_precision_6: 0.8066 - lr: 1.0000e-04\n",
            "Epoch 7/50\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3372 - dice_coef: 0.7586 - iou: 0.6131 - recall_6: 0.7497 - precision_6: 0.8671\n",
            "Epoch 7: val_loss improved from 0.40106 to 0.39548, saving model to files/model5.h5\n",
            "252/252 [==============================] - 212s 837ms/step - loss: 0.3372 - dice_coef: 0.7586 - iou: 0.6131 - recall_6: 0.7497 - precision_6: 0.8671 - val_loss: 0.3955 - val_dice_coef: 0.7164 - val_iou: 0.5595 - val_recall_6: 0.7387 - val_precision_6: 0.8065 - lr: 1.0000e-04\n",
            "Epoch 8/50\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3253 - dice_coef: 0.7684 - iou: 0.6258 - recall_6: 0.7541 - precision_6: 0.8713\n",
            "Epoch 8: val_loss improved from 0.39548 to 0.37330, saving model to files/model5.h5\n",
            "252/252 [==============================] - 211s 837ms/step - loss: 0.3253 - dice_coef: 0.7684 - iou: 0.6258 - recall_6: 0.7541 - precision_6: 0.8713 - val_loss: 0.3733 - val_dice_coef: 0.7324 - val_iou: 0.5800 - val_recall_6: 0.7298 - val_precision_6: 0.8386 - lr: 1.0000e-04\n",
            "Epoch 9/50\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3166 - dice_coef: 0.7756 - iou: 0.6353 - recall_6: 0.7578 - precision_6: 0.8749\n",
            "Epoch 9: val_loss improved from 0.37330 to 0.36671, saving model to files/model5.h5\n",
            "252/252 [==============================] - 211s 836ms/step - loss: 0.3166 - dice_coef: 0.7756 - iou: 0.6353 - recall_6: 0.7578 - precision_6: 0.8749 - val_loss: 0.3667 - val_dice_coef: 0.7404 - val_iou: 0.5894 - val_recall_6: 0.7388 - val_precision_6: 0.8343 - lr: 1.0000e-04\n",
            "Epoch 10/50\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3086 - dice_coef: 0.7819 - iou: 0.6438 - recall_6: 0.7614 - precision_6: 0.8785\n",
            "Epoch 10: val_loss improved from 0.36671 to 0.35795, saving model to files/model5.h5\n",
            "252/252 [==============================] - 212s 839ms/step - loss: 0.3086 - dice_coef: 0.7819 - iou: 0.6438 - recall_6: 0.7614 - precision_6: 0.8785 - val_loss: 0.3580 - val_dice_coef: 0.7466 - val_iou: 0.5973 - val_recall_6: 0.7389 - val_precision_6: 0.8425 - lr: 1.0000e-04\n",
            "Epoch 11/50\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.3010 - dice_coef: 0.7880 - iou: 0.6520 - recall_6: 0.7651 - precision_6: 0.8827\n",
            "Epoch 11: val_loss improved from 0.35795 to 0.35750, saving model to files/model5.h5\n",
            "252/252 [==============================] - 212s 840ms/step - loss: 0.3010 - dice_coef: 0.7880 - iou: 0.6520 - recall_6: 0.7651 - precision_6: 0.8827 - val_loss: 0.3575 - val_dice_coef: 0.7495 - val_iou: 0.6013 - val_recall_6: 0.7224 - val_precision_6: 0.8548 - lr: 1.0000e-04\n",
            "Epoch 12/50\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2933 - dice_coef: 0.7941 - iou: 0.6604 - recall_6: 0.7695 - precision_6: 0.8873\n",
            "Epoch 12: val_loss improved from 0.35750 to 0.35514, saving model to files/model5.h5\n",
            "252/252 [==============================] - 211s 838ms/step - loss: 0.2933 - dice_coef: 0.7941 - iou: 0.6604 - recall_6: 0.7695 - precision_6: 0.8873 - val_loss: 0.3551 - val_dice_coef: 0.7525 - val_iou: 0.6052 - val_recall_6: 0.7200 - val_precision_6: 0.8589 - lr: 1.0000e-04\n",
            "Epoch 13/50\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2848 - dice_coef: 0.8006 - iou: 0.6693 - recall_6: 0.7740 - precision_6: 0.8923\n",
            "Epoch 13: val_loss did not improve from 0.35514\n",
            "252/252 [==============================] - 207s 821ms/step - loss: 0.2848 - dice_coef: 0.8006 - iou: 0.6693 - recall_6: 0.7740 - precision_6: 0.8923 - val_loss: 0.3579 - val_dice_coef: 0.7543 - val_iou: 0.6072 - val_recall_6: 0.7242 - val_precision_6: 0.8524 - lr: 1.0000e-04\n",
            "Epoch 14/50\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2770 - dice_coef: 0.8067 - iou: 0.6777 - recall_6: 0.7778 - precision_6: 0.8973\n",
            "Epoch 14: val_loss did not improve from 0.35514\n",
            "252/252 [==============================] - 207s 823ms/step - loss: 0.2770 - dice_coef: 0.8067 - iou: 0.6777 - recall_6: 0.7778 - precision_6: 0.8973 - val_loss: 0.3642 - val_dice_coef: 0.7520 - val_iou: 0.6046 - val_recall_6: 0.7221 - val_precision_6: 0.8481 - lr: 1.0000e-04\n",
            "Epoch 15/50\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2672 - dice_coef: 0.8138 - iou: 0.6877 - recall_6: 0.7821 - precision_6: 0.9037\n",
            "Epoch 15: val_loss did not improve from 0.35514\n",
            "252/252 [==============================] - 207s 823ms/step - loss: 0.2672 - dice_coef: 0.8138 - iou: 0.6877 - recall_6: 0.7821 - precision_6: 0.9037 - val_loss: 0.3612 - val_dice_coef: 0.7528 - val_iou: 0.6055 - val_recall_6: 0.7157 - val_precision_6: 0.8522 - lr: 1.0000e-04\n",
            "Epoch 16/50\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2622 - dice_coef: 0.8177 - iou: 0.6932 - recall_6: 0.7836 - precision_6: 0.9070\n",
            "Epoch 16: val_loss did not improve from 0.35514\n",
            "252/252 [==============================] - 207s 823ms/step - loss: 0.2622 - dice_coef: 0.8177 - iou: 0.6932 - recall_6: 0.7836 - precision_6: 0.9070 - val_loss: 0.3734 - val_dice_coef: 0.7521 - val_iou: 0.6041 - val_recall_6: 0.7387 - val_precision_6: 0.8231 - lr: 1.0000e-04\n",
            "Epoch 17/50\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2578 - dice_coef: 0.8210 - iou: 0.6978 - recall_6: 0.7861 - precision_6: 0.9086\n",
            "Epoch 17: val_loss did not improve from 0.35514\n",
            "\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "252/252 [==============================] - 207s 823ms/step - loss: 0.2578 - dice_coef: 0.8210 - iou: 0.6978 - recall_6: 0.7861 - precision_6: 0.9086 - val_loss: 0.3774 - val_dice_coef: 0.7499 - val_iou: 0.6013 - val_recall_6: 0.7134 - val_precision_6: 0.8391 - lr: 1.0000e-04\n",
            "Epoch 18/50\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2381 - dice_coef: 0.8337 - iou: 0.7163 - recall_6: 0.7952 - precision_6: 0.9210\n",
            "Epoch 18: val_loss did not improve from 0.35514\n",
            "252/252 [==============================] - 207s 823ms/step - loss: 0.2381 - dice_coef: 0.8337 - iou: 0.7163 - recall_6: 0.7952 - precision_6: 0.9210 - val_loss: 0.3598 - val_dice_coef: 0.7547 - val_iou: 0.6075 - val_recall_6: 0.7059 - val_precision_6: 0.8577 - lr: 1.0000e-05\n",
            "Epoch 19/50\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2241 - dice_coef: 0.8441 - iou: 0.7316 - recall_6: 0.8020 - precision_6: 0.9310\n",
            "Epoch 19: val_loss did not improve from 0.35514\n",
            "252/252 [==============================] - 207s 823ms/step - loss: 0.2241 - dice_coef: 0.8441 - iou: 0.7316 - recall_6: 0.8020 - precision_6: 0.9310 - val_loss: 0.3641 - val_dice_coef: 0.7540 - val_iou: 0.6065 - val_recall_6: 0.7019 - val_precision_6: 0.8576 - lr: 1.0000e-05\n",
            "Epoch 20/50\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2160 - dice_coef: 0.8502 - iou: 0.7406 - recall_6: 0.8059 - precision_6: 0.9372\n",
            "Epoch 20: val_loss did not improve from 0.35514\n",
            "252/252 [==============================] - 207s 823ms/step - loss: 0.2160 - dice_coef: 0.8502 - iou: 0.7406 - recall_6: 0.8059 - precision_6: 0.9372 - val_loss: 0.3678 - val_dice_coef: 0.7532 - val_iou: 0.6055 - val_recall_6: 0.6996 - val_precision_6: 0.8571 - lr: 1.0000e-05\n",
            "Epoch 21/50\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2091 - dice_coef: 0.8553 - iou: 0.7485 - recall_6: 0.8091 - precision_6: 0.9424\n",
            "Epoch 21: val_loss did not improve from 0.35514\n",
            "252/252 [==============================] - 207s 823ms/step - loss: 0.2091 - dice_coef: 0.8553 - iou: 0.7485 - recall_6: 0.8091 - precision_6: 0.9424 - val_loss: 0.3711 - val_dice_coef: 0.7525 - val_iou: 0.6046 - val_recall_6: 0.6962 - val_precision_6: 0.8575 - lr: 1.0000e-05\n",
            "Epoch 22/50\n",
            "252/252 [==============================] - ETA: 0s - loss: 0.2028 - dice_coef: 0.8601 - iou: 0.7557 - recall_6: 0.8119 - precision_6: 0.9470\n",
            "Epoch 22: val_loss did not improve from 0.35514\n",
            "\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "252/252 [==============================] - 207s 823ms/step - loss: 0.2028 - dice_coef: 0.8601 - iou: 0.7557 - recall_6: 0.8119 - precision_6: 0.9470 - val_loss: 0.3745 - val_dice_coef: 0.7519 - val_iou: 0.6038 - val_recall_6: 0.6933 - val_precision_6: 0.8577 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1bbdee4090>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "\"\"\" Seeding \"\"\"\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "\"\"\" Directory to save files \"\"\"\n",
        "create_dir(\"files\")\n",
        "\n",
        "\"\"\" Hyperparameters \"\"\"\n",
        "batch_size = 1\n",
        "lr = 1e-4\n",
        "num_epochs = 50\n",
        "model_path = os.path.join(\"files\", \"model5.h5\")\n",
        "csv_path = os.path.join(\"files\", \"data5.csv\")\n",
        "\n",
        "\"\"\" Dataset \"\"\"\n",
        "dataset_path = \"new_data\"\n",
        "train_path = os.path.join(dataset_path, \"train\")\n",
        "valid_path = os.path.join(dataset_path, \"test\")\n",
        "\n",
        "train_x, train_y = load_data(train_path)\n",
        "train_x, train_y = shuffling(train_x, train_y)\n",
        "valid_x, valid_y = load_data(valid_path)\n",
        "\n",
        "print(f\"Train: {len(train_x)} - {len(train_y)}\")\n",
        "print(f\"Valid: {len(valid_x)} - {len(valid_y)}\")\n",
        "\n",
        "train_dataset = tf_dataset(train_x, train_y, batch_size=batch_size)\n",
        "valid_dataset = tf_dataset(valid_x, valid_y, batch_size=batch_size)\n",
        "\n",
        "train_steps = len(train_x)//batch_size\n",
        "valid_setps = len(valid_x)//batch_size\n",
        "\n",
        "if len(train_x) % batch_size != 0:\n",
        "    train_steps += 1\n",
        "if len(valid_x) % batch_size != 0:\n",
        "    valid_setps += 1\n",
        "\n",
        "\"\"\" Model \"\"\"\n",
        "model5 = build_unet((H, W, 3), num_filters=[64, 128, 256, 512, 1280], strides=[1, 2, 2, 2])\n",
        "\n",
        "model5.compile(loss=DiceBCELoss, optimizer=Adam(lr), metrics=[dice_coef, iou, Recall(), Precision()])\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
        "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5, min_lr=1e-6, verbose=1),\n",
        "    CSVLogger(csv_path),\n",
        "    TensorBoard(),\n",
        "    EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=False)\n",
        "]\n",
        "\n",
        "model5.fit(\n",
        "    train_dataset,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=valid_dataset,\n",
        "    steps_per_epoch=train_steps,\n",
        "    validation_steps=valid_setps,\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0HWQPIv6F3u"
      },
      "source": [
        "### Evaluating the Model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ptl8ug8uby3R"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import CustomObjectScope\n",
        "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmFXTEtz6Rhn"
      },
      "outputs": [],
      "source": [
        "H = 512\n",
        "W = 512\n",
        "\n",
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "def read_image(path):\n",
        "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    # x = cv2.resize(x, (W, H))\n",
        "    ori_x = x\n",
        "    x = x/255.0\n",
        "    x = x.astype(np.float32)\n",
        "    return ori_x, x\n",
        "\n",
        "def read_mask(path):\n",
        "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  ## (512, 512)\n",
        "    # x = cv2.resize(x, (W, H))\n",
        "    ori_x = x\n",
        "    x = x/255.0\n",
        "    x = x.astype(np.int32)\n",
        "    return ori_x, x\n",
        "\n",
        "def load_data(path):\n",
        "    x = sorted(glob(os.path.join(path, \"image\", \"*.png\")))\n",
        "    y = sorted(glob(os.path.join(path, \"mask\", \"*.png\")))\n",
        "    return x, y\n",
        "\n",
        "def save_results(ori_x, ori_y, y_pred, save_image_path):\n",
        "    line = np.ones((H, 10, 3)) * 255\n",
        "\n",
        "    ori_y = np.expand_dims(ori_y, axis=-1)\n",
        "    ori_y = np.concatenate([ori_y, ori_y, ori_y], axis=-1)\n",
        "\n",
        "    y_pred = np.expand_dims(y_pred, axis=-1)\n",
        "    y_pred = np.concatenate([y_pred, y_pred, y_pred], axis=-1) * 255\n",
        "\n",
        "    cat_images = np.concatenate([ori_x, line, ori_y, line, y_pred], axis=1)\n",
        "    cv2.imwrite(save_image_path, cat_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVTFZdxa6TuQ",
        "outputId": "86e6c3bc-cc57-4923-e01f-fcfba2245b31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:44<00:00,  4.93s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.96841\n",
            "F1: 0.77004\n",
            "Jaccard: 0.62777\n",
            "Recall: 0.83601\n",
            "Precision: 0.71794\n"
          ]
        }
      ],
      "source": [
        "\"\"\" Save the results in this folder \"\"\"\n",
        "# create_dir(\"results\")\n",
        "\n",
        "\"\"\" Load the model \"\"\"\n",
        "# with CustomObjectScope({'iou': iou, 'dice_coef': dice_coef}):\n",
        "model = load_model(\"files/model1.h5\", compile=False)\n",
        "\n",
        "\"\"\" Load the dataset \"\"\"\n",
        "dataset_path = os.path.join(\"new_data\", \"test\")\n",
        "test_x, test_y = load_data(dataset_path)\n",
        "\n",
        "\"\"\" Make the prediction and calculate the metrics values \"\"\"\n",
        "SCORE = []\n",
        "for x, y in tqdm(zip(test_x, test_y), total=len(test_x)):\n",
        "    \"\"\" Extracting name \"\"\"\n",
        "    name = x.split(\"/\")[-1].split(\".\")[0]\n",
        "\n",
        "    \"\"\" Read the image and mask \"\"\"\n",
        "    ori_x, x = read_image(x)\n",
        "    ori_y, y = read_mask(y)\n",
        "\n",
        "    \"\"\" Prediction \"\"\"\n",
        "    y_pred = model.predict(np.expand_dims(x, axis=0))[0]\n",
        "    y_pred = y_pred > 0.5\n",
        "    y_pred = y_pred.astype(np.int32)\n",
        "    y_pred = np.squeeze(y_pred, axis=-1)\n",
        "\n",
        "    \"\"\" Saving the images \"\"\"\n",
        "    save_image_path = f\"results/{name}.png\"\n",
        "    save_results(ori_x, ori_y, y_pred, save_image_path)\n",
        "\n",
        "    \"\"\" Flatten the array \"\"\"\n",
        "    y = y.flatten()\n",
        "    y_pred = y_pred.flatten()\n",
        "\n",
        "    \"\"\" Calculate the metrics \"\"\"\n",
        "    acc_value = accuracy_score(y, y_pred)\n",
        "    f1_value = f1_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "    jac_value = jaccard_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "    recall_value = recall_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "    precision_value = precision_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "    SCORE.append([name, acc_value, f1_value, jac_value, recall_value, precision_value])\n",
        "\n",
        "score1 = [s[1:] for s in SCORE]\n",
        "score1 = np.mean(score1, axis=0)\n",
        "print(f\"Accuracy: {score1[0]:0.5f}\")\n",
        "print(f\"F1: {score1[1]:0.5f}\")\n",
        "print(f\"Jaccard: {score1[2]:0.5f}\")\n",
        "print(f\"Recall: {score1[3]:0.5f}\")\n",
        "print(f\"Precision: {score1[4]:0.5f}\")\n",
        "\n",
        "\"\"\" Saving \"\"\"\n",
        "df = pd.DataFrame(SCORE, columns=[\"Image\", \"Acc\", \"F1\", \"Jaccard\", \"Recall\", \"Precision\"])\n",
        "df.to_csv(\"files/score1.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sg7ebjFkXXeu",
        "outputId": "a5069862-3bcd-4762-eb54-db8925524b76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:05<00:00,  1.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.96837\n",
            "F1: 0.76973\n",
            "Jaccard: 0.62744\n",
            "Recall: 0.83562\n",
            "Precision: 0.71795\n"
          ]
        }
      ],
      "source": [
        "\"\"\" Save the results in this folder \"\"\"\n",
        "# create_dir(\"results\")\n",
        "\n",
        "\"\"\" Load the model \"\"\"\n",
        "# with CustomObjectScope({'iou': iou, 'dice_coef': dice_coef}):\n",
        "model = load_model(\"files/model2.h5\", compile=False)\n",
        "\n",
        "\"\"\" Load the dataset \"\"\"\n",
        "dataset_path = os.path.join(\"new_data\", \"test\")\n",
        "test_x, test_y = load_data(dataset_path)\n",
        "\n",
        "\"\"\" Make the prediction and calculate the metrics values \"\"\"\n",
        "SCORE = []\n",
        "for x, y in tqdm(zip(test_x, test_y), total=len(test_x)):\n",
        "    \"\"\" Extracting name \"\"\"\n",
        "    name = x.split(\"/\")[-1].split(\".\")[0]\n",
        "\n",
        "    \"\"\" Read the image and mask \"\"\"\n",
        "    ori_x, x = read_image(x)\n",
        "    ori_y, y = read_mask(y)\n",
        "\n",
        "    \"\"\" Prediction \"\"\"\n",
        "    y_pred = model.predict(np.expand_dims(x, axis=0))[0]\n",
        "    y_pred = y_pred > 0.5\n",
        "    y_pred = y_pred.astype(np.int32)\n",
        "    y_pred = np.squeeze(y_pred, axis=-1)\n",
        "\n",
        "    \"\"\" Saving the images \"\"\"\n",
        "    save_image_path = f\"results/{name}.png\"\n",
        "    save_results(ori_x, ori_y, y_pred, save_image_path)\n",
        "\n",
        "    \"\"\" Flatten the array \"\"\"\n",
        "    y = y.flatten()\n",
        "    y_pred = y_pred.flatten()\n",
        "\n",
        "    \"\"\" Calculate the metrics \"\"\"\n",
        "    acc_value = accuracy_score(y, y_pred)\n",
        "    f1_value = f1_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "    jac_value = jaccard_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "    recall_value = recall_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "    precision_value = precision_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "    SCORE.append([name, acc_value, f1_value, jac_value, recall_value, precision_value])\n",
        "\n",
        "score2 = [s[1:] for s in SCORE]\n",
        "score2 = np.mean(score2, axis=0)\n",
        "print(f\"Accuracy: {score2[0]:0.5f}\")\n",
        "print(f\"F1: {score2[1]:0.5f}\")\n",
        "print(f\"Jaccard: {score2[2]:0.5f}\")\n",
        "print(f\"Recall: {score2[3]:0.5f}\")\n",
        "print(f\"Precision: {score2[4]:0.5f}\")\n",
        "\n",
        "\"\"\" Saving \"\"\"\n",
        "df = pd.DataFrame(SCORE, columns=[\"Image\", \"Acc\", \"F1\", \"Jaccard\", \"Recall\", \"Precision\"])\n",
        "df.to_csv(\"files/score2.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oL_gmMQXXkV",
        "outputId": "20ed9f85-e5bf-4111-c80e-697dd46e440b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:06<00:00,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.96845\n",
            "F1: 0.77291\n",
            "Jaccard: 0.63231\n",
            "Recall: 0.84934\n",
            "Precision: 0.71261\n"
          ]
        }
      ],
      "source": [
        "\"\"\" Save the results in this folder \"\"\"\n",
        "# create_dir(\"results\")\n",
        "\n",
        "\"\"\" Load the model \"\"\"\n",
        "# with CustomObjectScope({'iou': iou, 'dice_coef': dice_coef}):\n",
        "model = load_model(\"files/model3.h5\", compile=False)\n",
        "\n",
        "\"\"\" Load the dataset \"\"\"\n",
        "dataset_path = os.path.join(\"new_data\", \"test\")\n",
        "test_x, test_y = load_data(dataset_path)\n",
        "\n",
        "\"\"\" Make the prediction and calculate the metrics values \"\"\"\n",
        "SCORE = []\n",
        "for x, y in tqdm(zip(test_x, test_y), total=len(test_x)):\n",
        "    \"\"\" Extracting name \"\"\"\n",
        "    name = x.split(\"/\")[-1].split(\".\")[0]\n",
        "\n",
        "    \"\"\" Read the image and mask \"\"\"\n",
        "    ori_x, x = read_image(x)\n",
        "    ori_y, y = read_mask(y)\n",
        "\n",
        "    \"\"\" Prediction \"\"\"\n",
        "    y_pred = model.predict(np.expand_dims(x, axis=0))[0]\n",
        "    y_pred = y_pred > 0.5\n",
        "    y_pred = y_pred.astype(np.int32)\n",
        "    y_pred = np.squeeze(y_pred, axis=-1)\n",
        "\n",
        "    \"\"\" Saving the images \"\"\"\n",
        "    save_image_path = f\"results/{name}.png\"\n",
        "    save_results(ori_x, ori_y, y_pred, save_image_path)\n",
        "\n",
        "    \"\"\" Flatten the array \"\"\"\n",
        "    y = y.flatten()\n",
        "    y_pred = y_pred.flatten()\n",
        "\n",
        "    \"\"\" Calculate the metrics \"\"\"\n",
        "    acc_value = accuracy_score(y, y_pred)\n",
        "    f1_value = f1_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "    jac_value = jaccard_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "    recall_value = recall_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "    precision_value = precision_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "    SCORE.append([name, acc_value, f1_value, jac_value, recall_value, precision_value])\n",
        "\n",
        "score3 = [s[1:] for s in SCORE]\n",
        "score3 = np.mean(score3, axis=0)\n",
        "print(f\"Accuracy: {score3[0]:0.5f}\")\n",
        "print(f\"F1: {score3[1]:0.5f}\")\n",
        "print(f\"Jaccard: {score3[2]:0.5f}\")\n",
        "print(f\"Recall: {score3[3]:0.5f}\")\n",
        "print(f\"Precision: {score3[4]:0.5f}\")\n",
        "\n",
        "\"\"\" Saving \"\"\"\n",
        "df = pd.DataFrame(SCORE, columns=[\"Image\", \"Acc\", \"F1\", \"Jaccard\", \"Recall\", \"Precision\"])\n",
        "df.to_csv(\"files/score3.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_S29nWgXXuG",
        "outputId": "f98edfab-77ec-4470-8613-d5152f9c45d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:06<00:00,  1.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.96873\n",
            "F1: 0.77373\n",
            "Jaccard: 0.63328\n",
            "Recall: 0.84645\n",
            "Precision: 0.71597\n"
          ]
        }
      ],
      "source": [
        "\"\"\" Save the results in this folder \"\"\"\n",
        "# create_dir(\"results\")\n",
        "\n",
        "\"\"\" Load the model \"\"\"\n",
        "# with CustomObjectScope({'iou': iou, 'dice_coef': dice_coef}):\n",
        "model = load_model(\"files/model4.h5\", compile=False)\n",
        "\n",
        "\"\"\" Load the dataset \"\"\"\n",
        "dataset_path = os.path.join(\"new_data\", \"test\")\n",
        "test_x, test_y = load_data(dataset_path)\n",
        "\n",
        "\"\"\" Make the prediction and calculate the metrics values \"\"\"\n",
        "SCORE = []\n",
        "for x, y in tqdm(zip(test_x, test_y), total=len(test_x)):\n",
        "    \"\"\" Extracting name \"\"\"\n",
        "    name = x.split(\"/\")[-1].split(\".\")[0]\n",
        "\n",
        "    \"\"\" Read the image and mask \"\"\"\n",
        "    ori_x, x = read_image(x)\n",
        "    ori_y, y = read_mask(y)\n",
        "\n",
        "    \"\"\" Prediction \"\"\"\n",
        "    y_pred = model.predict(np.expand_dims(x, axis=0))[0]\n",
        "    y_pred = y_pred > 0.5\n",
        "    y_pred = y_pred.astype(np.int32)\n",
        "    y_pred = np.squeeze(y_pred, axis=-1)\n",
        "\n",
        "    \"\"\" Saving the images \"\"\"\n",
        "    save_image_path = f\"results/{name}.png\"\n",
        "    save_results(ori_x, ori_y, y_pred, save_image_path)\n",
        "\n",
        "    \"\"\" Flatten the array \"\"\"\n",
        "    y = y.flatten()\n",
        "    y_pred = y_pred.flatten()\n",
        "\n",
        "    \"\"\" Calculate the metrics \"\"\"\n",
        "    acc_value = accuracy_score(y, y_pred)\n",
        "    f1_value = f1_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "    jac_value = jaccard_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "    recall_value = recall_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "    precision_value = precision_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "    SCORE.append([name, acc_value, f1_value, jac_value, recall_value, precision_value])\n",
        "\n",
        "score4 = [s[1:] for s in SCORE]\n",
        "score4 = np.mean(score4, axis=0)\n",
        "print(f\"Accuracy: {score4[0]:0.5f}\")\n",
        "print(f\"F1: {score4[1]:0.5f}\")\n",
        "print(f\"Jaccard: {score4[2]:0.5f}\")\n",
        "print(f\"Recall: {score4[3]:0.5f}\")\n",
        "print(f\"Precision: {score4[4]:0.5f}\")\n",
        "\n",
        "\"\"\" Saving \"\"\"\n",
        "df = pd.DataFrame(SCORE, columns=[\"Image\", \"Acc\", \"F1\", \"Jaccard\", \"Recall\", \"Precision\"])\n",
        "df.to_csv(\"files/score4.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1EK6knKj77D",
        "outputId": "652f4fcc-b0c0-4b0d-c5ee-08094b98f314"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:07<00:00,  1.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.96827\n",
            "F1: 0.76239\n",
            "Jaccard: 0.61829\n",
            "Recall: 0.81127\n",
            "Precision: 0.72389\n"
          ]
        }
      ],
      "source": [
        "\"\"\" Save the results in this folder \"\"\"\n",
        "# create_dir(\"results\")\n",
        "\n",
        "\"\"\" Load the model \"\"\"\n",
        "# with CustomObjectScope({'iou': iou, 'dice_coef': dice_coef}):\n",
        "model = load_model(\"files/model5.h5\", compile=False)\n",
        "\n",
        "\"\"\" Load the dataset \"\"\"\n",
        "dataset_path = os.path.join(\"new_data\", \"test\")\n",
        "test_x, test_y = load_data(dataset_path)\n",
        "\n",
        "\"\"\" Make the prediction and calculate the metrics values \"\"\"\n",
        "SCORE = []\n",
        "for x, y in tqdm(zip(test_x, test_y), total=len(test_x)):\n",
        "    \"\"\" Extracting name \"\"\"\n",
        "    name = x.split(\"/\")[-1].split(\".\")[0]\n",
        "\n",
        "    \"\"\" Read the image and mask \"\"\"\n",
        "    ori_x, x = read_image(x)\n",
        "    ori_y, y = read_mask(y)\n",
        "\n",
        "    \"\"\" Prediction \"\"\"\n",
        "    y_pred = model.predict(np.expand_dims(x, axis=0))[0]\n",
        "    y_pred = y_pred > 0.5\n",
        "    y_pred = y_pred.astype(np.int32)\n",
        "    y_pred = np.squeeze(y_pred, axis=-1)\n",
        "\n",
        "    \"\"\" Saving the images \"\"\"\n",
        "    save_image_path = f\"results/{name}.png\"\n",
        "    save_results(ori_x, ori_y, y_pred, save_image_path)\n",
        "\n",
        "    \"\"\" Flatten the array \"\"\"\n",
        "    y = y.flatten()\n",
        "    y_pred = y_pred.flatten()\n",
        "\n",
        "    \"\"\" Calculate the metrics \"\"\"\n",
        "    acc_value = accuracy_score(y, y_pred)\n",
        "    f1_value = f1_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "    jac_value = jaccard_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "    recall_value = recall_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "    precision_value = precision_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "    SCORE.append([name, acc_value, f1_value, jac_value, recall_value, precision_value])\n",
        "\n",
        "score5 = [s[1:] for s in SCORE]\n",
        "score5 = np.mean(score5, axis=0)\n",
        "print(f\"Accuracy: {score5[0]:0.5f}\")\n",
        "print(f\"F1: {score5[1]:0.5f}\")\n",
        "print(f\"Jaccard: {score5[2]:0.5f}\")\n",
        "print(f\"Recall: {score5[3]:0.5f}\")\n",
        "print(f\"Precision: {score5[4]:0.5f}\")\n",
        "\n",
        "\"\"\" Saving \"\"\"\n",
        "df = pd.DataFrame(SCORE, columns=[\"Image\", \"Acc\", \"F1\", \"Jaccard\", \"Recall\", \"Precision\"])\n",
        "df.to_csv(\"files/score5.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Save the results in this folder \"\"\"\n",
        "create_dir(\"results75\")\n",
        "\n",
        "\"\"\" Load the model \"\"\"\n",
        "# with CustomObjectScope({'iou': iou, 'dice_coef': dice_coef}):\n",
        "model = load_model(\"files/model4.h5\", compile=False)\n",
        "\n",
        "\"\"\" Load the dataset \"\"\"\n",
        "dataset_path = os.path.join(\"new_data\", \"test\")\n",
        "test_x, test_y = load_data(dataset_path)\n",
        "\n",
        "\"\"\" Make the prediction and calculate the metrics values \"\"\"\n",
        "SCORE = []\n",
        "for x, y in tqdm(zip(test_x, test_y), total=len(test_x)):\n",
        "    \"\"\" Extracting name \"\"\"\n",
        "    name = x.split(\"/\")[-1].split(\".\")[0]\n",
        "\n",
        "    \"\"\" Read the image and mask \"\"\"\n",
        "    ori_x, x = read_image(x)\n",
        "    ori_y, y = read_mask(y)\n",
        "\n",
        "    \"\"\" Prediction \"\"\"\n",
        "    y_pred = model.predict(np.expand_dims(x, axis=0))[0]\n",
        "    y_pred = y_pred > 0.75\n",
        "    y_pred = y_pred.astype(np.int32)\n",
        "    y_pred = np.squeeze(y_pred, axis=-1)\n",
        "\n",
        "    \"\"\" Saving the images \"\"\"\n",
        "    save_image_path = f\"results75/{name}.png\"\n",
        "    save_results(ori_x, ori_y, y_pred, save_image_path)\n",
        "\n",
        "    \"\"\" Flatten the array \"\"\"\n",
        "    y = y.flatten()\n",
        "    y_pred = y_pred.flatten()\n",
        "\n",
        "    \"\"\" Calculate the metrics \"\"\"\n",
        "    acc_value = accuracy_score(y, y_pred)\n",
        "    f1_value = f1_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "    jac_value = jaccard_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "    recall_value = recall_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "    precision_value = precision_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "    SCORE.append([name, acc_value, f1_value, jac_value, recall_value, precision_value])\n",
        "\n",
        "score4 = [s[1:] for s in SCORE]\n",
        "score4 = np.mean(score4, axis=0)\n",
        "print(f\"Accuracy: {score4[0]:0.5f}\")\n",
        "print(f\"F1: {score4[1]:0.5f}\")\n",
        "print(f\"Jaccard: {score4[2]:0.5f}\")\n",
        "print(f\"Recall: {score4[3]:0.5f}\")\n",
        "print(f\"Precision: {score4[4]:0.5f}\")\n",
        "\n",
        "\"\"\" Saving \"\"\"\n",
        "df = pd.DataFrame(SCORE, columns=[\"Image\", \"Acc\", \"F1\", \"Jaccard\", \"Recall\", \"Precision\"])\n",
        "df.to_csv(\"files/score75.csv\")"
      ],
      "metadata": {
        "id": "6ROwghZi7B4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "087e9955-073c-4082-fc05-2d27bd0b2950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:15<00:00,  1.71s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.97163\n",
            "F1: 0.78108\n",
            "Jaccard: 0.64288\n",
            "Recall: 0.80378\n",
            "Precision: 0.76381\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJ6h7aSJX50e",
        "outputId": "d848c523-1308-46b4-cc9b-c70387cc6723"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "z_dim = 64\n",
        "channels = [384, 512, 768, 1024, 1280]\n",
        "final_score = [score1[1], score2[1], score3[1], score4[1], score5[1]]\n",
        "\n",
        "plt.plot(channels, final_score)  \n",
        "plt.xlabel(\"Number of Channels\")\n",
        "plt.ylabel(\"F1-Score\")\n",
        "plt.show()  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "f1v0HjjSEROD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "64_z-dim_Analysis_BV_Segmentation_DiceBCE_HRF.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}