{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIUz94YO5Y0x"
      },
      "source": [
        "### Import the required libraries and modules:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RN5vXWIK27Lr"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import Recall, Precision\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rx3CS_MbV06K",
        "outputId": "0ca2abef-6f7a-4d18-9894-bba7edf4f0e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/Blood_Vessel_Results/ALL_BEST_RESULTS/BV_OD_CHASE\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "%cd /content/gdrive/MyDrive/Blood_Vessel_Results/ALL_BEST_RESULTS/BV_OD_CHASE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQcINXFE59yv"
      },
      "source": [
        "### Unzip the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mA5voGSj58wH"
      },
      "outputs": [],
      "source": [
        "# !unzip new_data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WctlpFt6hx4"
      },
      "source": [
        "### Construct the Model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epeNiZGQ5gSW",
        "outputId": "6d5239f1-89e3-4fb2-9d60-d23097ded952"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"UNET\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 512, 512, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 512, 512, 64  1792        ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 512, 512, 64  256        ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 512, 512, 64  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 512, 512, 64  36928       ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 512, 512, 64  256        ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 512, 512, 64  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 256, 256, 64  0           ['activation_1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 256, 256, 12  73856       ['max_pooling2d[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 256, 256, 12  512        ['conv2d_2[0][0]']               \n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 256, 256, 12  0           ['batch_normalization_2[0][0]']  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 256, 256, 12  147584      ['activation_2[0][0]']           \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 256, 256, 12  512        ['conv2d_3[0][0]']               \n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 256, 256, 12  0           ['batch_normalization_3[0][0]']  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 12  0          ['activation_3[0][0]']           \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 128, 128, 25  295168      ['max_pooling2d_1[0][0]']        \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 128, 128, 25  1024       ['conv2d_4[0][0]']               \n",
            " rmalization)                   6)                                                                \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 128, 128, 25  0           ['batch_normalization_4[0][0]']  \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 128, 128, 25  590080      ['activation_4[0][0]']           \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 128, 128, 25  1024       ['conv2d_5[0][0]']               \n",
            " rmalization)                   6)                                                                \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 128, 128, 25  0           ['batch_normalization_5[0][0]']  \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 256)  0          ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 64, 64, 512)  1180160     ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 64, 64, 512)  2048       ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 64, 64, 512)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 64, 64, 512)  2359808     ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 64, 64, 512)  2048       ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 64, 64, 512)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 512)  0          ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 32, 32, 1024  4719616     ['max_pooling2d_3[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 32, 32, 1024  4096       ['conv2d_8[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 32, 32, 1024  0           ['batch_normalization_8[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 32, 32, 1024  9438208     ['activation_8[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 32, 32, 1024  4096       ['conv2d_9[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 32, 32, 1024  0           ['batch_normalization_9[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTransp  (None, 64, 64, 512)  2097664    ['activation_9[0][0]']           \n",
            " ose)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 64, 64, 1024  0           ['conv2d_transpose[0][0]',       \n",
            "                                )                                 'activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 64, 64, 512)  4719104     ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 64, 64, 512)  2048       ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 64, 64, 512)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 64, 64, 512)  2359808     ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 64, 64, 512)  2048       ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 64, 64, 512)  0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, 128, 128, 25  524544     ['activation_11[0][0]']          \n",
            " spose)                         6)                                                                \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 128, 128, 51  0           ['conv2d_transpose_1[0][0]',     \n",
            "                                2)                                'activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 128, 128, 25  1179904     ['concatenate_1[0][0]']          \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 128, 128, 25  1024       ['conv2d_12[0][0]']              \n",
            " ormalization)                  6)                                                                \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 128, 128, 25  0           ['batch_normalization_12[0][0]'] \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 128, 128, 25  590080      ['activation_12[0][0]']          \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 128, 128, 25  1024       ['conv2d_13[0][0]']              \n",
            " ormalization)                  6)                                                                \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 128, 128, 25  0           ['batch_normalization_13[0][0]'] \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, 256, 256, 12  131200     ['activation_13[0][0]']          \n",
            " spose)                         8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 256, 256, 25  0           ['conv2d_transpose_2[0][0]',     \n",
            "                                6)                                'activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 256, 256, 12  295040      ['concatenate_2[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 256, 256, 12  512        ['conv2d_14[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 256, 256, 12  0           ['batch_normalization_14[0][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 256, 256, 12  147584      ['activation_14[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 256, 256, 12  512        ['conv2d_15[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 256, 256, 12  0           ['batch_normalization_15[0][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2DTran  (None, 512, 512, 64  32832      ['activation_15[0][0]']          \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 512, 512, 12  0           ['conv2d_transpose_3[0][0]',     \n",
            "                                8)                                'activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 512, 512, 64  73792       ['concatenate_3[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 512, 512, 64  256        ['conv2d_16[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 512, 512, 64  0           ['batch_normalization_16[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 512, 512, 64  36928       ['activation_16[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 512, 512, 64  256        ['conv2d_17[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 512, 512, 64  0           ['batch_normalization_17[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 512, 512, 2)  130         ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31,055,362\n",
            "Trainable params: 31,043,586\n",
            "Non-trainable params: 11,776\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def conv_block(inputs, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def encoder_block(inputs, num_filters, strides=2):\n",
        "    x = conv_block(inputs, num_filters)\n",
        "    p = MaxPool2D(strides)(x)\n",
        "    return x, p\n",
        "\n",
        "def decoder_block(inputs, skip_features, num_filters, strides=2):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=strides, padding=\"same\")(inputs)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "def build_unet(input_shape, num_filters=[64, 128, 256, 512, 1024], strides=[2, 2, 2, 2]):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    s1, p1 = encoder_block(inputs, num_filters[0], strides=strides[0])\n",
        "    s2, p2 = encoder_block(p1, num_filters[1], strides=strides[1])\n",
        "    s3, p3 = encoder_block(p2, num_filters[2], strides=strides[2])\n",
        "    s4, p4 = encoder_block(p3, num_filters[3], strides=strides[3])\n",
        "\n",
        "    b1 = conv_block(p4, num_filters[4])\n",
        "\n",
        "    d1 = decoder_block(b1, s4, num_filters[3], strides=strides[3])\n",
        "    d2 = decoder_block(d1, s3, num_filters[2], strides=strides[2])\n",
        "    d3 = decoder_block(d2, s2, num_filters[1], strides=strides[1])\n",
        "    d4 = decoder_block(d3, s1, num_filters[0], strides=strides[0])\n",
        "\n",
        "    outputs = Conv2D(2, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"UNET\")\n",
        "    return model\n",
        "\n",
        "input_shape = (512, 512, 3)\n",
        "model = build_unet(input_shape)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWKUCE3_6vBv"
      },
      "source": [
        "### Adding the Metrics:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5HXET5Z6uZX"
      },
      "outputs": [],
      "source": [
        "def iou(y_true, y_pred):\n",
        "    def f(y_true, y_pred):\n",
        "        intersection = (y_true * y_pred).sum()\n",
        "        union = y_true.sum() + y_pred.sum() - intersection\n",
        "        x = (intersection + 1e-15) / (union + 1e-15)\n",
        "        x = x.astype(np.float32)\n",
        "        return x\n",
        "    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n",
        "\n",
        "smooth = 1e-15\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true = tf.keras.layers.Flatten()(y_true)\n",
        "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coef(y_true, y_pred)\n",
        "\n",
        "def DiceBCELoss(y_true, y_pred):\n",
        "\n",
        "    inputs = tf.keras.layers.Flatten()(y_true)\n",
        "    targets = tf.keras.layers.Flatten()(y_pred)\n",
        "\n",
        "    intersection = tf.reduce_sum(inputs * targets)\n",
        "    dice_loss = 1 - (2.*intersection + smooth)/(tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
        "    BCE = tf.keras.losses.BinaryCrossentropy()\n",
        "    Dice_BCE = BCE(inputs, targets) + dice_loss\n",
        "\n",
        "    return Dice_BCE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuGIkqEH65dX"
      },
      "source": [
        "### Training the Model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNdxwX_-5udw"
      },
      "outputs": [],
      "source": [
        "W = 512\n",
        "H = 512\n",
        "\n",
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "def load_data(path):\n",
        "    x = sorted(glob(os.path.join(path, \"image\", \"*.png\")))\n",
        "    y = sorted(glob(os.path.join(path, \"mask\", \"*.png\")))\n",
        "    return x, y\n",
        "\n",
        "def shuffling(x, y):\n",
        "    x, y = shuffle(x, y, random_state=42)\n",
        "    return x, y\n",
        "\n",
        "def read_image(path):\n",
        "    path = path.decode()\n",
        "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    # x = cv2.resize(x, (W, H))\n",
        "    x = x/255.0\n",
        "    x = x.astype(np.float32)\n",
        "    return x\n",
        "\n",
        "def read_mask(path):\n",
        "    path = path.decode()\n",
        "    x = cv2.imread(path, cv2.IMREAD_COLOR)  ## (512, 512, 3)\n",
        "    # x = cv2.resize(x, (W, H))\n",
        "    x = x/255.0\n",
        "    x = x.astype(np.float32)\n",
        "    x = x[:,:,0:2] # Discard the last channel \n",
        "\n",
        "    return x\n",
        "\n",
        "def tf_parse(x, y):\n",
        "    def _parse(x, y):\n",
        "        x = read_image(x)\n",
        "        y = read_mask(y)\n",
        "        return x, y\n",
        "\n",
        "    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n",
        "    x.set_shape([H, W, 3])\n",
        "    y.set_shape([H, W, 2])\n",
        "    return x, y\n",
        "\n",
        "def tf_dataset(X, Y, batch_size=2):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
        "    dataset = dataset.map(tf_parse)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(4)\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9oxQCQo7Jnw",
        "outputId": "606a7515-097e-4355-f023-a1d6c3979750"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 92 - 92\n",
            "Valid: 5 - 5\n",
            "Epoch 1/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 1.2293 - dice_coef: 0.1602 - iou: 0.0875 - recall: 0.6673 - precision: 0.2720\n",
            "Epoch 1: val_loss improved from inf to 1.56823, saving model to files/model_1024.h5\n",
            "46/46 [==============================] - 96s 2s/step - loss: 1.2293 - dice_coef: 0.1602 - iou: 0.0875 - recall: 0.6673 - precision: 0.2720 - val_loss: 1.5682 - val_dice_coef: 0.0702 - val_iou: 0.0364 - val_recall: 0.0453 - val_precision: 0.0370 - lr: 1.0000e-04\n",
            "Epoch 2/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 1.0129 - dice_coef: 0.2380 - iou: 0.1353 - recall: 0.7314 - precision: 0.5709\n",
            "Epoch 2: val_loss improved from 1.56823 to 1.40201, saving model to files/model_1024.h5\n",
            "46/46 [==============================] - 36s 779ms/step - loss: 1.0129 - dice_coef: 0.2380 - iou: 0.1353 - recall: 0.7314 - precision: 0.5709 - val_loss: 1.4020 - val_dice_coef: 0.0650 - val_iou: 0.0336 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 3/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.9392 - dice_coef: 0.2783 - iou: 0.1618 - recall: 0.7756 - precision: 0.6306\n",
            "Epoch 3: val_loss improved from 1.40201 to 1.31259, saving model to files/model_1024.h5\n",
            "46/46 [==============================] - 36s 786ms/step - loss: 0.9392 - dice_coef: 0.2783 - iou: 0.1618 - recall: 0.7756 - precision: 0.6306 - val_loss: 1.3126 - val_dice_coef: 0.0615 - val_iou: 0.0317 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 4/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.8853 - dice_coef: 0.3087 - iou: 0.1827 - recall: 0.7937 - precision: 0.6726\n",
            "Epoch 4: val_loss did not improve from 1.31259\n",
            "46/46 [==============================] - 33s 717ms/step - loss: 0.8853 - dice_coef: 0.3087 - iou: 0.1827 - recall: 0.7937 - precision: 0.6726 - val_loss: 1.3447 - val_dice_coef: 0.0535 - val_iou: 0.0275 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 5/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.8371 - dice_coef: 0.3366 - iou: 0.2026 - recall: 0.8047 - precision: 0.7053\n",
            "Epoch 5: val_loss improved from 1.31259 to 1.19268, saving model to files/model_1024.h5\n",
            "46/46 [==============================] - 36s 788ms/step - loss: 0.8371 - dice_coef: 0.3366 - iou: 0.2026 - recall: 0.8047 - precision: 0.7053 - val_loss: 1.1927 - val_dice_coef: 0.0599 - val_iou: 0.0309 - val_recall: 2.4979e-05 - val_precision: 0.0015 - lr: 1.0000e-04\n",
            "Epoch 6/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.7911 - dice_coef: 0.3647 - iou: 0.2232 - recall: 0.8128 - precision: 0.7337\n",
            "Epoch 6: val_loss improved from 1.19268 to 1.15630, saving model to files/model_1024.h5\n",
            "46/46 [==============================] - 38s 808ms/step - loss: 0.7911 - dice_coef: 0.3647 - iou: 0.2232 - recall: 0.8128 - precision: 0.7337 - val_loss: 1.1563 - val_dice_coef: 0.0630 - val_iou: 0.0325 - val_recall: 0.0027 - val_precision: 0.0343 - lr: 1.0000e-04\n",
            "Epoch 7/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.7464 - dice_coef: 0.3941 - iou: 0.2456 - recall: 0.8219 - precision: 0.7593\n",
            "Epoch 7: val_loss improved from 1.15630 to 1.13623, saving model to files/model_1024.h5\n",
            "46/46 [==============================] - 36s 786ms/step - loss: 0.7464 - dice_coef: 0.3941 - iou: 0.2456 - recall: 0.8219 - precision: 0.7593 - val_loss: 1.1362 - val_dice_coef: 0.0734 - val_iou: 0.0381 - val_recall: 0.0342 - val_precision: 0.1621 - lr: 1.0000e-04\n",
            "Epoch 8/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.7114 - dice_coef: 0.4185 - iou: 0.2649 - recall: 0.8229 - precision: 0.7716\n",
            "Epoch 8: val_loss improved from 1.13623 to 1.09396, saving model to files/model_1024.h5\n",
            "46/46 [==============================] - 37s 813ms/step - loss: 0.7114 - dice_coef: 0.4185 - iou: 0.2649 - recall: 0.8229 - precision: 0.7716 - val_loss: 1.0940 - val_dice_coef: 0.0992 - val_iou: 0.0522 - val_recall: 0.0927 - val_precision: 0.2829 - lr: 1.0000e-04\n",
            "Epoch 9/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.6711 - dice_coef: 0.4466 - iou: 0.2877 - recall: 0.8276 - precision: 0.7911\n",
            "Epoch 9: val_loss improved from 1.09396 to 1.02873, saving model to files/model_1024.h5\n",
            "46/46 [==============================] - 38s 820ms/step - loss: 0.6711 - dice_coef: 0.4466 - iou: 0.2877 - recall: 0.8276 - precision: 0.7911 - val_loss: 1.0287 - val_dice_coef: 0.1510 - val_iou: 0.0819 - val_recall: 0.2147 - val_precision: 0.4194 - lr: 1.0000e-04\n",
            "Epoch 10/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.6345 - dice_coef: 0.4731 - iou: 0.3101 - recall: 0.8294 - precision: 0.8076\n",
            "Epoch 10: val_loss improved from 1.02873 to 0.93247, saving model to files/model_1024.h5\n",
            "46/46 [==============================] - 37s 797ms/step - loss: 0.6345 - dice_coef: 0.4731 - iou: 0.3101 - recall: 0.8294 - precision: 0.8076 - val_loss: 0.9325 - val_dice_coef: 0.2391 - val_iou: 0.1361 - val_recall: 0.4373 - val_precision: 0.5298 - lr: 1.0000e-04\n",
            "Epoch 11/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.6006 - dice_coef: 0.4983 - iou: 0.3321 - recall: 0.8304 - precision: 0.8212\n",
            "Epoch 11: val_loss improved from 0.93247 to 0.89213, saving model to files/model_1024.h5\n",
            "46/46 [==============================] - 36s 790ms/step - loss: 0.6006 - dice_coef: 0.4983 - iou: 0.3321 - recall: 0.8304 - precision: 0.8212 - val_loss: 0.8921 - val_dice_coef: 0.2634 - val_iou: 0.1519 - val_recall: 0.4397 - val_precision: 0.5544 - lr: 1.0000e-04\n",
            "Epoch 12/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.5702 - dice_coef: 0.5217 - iou: 0.3532 - recall: 0.8289 - precision: 0.8311\n",
            "Epoch 12: val_loss improved from 0.89213 to 0.72757, saving model to files/model_1024.h5\n",
            "46/46 [==============================] - 37s 799ms/step - loss: 0.5702 - dice_coef: 0.5217 - iou: 0.3532 - recall: 0.8289 - precision: 0.8311 - val_loss: 0.7276 - val_dice_coef: 0.3888 - val_iou: 0.2414 - val_recall: 0.6231 - val_precision: 0.7118 - lr: 1.0000e-04\n",
            "Epoch 13/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.5418 - dice_coef: 0.5438 - iou: 0.3738 - recall: 0.8263 - precision: 0.8412\n",
            "Epoch 13: val_loss improved from 0.72757 to 0.65049, saving model to files/model_1024.h5\n",
            "46/46 [==============================] - 37s 794ms/step - loss: 0.5418 - dice_coef: 0.5438 - iou: 0.3738 - recall: 0.8263 - precision: 0.8412 - val_loss: 0.6505 - val_dice_coef: 0.4439 - val_iou: 0.2855 - val_recall: 0.6741 - val_precision: 0.8263 - lr: 1.0000e-04\n",
            "Epoch 14/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.5167 - dice_coef: 0.5642 - iou: 0.3933 - recall: 0.8244 - precision: 0.8457\n",
            "Epoch 14: val_loss did not improve from 0.65049\n",
            "46/46 [==============================] - 33s 718ms/step - loss: 0.5167 - dice_coef: 0.5642 - iou: 0.3933 - recall: 0.8244 - precision: 0.8457 - val_loss: 0.6882 - val_dice_coef: 0.4663 - val_iou: 0.3045 - val_recall: 0.7812 - val_precision: 0.7031 - lr: 1.0000e-04\n",
            "Epoch 15/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.4984 - dice_coef: 0.5802 - iou: 0.4090 - recall: 0.8180 - precision: 0.8475\n",
            "Epoch 15: val_loss improved from 0.65049 to 0.60225, saving model to files/model_1024.h5\n",
            "46/46 [==============================] - 37s 816ms/step - loss: 0.4984 - dice_coef: 0.5802 - iou: 0.4090 - recall: 0.8180 - precision: 0.8475 - val_loss: 0.6022 - val_dice_coef: 0.5116 - val_iou: 0.3452 - val_recall: 0.8166 - val_precision: 0.6991 - lr: 1.0000e-04\n",
            "Epoch 16/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.4692 - dice_coef: 0.6029 - iou: 0.4318 - recall: 0.8193 - precision: 0.8593\n",
            "Epoch 16: val_loss improved from 0.60225 to 0.54019, saving model to files/model_1024.h5\n",
            "46/46 [==============================] - 37s 805ms/step - loss: 0.4692 - dice_coef: 0.6029 - iou: 0.4318 - recall: 0.8193 - precision: 0.8593 - val_loss: 0.5402 - val_dice_coef: 0.5423 - val_iou: 0.3723 - val_recall: 0.7410 - val_precision: 0.8207 - lr: 1.0000e-04\n",
            "Epoch 17/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.4453 - dice_coef: 0.6224 - iou: 0.4521 - recall: 0.8177 - precision: 0.8684\n",
            "Epoch 17: val_loss improved from 0.54019 to 0.53171, saving model to files/model_1024.h5\n",
            "46/46 [==============================] - 37s 785ms/step - loss: 0.4453 - dice_coef: 0.6224 - iou: 0.4521 - recall: 0.8177 - precision: 0.8684 - val_loss: 0.5317 - val_dice_coef: 0.5478 - val_iou: 0.3778 - val_recall: 0.7419 - val_precision: 0.8227 - lr: 1.0000e-04\n",
            "Epoch 18/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.4209 - dice_coef: 0.6424 - iou: 0.4735 - recall: 0.8183 - precision: 0.8787\n",
            "Epoch 18: val_loss did not improve from 0.53171\n",
            "46/46 [==============================] - 33s 718ms/step - loss: 0.4209 - dice_coef: 0.6424 - iou: 0.4735 - recall: 0.8183 - precision: 0.8787 - val_loss: 0.5408 - val_dice_coef: 0.5435 - val_iou: 0.3737 - val_recall: 0.7109 - val_precision: 0.8225 - lr: 1.0000e-04\n",
            "Epoch 19/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.4015 - dice_coef: 0.6589 - iou: 0.4916 - recall: 0.8162 - precision: 0.8831\n",
            "Epoch 19: val_loss improved from 0.53171 to 0.50694, saving model to files/model_1024.h5\n",
            "46/46 [==============================] - 37s 803ms/step - loss: 0.4015 - dice_coef: 0.6589 - iou: 0.4916 - recall: 0.8162 - precision: 0.8831 - val_loss: 0.5069 - val_dice_coef: 0.5724 - val_iou: 0.4012 - val_recall: 0.7229 - val_precision: 0.8240 - lr: 1.0000e-04\n",
            "Epoch 20/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.3838 - dice_coef: 0.6739 - iou: 0.5085 - recall: 0.8134 - precision: 0.8877\n",
            "Epoch 20: val_loss improved from 0.50694 to 0.45950, saving model to files/model_1024.h5\n",
            "46/46 [==============================] - 36s 790ms/step - loss: 0.3838 - dice_coef: 0.6739 - iou: 0.5085 - recall: 0.8134 - precision: 0.8877 - val_loss: 0.4595 - val_dice_coef: 0.6120 - val_iou: 0.4412 - val_recall: 0.7594 - val_precision: 0.8363 - lr: 1.0000e-04\n",
            "Epoch 21/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.3618 - dice_coef: 0.6919 - iou: 0.5293 - recall: 0.8148 - precision: 0.8971\n",
            "Epoch 21: val_loss improved from 0.45950 to 0.45285, saving model to files/model_1024.h5\n",
            "46/46 [==============================] - 39s 842ms/step - loss: 0.3618 - dice_coef: 0.6919 - iou: 0.5293 - recall: 0.8148 - precision: 0.8971 - val_loss: 0.4529 - val_dice_coef: 0.6176 - val_iou: 0.4472 - val_recall: 0.7831 - val_precision: 0.8132 - lr: 1.0000e-04\n",
            "Epoch 22/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.3441 - dice_coef: 0.7070 - iou: 0.5471 - recall: 0.8148 - precision: 0.9037\n",
            "Epoch 22: val_loss did not improve from 0.45285\n",
            "46/46 [==============================] - 33s 718ms/step - loss: 0.3441 - dice_coef: 0.7070 - iou: 0.5471 - recall: 0.8148 - precision: 0.9037 - val_loss: 0.4667 - val_dice_coef: 0.6254 - val_iou: 0.4556 - val_recall: 0.8225 - val_precision: 0.7477 - lr: 1.0000e-04\n",
            "Epoch 23/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.3356 - dice_coef: 0.7153 - iou: 0.5571 - recall: 0.8093 - precision: 0.9022\n",
            "Epoch 23: val_loss did not improve from 0.45285\n",
            "46/46 [==============================] - 33s 718ms/step - loss: 0.3356 - dice_coef: 0.7153 - iou: 0.5571 - recall: 0.8093 - precision: 0.9022 - val_loss: 0.4538 - val_dice_coef: 0.6179 - val_iou: 0.4478 - val_recall: 0.7092 - val_precision: 0.8372 - lr: 1.0000e-04\n",
            "Epoch 24/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.3195 - dice_coef: 0.7289 - iou: 0.5737 - recall: 0.8105 - precision: 0.9078\n",
            "Epoch 24: val_loss improved from 0.45285 to 0.43475, saving model to files/model_1024.h5\n",
            "46/46 [==============================] - 36s 787ms/step - loss: 0.3195 - dice_coef: 0.7289 - iou: 0.5737 - recall: 0.8105 - precision: 0.9078 - val_loss: 0.4348 - val_dice_coef: 0.6355 - val_iou: 0.4662 - val_recall: 0.7297 - val_precision: 0.8266 - lr: 1.0000e-04\n",
            "Epoch 25/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.3087 - dice_coef: 0.7386 - iou: 0.5857 - recall: 0.8080 - precision: 0.9105\n",
            "Epoch 25: val_loss did not improve from 0.43475\n",
            "46/46 [==============================] - 33s 718ms/step - loss: 0.3087 - dice_coef: 0.7386 - iou: 0.5857 - recall: 0.8080 - precision: 0.9105 - val_loss: 0.4474 - val_dice_coef: 0.6273 - val_iou: 0.4575 - val_recall: 0.6971 - val_precision: 0.8241 - lr: 1.0000e-04\n",
            "Epoch 26/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.2933 - dice_coef: 0.7516 - iou: 0.6022 - recall: 0.8096 - precision: 0.9176\n",
            "Epoch 26: val_loss did not improve from 0.43475\n",
            "46/46 [==============================] - 33s 717ms/step - loss: 0.2933 - dice_coef: 0.7516 - iou: 0.6022 - recall: 0.8096 - precision: 0.9176 - val_loss: 0.4436 - val_dice_coef: 0.6304 - val_iou: 0.4608 - val_recall: 0.6845 - val_precision: 0.8399 - lr: 1.0000e-04\n",
            "Epoch 27/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.2768 - dice_coef: 0.7656 - iou: 0.6204 - recall: 0.8131 - precision: 0.9267\n",
            "Epoch 27: val_loss did not improve from 0.43475\n",
            "46/46 [==============================] - 33s 717ms/step - loss: 0.2768 - dice_coef: 0.7656 - iou: 0.6204 - recall: 0.8131 - precision: 0.9267 - val_loss: 0.4384 - val_dice_coef: 0.6336 - val_iou: 0.4643 - val_recall: 0.6501 - val_precision: 0.8575 - lr: 1.0000e-04\n",
            "Epoch 28/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.2648 - dice_coef: 0.7761 - iou: 0.6343 - recall: 0.8133 - precision: 0.9317\n",
            "Epoch 28: val_loss did not improve from 0.43475\n",
            "46/46 [==============================] - 33s 717ms/step - loss: 0.2648 - dice_coef: 0.7761 - iou: 0.6343 - recall: 0.8133 - precision: 0.9317 - val_loss: 0.4419 - val_dice_coef: 0.6343 - val_iou: 0.4649 - val_recall: 0.6569 - val_precision: 0.8429 - lr: 1.0000e-04\n",
            "Epoch 29/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.2545 - dice_coef: 0.7852 - iou: 0.6466 - recall: 0.8125 - precision: 0.9359\n",
            "Epoch 29: val_loss improved from 0.43475 to 0.42081, saving model to files/model_1024.h5\n",
            "46/46 [==============================] - 36s 786ms/step - loss: 0.2545 - dice_coef: 0.7852 - iou: 0.6466 - recall: 0.8125 - precision: 0.9359 - val_loss: 0.4208 - val_dice_coef: 0.6552 - val_iou: 0.4875 - val_recall: 0.6922 - val_precision: 0.8299 - lr: 1.0000e-04\n",
            "Epoch 30/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.2498 - dice_coef: 0.7901 - iou: 0.6532 - recall: 0.8094 - precision: 0.9347\n",
            "Epoch 30: val_loss improved from 0.42081 to 0.39847, saving model to files/model_1024.h5\n",
            "46/46 [==============================] - 37s 800ms/step - loss: 0.2498 - dice_coef: 0.7901 - iou: 0.6532 - recall: 0.8094 - precision: 0.9347 - val_loss: 0.3985 - val_dice_coef: 0.6707 - val_iou: 0.5048 - val_recall: 0.6881 - val_precision: 0.8505 - lr: 1.0000e-04\n",
            "Epoch 31/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.2495 - dice_coef: 0.7912 - iou: 0.6547 - recall: 0.8065 - precision: 0.9290\n",
            "Epoch 31: val_loss improved from 0.39847 to 0.37589, saving model to files/model_1024.h5\n",
            "46/46 [==============================] - 36s 789ms/step - loss: 0.2495 - dice_coef: 0.7912 - iou: 0.6547 - recall: 0.8065 - precision: 0.9290 - val_loss: 0.3759 - val_dice_coef: 0.6914 - val_iou: 0.5286 - val_recall: 0.7203 - val_precision: 0.8483 - lr: 1.0000e-04\n",
            "Epoch 32/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.2414 - dice_coef: 0.7982 - iou: 0.6644 - recall: 0.8063 - precision: 0.9330\n",
            "Epoch 32: val_loss improved from 0.37589 to 0.35662, saving model to files/model_1024.h5\n",
            "46/46 [==============================] - 36s 786ms/step - loss: 0.2414 - dice_coef: 0.7982 - iou: 0.6644 - recall: 0.8063 - precision: 0.9330 - val_loss: 0.3566 - val_dice_coef: 0.7105 - val_iou: 0.5513 - val_recall: 0.7584 - val_precision: 0.8304 - lr: 1.0000e-04\n",
            "Epoch 33/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.2282 - dice_coef: 0.8090 - iou: 0.6795 - recall: 0.8099 - precision: 0.9407\n",
            "Epoch 33: val_loss did not improve from 0.35662\n",
            "46/46 [==============================] - 33s 718ms/step - loss: 0.2282 - dice_coef: 0.8090 - iou: 0.6795 - recall: 0.8099 - precision: 0.9407 - val_loss: 0.3568 - val_dice_coef: 0.7067 - val_iou: 0.5469 - val_recall: 0.7355 - val_precision: 0.8564 - lr: 1.0000e-04\n",
            "Epoch 34/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.2173 - dice_coef: 0.8183 - iou: 0.6926 - recall: 0.8130 - precision: 0.9462\n",
            "Epoch 34: val_loss did not improve from 0.35662\n",
            "46/46 [==============================] - 33s 718ms/step - loss: 0.2173 - dice_coef: 0.8183 - iou: 0.6926 - recall: 0.8130 - precision: 0.9462 - val_loss: 0.3681 - val_dice_coef: 0.6957 - val_iou: 0.5340 - val_recall: 0.6924 - val_precision: 0.8707 - lr: 1.0000e-04\n",
            "Epoch 35/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.2154 - dice_coef: 0.8206 - iou: 0.6959 - recall: 0.8112 - precision: 0.9448\n",
            "Epoch 35: val_loss did not improve from 0.35662\n",
            "46/46 [==============================] - 33s 718ms/step - loss: 0.2154 - dice_coef: 0.8206 - iou: 0.6959 - recall: 0.8112 - precision: 0.9448 - val_loss: 0.3657 - val_dice_coef: 0.6998 - val_iou: 0.5390 - val_recall: 0.7036 - val_precision: 0.8491 - lr: 1.0000e-04\n",
            "Epoch 36/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.2106 - dice_coef: 0.8249 - iou: 0.7021 - recall: 0.8107 - precision: 0.9470\n",
            "Epoch 36: val_loss did not improve from 0.35662\n",
            "46/46 [==============================] - 33s 717ms/step - loss: 0.2106 - dice_coef: 0.8249 - iou: 0.7021 - recall: 0.8107 - precision: 0.9470 - val_loss: 0.3815 - val_dice_coef: 0.6902 - val_iou: 0.5275 - val_recall: 0.6610 - val_precision: 0.8605 - lr: 1.0000e-04\n",
            "Epoch 37/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.2077 - dice_coef: 0.8276 - iou: 0.7061 - recall: 0.8094 - precision: 0.9461\n",
            "Epoch 37: val_loss did not improve from 0.35662\n",
            "\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "46/46 [==============================] - 33s 717ms/step - loss: 0.2077 - dice_coef: 0.8276 - iou: 0.7061 - recall: 0.8094 - precision: 0.9461 - val_loss: 0.3720 - val_dice_coef: 0.6954 - val_iou: 0.5343 - val_recall: 0.6689 - val_precision: 0.8695 - lr: 1.0000e-04\n",
            "Epoch 38/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.1938 - dice_coef: 0.8385 - iou: 0.7221 - recall: 0.8180 - precision: 0.9549\n",
            "Epoch 38: val_loss improved from 0.35662 to 0.33545, saving model to files/model_1024.h5\n",
            "46/46 [==============================] - 38s 817ms/step - loss: 0.1938 - dice_coef: 0.8385 - iou: 0.7221 - recall: 0.8180 - precision: 0.9549 - val_loss: 0.3354 - val_dice_coef: 0.7253 - val_iou: 0.5696 - val_recall: 0.7069 - val_precision: 0.8808 - lr: 1.0000e-05\n",
            "Epoch 39/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.1793 - dice_coef: 0.8493 - iou: 0.7382 - recall: 0.8221 - precision: 0.9675\n",
            "Epoch 39: val_loss did not improve from 0.33545\n",
            "46/46 [==============================] - 34s 732ms/step - loss: 0.1793 - dice_coef: 0.8493 - iou: 0.7382 - recall: 0.8221 - precision: 0.9675 - val_loss: 0.3419 - val_dice_coef: 0.7196 - val_iou: 0.5627 - val_recall: 0.6981 - val_precision: 0.8813 - lr: 1.0000e-05\n",
            "Epoch 40/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.1746 - dice_coef: 0.8531 - iou: 0.7439 - recall: 0.8243 - precision: 0.9709\n",
            "Epoch 40: val_loss did not improve from 0.33545\n",
            "46/46 [==============================] - 33s 718ms/step - loss: 0.1746 - dice_coef: 0.8531 - iou: 0.7439 - recall: 0.8243 - precision: 0.9709 - val_loss: 0.3421 - val_dice_coef: 0.7193 - val_iou: 0.5623 - val_recall: 0.6966 - val_precision: 0.8816 - lr: 1.0000e-05\n",
            "Epoch 41/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.1712 - dice_coef: 0.8559 - iou: 0.7482 - recall: 0.8257 - precision: 0.9734\n",
            "Epoch 41: val_loss did not improve from 0.33545\n",
            "46/46 [==============================] - 33s 718ms/step - loss: 0.1712 - dice_coef: 0.8559 - iou: 0.7482 - recall: 0.8257 - precision: 0.9734 - val_loss: 0.3429 - val_dice_coef: 0.7187 - val_iou: 0.5616 - val_recall: 0.6936 - val_precision: 0.8827 - lr: 1.0000e-05\n",
            "Epoch 42/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.1682 - dice_coef: 0.8583 - iou: 0.7519 - recall: 0.8267 - precision: 0.9754\n",
            "Epoch 42: val_loss did not improve from 0.33545\n",
            "46/46 [==============================] - 33s 718ms/step - loss: 0.1682 - dice_coef: 0.8583 - iou: 0.7519 - recall: 0.8267 - precision: 0.9754 - val_loss: 0.3438 - val_dice_coef: 0.7180 - val_iou: 0.5609 - val_recall: 0.6908 - val_precision: 0.8835 - lr: 1.0000e-05\n",
            "Epoch 43/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.1656 - dice_coef: 0.8605 - iou: 0.7552 - recall: 0.8276 - precision: 0.9773\n",
            "Epoch 43: val_loss did not improve from 0.33545\n",
            "\n",
            "Epoch 43: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "46/46 [==============================] - 33s 717ms/step - loss: 0.1656 - dice_coef: 0.8605 - iou: 0.7552 - recall: 0.8276 - precision: 0.9773 - val_loss: 0.3447 - val_dice_coef: 0.7174 - val_iou: 0.5602 - val_recall: 0.6882 - val_precision: 0.8841 - lr: 1.0000e-05\n",
            "Epoch 44/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.1633 - dice_coef: 0.8622 - iou: 0.7579 - recall: 0.8248 - precision: 0.9799\n",
            "Epoch 44: val_loss did not improve from 0.33545\n",
            "46/46 [==============================] - 33s 718ms/step - loss: 0.1633 - dice_coef: 0.8622 - iou: 0.7579 - recall: 0.8248 - precision: 0.9799 - val_loss: 0.3412 - val_dice_coef: 0.7208 - val_iou: 0.5643 - val_recall: 0.6937 - val_precision: 0.8828 - lr: 1.0000e-06\n",
            "Epoch 45/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.1626 - dice_coef: 0.8628 - iou: 0.7588 - recall: 0.8285 - precision: 0.9794\n",
            "Epoch 45: val_loss did not improve from 0.33545\n",
            "46/46 [==============================] - 33s 717ms/step - loss: 0.1626 - dice_coef: 0.8628 - iou: 0.7588 - recall: 0.8285 - precision: 0.9794 - val_loss: 0.3403 - val_dice_coef: 0.7217 - val_iou: 0.5653 - val_recall: 0.6945 - val_precision: 0.8825 - lr: 1.0000e-06\n",
            "Epoch 46/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.1623 - dice_coef: 0.8631 - iou: 0.7592 - recall: 0.8288 - precision: 0.9796\n",
            "Epoch 46: val_loss did not improve from 0.33545\n",
            "46/46 [==============================] - 33s 718ms/step - loss: 0.1623 - dice_coef: 0.8631 - iou: 0.7592 - recall: 0.8288 - precision: 0.9796 - val_loss: 0.3398 - val_dice_coef: 0.7221 - val_iou: 0.5659 - val_recall: 0.6949 - val_precision: 0.8824 - lr: 1.0000e-06\n",
            "Epoch 47/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.1620 - dice_coef: 0.8633 - iou: 0.7595 - recall: 0.8289 - precision: 0.9798\n",
            "Epoch 47: val_loss did not improve from 0.33545\n",
            "46/46 [==============================] - 33s 718ms/step - loss: 0.1620 - dice_coef: 0.8633 - iou: 0.7595 - recall: 0.8289 - precision: 0.9798 - val_loss: 0.3395 - val_dice_coef: 0.7225 - val_iou: 0.5663 - val_recall: 0.6952 - val_precision: 0.8825 - lr: 1.0000e-06\n",
            "Epoch 48/50\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.1618 - dice_coef: 0.8635 - iou: 0.7598 - recall: 0.8289 - precision: 0.9799\n",
            "Epoch 48: val_loss did not improve from 0.33545\n",
            "46/46 [==============================] - 33s 718ms/step - loss: 0.1618 - dice_coef: 0.8635 - iou: 0.7598 - recall: 0.8289 - precision: 0.9799 - val_loss: 0.3393 - val_dice_coef: 0.7227 - val_iou: 0.5666 - val_recall: 0.6955 - val_precision: 0.8824 - lr: 1.0000e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb3767dfc50>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "\"\"\" Seeding \"\"\"\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "\"\"\" Directory to save files \"\"\"\n",
        "create_dir(\"files\")\n",
        "\n",
        "\"\"\" Hyperparameters \"\"\"\n",
        "batch_size = 2\n",
        "lr = 1e-4\n",
        "num_epochs = 50\n",
        "model_path = os.path.join(\"files\", \"model_1024.h5\")\n",
        "csv_path = os.path.join(\"files\", \"data_1024.csv\")\n",
        "\n",
        "\"\"\" Dataset \"\"\"\n",
        "dataset_path = \"new_data\"\n",
        "train_path = os.path.join(dataset_path, \"train\")\n",
        "valid_path = os.path.join(dataset_path, \"test\")\n",
        "\n",
        "train_x, train_y = load_data(train_path)\n",
        "train_x, train_y = shuffling(train_x, train_y)\n",
        "valid_x, valid_y = load_data(valid_path)\n",
        "\n",
        "print(f\"Train: {len(train_x)} - {len(train_y)}\")\n",
        "print(f\"Valid: {len(valid_x)} - {len(valid_y)}\")\n",
        "\n",
        "train_dataset = tf_dataset(train_x, train_y, batch_size=batch_size)\n",
        "valid_dataset = tf_dataset(valid_x, valid_y, batch_size=batch_size)\n",
        "\n",
        "train_steps = len(train_x)//batch_size\n",
        "valid_setps = len(valid_x)//batch_size\n",
        "\n",
        "if len(train_x) % batch_size != 0:\n",
        "    train_steps += 1\n",
        "if len(valid_x) % batch_size != 0:\n",
        "    valid_setps += 1\n",
        "\n",
        "\"\"\" Model \"\"\"\n",
        "model_1024 = build_unet((H, W, 3), num_filters=[64, 128, 256, 512, 1024], strides=[1, 2, 2, 2])\n",
        "\n",
        "model_1024.compile(loss=DiceBCELoss, optimizer=Adam(lr), metrics=[dice_coef, iou, Recall(), Precision()])\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
        "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5, min_lr=1e-6, verbose=1),\n",
        "    CSVLogger(csv_path),\n",
        "    TensorBoard(),\n",
        "    EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=False)\n",
        "]\n",
        "\n",
        "model_1024.fit(\n",
        "    train_dataset,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=valid_dataset,\n",
        "    steps_per_epoch=train_steps,\n",
        "    validation_steps=valid_setps,\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2frB4UHf9mr3"
      },
      "source": [
        "### Evaluate The Model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5Kjrpfg9pDn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import CustomObjectScope\n",
        "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score, auc\n",
        "# from metrics import dice_loss, dice_coef, iou\n",
        "# from utils import get_filenames_sorted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbgjkGOU-QeQ"
      },
      "outputs": [],
      "source": [
        "H = 512\n",
        "W = 512\n",
        "\n",
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "def read_image(path):\n",
        "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    # x = cv2.resize(x, (W, H))\n",
        "    ori_x = x\n",
        "    x = x/255.0\n",
        "    x = x.astype(np.float32)\n",
        "    return ori_x, x\n",
        "\n",
        "def read_mask(path):\n",
        "    x = cv2.imread(path, cv2.IMREAD_COLOR)  ## (512, 512)\n",
        "    # x = cv2.resize(x, (W, H))\n",
        "    ori_x = x\n",
        "    x = x/255.0\n",
        "    x = x.astype(np.float32)\n",
        "    x = x[:,:,0:2] # Discard the last channel \n",
        "    return ori_x, x\n",
        "\n",
        "def load_data(path):\n",
        "    x = sorted(glob(os.path.join(path, \"image\", \"*.png\")))\n",
        "    y = sorted(glob(os.path.join(path, \"mask\", \"*.png\")))\n",
        "    return x, y\n",
        "\n",
        "def save_results(ori_x, ori_y, y_pred, save_image_path, channel):\n",
        "    line = np.ones((y_pred.shape[0], 10, 3)) * 255\n",
        "\n",
        "    pred_image = np.zeros((y_pred.shape[0], y_pred.shape[1], 3))\n",
        "    _y_pred = y_pred[:, :, channel]\n",
        "    _ori_y = ori_y[:, :, channel]\n",
        "    pred_image[:, :, 0] = ((_y_pred > 0.5) & (_ori_y <= 128)) * 255\n",
        "    pred_image[:, :, 1] = ((_y_pred > 0.5) & (_ori_y  > 128)) * 255\n",
        "    pred_image[:, :, 2] = ((_ori_y  > 128) & (_y_pred <= 0.5 )) * 255\n",
        "\n",
        "    print(\" saving result\", save_image_path)\n",
        "    cv2.imwrite(save_image_path, pred_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jmf9-n3_-EaL",
        "outputId": "ce97f707-1307-4253-bfbe-23d1725bc44f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "files/model_1024.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image_11L\n",
            "255 1.0\n",
            " saving result files_demo_od_0.1_1024/Image_11L.png\n",
            " saving result files_demo_bv_0.1_1024/Image_11L.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 1/5 [00:01<00:04,  1.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image_11R\n",
            "255 1.0\n",
            " saving result files_demo_od_0.1_1024/Image_11R.png\n",
            " saving result files_demo_bv_0.1_1024/Image_11R.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [00:01<00:02,  1.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image_12L\n",
            "255 1.0\n",
            " saving result files_demo_od_0.1_1024/Image_12L.png\n",
            " saving result files_demo_bv_0.1_1024/Image_12L.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [00:02<00:01,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image_12R\n",
            "255 1.0\n",
            " saving result files_demo_od_0.1_1024/Image_12R.png\n",
            " saving result files_demo_bv_0.1_1024/Image_12R.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [00:03<00:00,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image_13L\n",
            "255 1.0\n",
            " saving result files_demo_od_0.1_1024/Image_13L.png\n",
            " saving result files_demo_bv_0.1_1024/Image_13L.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:04<00:00,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "****** OD ******Metrics\n",
            "Threshold: 0.1\n",
            "Accuracy: 0.99473\n",
            "F1: 0.78581 (dice score)\n",
            "Jaccard: 0.65501\n",
            "Recall: 0.67278\n",
            "Precision: 0.97344\n",
            "AUC: 0.67278\n",
            "\n",
            "\n",
            "****** BV ******Metrics\n",
            "Threshold: 0.1\n",
            "Accuracy: 0.97117\n",
            "F1: 0.80451 (dice score)\n",
            "Jaccard: 0.67321\n",
            "Recall: 0.81317\n",
            "Precision: 0.79812\n",
            "AUC: 0.81317\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "data_dir = \"new_data\"\n",
        "od_channel, bv_channel = 0, 1\n",
        "\n",
        "model_dir = \"files\"\n",
        "threshold = 0.1\n",
        "\n",
        "od_result_dir = f\"files_demo_od_{threshold}_1024\"\n",
        "bv_result_dir = f\"files_demo_bv_{threshold}_1024\"\n",
        "\n",
        "create_dir(od_result_dir)\n",
        "create_dir(bv_result_dir)\n",
        "\n",
        "\"\"\" Load the model \"\"\"\n",
        "model_file_name = f\"{model_dir}/model_1024.h5\"\n",
        "print(model_file_name)\n",
        "# with CustomObjectScope({'iou': iou, 'dice_coef': dice_coef, 'dice_coef_OD': dice_coef_OD, 'dice_coef_MA': dice_coef_MA, 'dice_loss': dice_loss}):\n",
        "model = tf.keras.models.load_model(model_file_name, compile = False)\n",
        "\n",
        "\"\"\" Load the dataset \"\"\"\n",
        "# dataset_path = os.path.join(data_dir, \"test\")\n",
        "# test_x, test_y = get_filenames_sorted(data_dir + \"/test/image/\", data_dir + \"/test/mask/\" )\n",
        "\n",
        "dataset_path = os.path.join(\"new_data\", \"test\")\n",
        "test_x, test_y = load_data(dataset_path)\n",
        "\n",
        "\"\"\" Make the prediction and calculate the metrics values \"\"\"\n",
        "SCORE_BV, SCORE_OD = [], []\n",
        "for x, y in tqdm(zip(test_x, test_y), total=len(test_x)):\n",
        "    \"\"\" Extracting name \"\"\"\n",
        "    name = x.rsplit(\"/\", 1)[1].rsplit(\".\", 1)[0]\n",
        "    print(name)\n",
        "\n",
        "    \"\"\" Read the image and mask \"\"\"\n",
        "    ori_x, x = read_image(x)\n",
        "    ori_y, y = read_mask(y)\n",
        "\n",
        "    \"\"\" Prediction \"\"\"\n",
        "    y_pred = model.predict(np.expand_dims(x, axis=0))[0]\n",
        "    y_pred_prob = deepcopy(y_pred)\n",
        "    y_pred = y_pred > threshold\n",
        "    y_pred = y_pred.astype(np.float32)\n",
        "\n",
        "    print(np.max(ori_y), np.max(y))\n",
        "\n",
        "    \"\"\" Saving the images \"\"\"\n",
        "    save_image_path_od = f\"{od_result_dir}/{name}.png\"\n",
        "    save_results(ori_x, ori_y, y_pred, save_image_path_od, od_channel)\n",
        "\n",
        "    save_image_path_bv = f\"{bv_result_dir}/{name}.png\"\n",
        "    save_results(ori_x, ori_y, y_pred, save_image_path_bv, bv_channel)\n",
        "\n",
        "\n",
        "#     \"\"\" Calculate the od metrics \"\"\"\n",
        "    bv_pred = y_pred[:, :, bv_channel].flatten()\n",
        "    bv_pred_prob = y_pred_prob[:, :, bv_channel].flatten()\n",
        "    bv_gt = y[:, :, bv_channel].flatten()\n",
        "    acc_value = accuracy_score(bv_gt > threshold, bv_pred>threshold)\n",
        "    f1_value = f1_score(bv_gt > threshold, bv_pred>threshold, labels=[0, 1], average=\"binary\")\n",
        "    jac_value = jaccard_score(bv_gt > threshold, bv_pred>threshold, labels=[0, 1], average=\"binary\")\n",
        "    recall_value = recall_score(bv_gt > threshold, bv_pred>threshold, labels=[0, 1], average=\"binary\")\n",
        "    recall_computed = np.sum((bv_gt > threshold) & (bv_pred > threshold)) / np.sum(bv_gt > threshold)\n",
        "    precision_value = precision_score(bv_gt > threshold, bv_pred>threshold, labels=[0, 1], average=\"binary\")\n",
        "    auc_score = auc(bv_gt > threshold, bv_pred_prob)\n",
        "    SCORE_BV.append([name, acc_value, f1_value, jac_value, recall_value, precision_value, recall_computed, auc_score])\n",
        "\n",
        "#     \"\"\" Calculate the ma metrics \"\"\"\n",
        "    bv_pred = y_pred[:, :, od_channel].flatten()\n",
        "    bv_pred_prob = y_pred_prob[:, :, bv_channel].flatten()\n",
        "    bv_gt = y[:, :, od_channel].flatten()\n",
        "    acc_value = accuracy_score(bv_gt > threshold, bv_pred>threshold)\n",
        "    f1_value = f1_score(bv_gt > threshold, bv_pred>threshold, labels=[0, 1], average=\"binary\")\n",
        "    jac_value = jaccard_score(bv_gt > threshold, bv_pred>threshold, labels=[0, 1], average=\"binary\")\n",
        "    recall_value = recall_score(bv_gt > threshold, bv_pred>threshold, labels=[0, 1], average=\"binary\")\n",
        "    recall_computed = np.sum((bv_gt > threshold) & (bv_pred > threshold)) / np.sum(bv_gt > threshold)\n",
        "    precision_value = precision_score(bv_gt > threshold, bv_pred>threshold, labels=[0, 1], average=\"binary\")\n",
        "    auc_score = auc(bv_gt > threshold, bv_pred_prob)\n",
        "    SCORE_OD.append([name, acc_value, f1_value, jac_value, recall_value, precision_value, recall_computed, auc_score])\n",
        "    \n",
        "print(\"\\n\")\n",
        "for SCORE in [SCORE_OD, SCORE_BV]:\n",
        "    if SCORE == SCORE_OD:\n",
        "        print(\"****** OD ******Metrics\")\n",
        "    else:\n",
        "        print(\"****** BV ******Metrics\")\n",
        "    score = [s[1:] for s in SCORE]\n",
        "    score = np.mean(score, axis=0)\n",
        "    print(f\"Threshold:\", threshold)\n",
        "    print(f\"Accuracy: {score[0]:0.5f}\")\n",
        "    print(f\"F1: {score[1]:0.5f} (dice score)\")\n",
        "    print(f\"Jaccard: {score[2]:0.5f}\")\n",
        "    print(f\"Recall: {score[3]:0.5f}\")\n",
        "    print(f\"Precision: {score[4]:0.5f}\")\n",
        "    print(f\"AUC: {score[5]:0.5f}\")\n",
        "\n",
        "    # \"\"\" Saving \"\"\"\n",
        "    if SCORE == SCORE_OD:\n",
        "        df = pd.DataFrame(SCORE, columns=[\"Image\", \"Acc\", \"F1\", \"Jaccard\", \"Recall\", \"Precision\", \"Recall Computed\", \"AUC\"])\n",
        "        df.to_csv(f\"{od_result_dir}/score.csv\")\n",
        "    else:\n",
        "        df = pd.DataFrame(SCORE, columns=[\"Image\", \"Acc\", \"F1\", \"Jaccard\", \"Recall\", \"Precision\", \"Recall Computed\", \"AUC\"])\n",
        "        df.to_csv(f\"{bv_result_dir}/score.csv\")\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"files/data_1024.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "R0bW2gXhiAjR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0a6b7b3-82ed-4696-cb69-6454230fa01b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   epoch  dice_coef       iou      loss      lr  precision    recall  \\\n",
              "0      0   0.160202  0.087521  1.229348  0.0001   0.271976  0.667325   \n",
              "1      1   0.237992  0.135282  1.012874  0.0001   0.570896  0.731355   \n",
              "2      2   0.278305  0.161813  0.939199  0.0001   0.630642  0.775578   \n",
              "3      3   0.308674  0.182689  0.885276  0.0001   0.672554  0.793682   \n",
              "4      4   0.336619  0.202578  0.837084  0.0001   0.705305  0.804737   \n",
              "\n",
              "   val_dice_coef   val_iou  val_loss  val_precision  val_recall  \n",
              "0       0.070151  0.036366  1.568234       0.036993    0.045270  \n",
              "1       0.065028  0.033619  1.402012       0.000000    0.000000  \n",
              "2       0.061470  0.031720  1.312585       0.000000    0.000000  \n",
              "3       0.053493  0.027491  1.344668       0.000000    0.000000  \n",
              "4       0.059916  0.030891  1.192678       0.001543    0.000025  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2ece18d1-a896-4a93-995a-0b9fe61b4f8c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>dice_coef</th>\n",
              "      <th>iou</th>\n",
              "      <th>loss</th>\n",
              "      <th>lr</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>val_dice_coef</th>\n",
              "      <th>val_iou</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_precision</th>\n",
              "      <th>val_recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.160202</td>\n",
              "      <td>0.087521</td>\n",
              "      <td>1.229348</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.271976</td>\n",
              "      <td>0.667325</td>\n",
              "      <td>0.070151</td>\n",
              "      <td>0.036366</td>\n",
              "      <td>1.568234</td>\n",
              "      <td>0.036993</td>\n",
              "      <td>0.045270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.237992</td>\n",
              "      <td>0.135282</td>\n",
              "      <td>1.012874</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.570896</td>\n",
              "      <td>0.731355</td>\n",
              "      <td>0.065028</td>\n",
              "      <td>0.033619</td>\n",
              "      <td>1.402012</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.278305</td>\n",
              "      <td>0.161813</td>\n",
              "      <td>0.939199</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.630642</td>\n",
              "      <td>0.775578</td>\n",
              "      <td>0.061470</td>\n",
              "      <td>0.031720</td>\n",
              "      <td>1.312585</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.308674</td>\n",
              "      <td>0.182689</td>\n",
              "      <td>0.885276</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.672554</td>\n",
              "      <td>0.793682</td>\n",
              "      <td>0.053493</td>\n",
              "      <td>0.027491</td>\n",
              "      <td>1.344668</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.336619</td>\n",
              "      <td>0.202578</td>\n",
              "      <td>0.837084</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.705305</td>\n",
              "      <td>0.804737</td>\n",
              "      <td>0.059916</td>\n",
              "      <td>0.030891</td>\n",
              "      <td>1.192678</td>\n",
              "      <td>0.001543</td>\n",
              "      <td>0.000025</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ece18d1-a896-4a93-995a-0b9fe61b4f8c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2ece18d1-a896-4a93-995a-0b9fe61b4f8c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2ece18d1-a896-4a93-995a-0b9fe61b4f8c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(df[\"epoch\"], df[\"dice_coef\"].values)\n",
        "plt.plot(df[\"epoch\"], df[\"val_dice_coef\"].values)\n",
        "plt.legend([\"train\", \"val\"])\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Dice Score\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OS2v320ECSo",
        "outputId": "ffe56a0b-b504-4aaf-df09-70edf8978c4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(df[\"epoch\"], df[\"loss\"].values)\n",
        "plt.plot(df[\"epoch\"], df[\"val_loss\"].values)\n",
        "plt.legend([\"train\", \"val\"])\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3zpUCtvkEGjQ",
        "outputId": "26c40247-a784-4b76-c54e-67d6a3b52de7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Best_OD_BV_CHASE_64.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}