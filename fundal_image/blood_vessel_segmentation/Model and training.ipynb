{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inputs, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def encoder_block(inputs, num_filters):\n",
    "    x = conv_block(inputs, num_filters)\n",
    "    p = MaxPool2D((2, 2))(x)\n",
    "    return x, p\n",
    "\n",
    "def decoder_block(inputs, skip_features, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "def build_unet(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    s1, p1 = encoder_block(inputs, 64)\n",
    "    s2, p2 = encoder_block(p1, 128)\n",
    "    s3, p3 = encoder_block(p2, 256)\n",
    "    s4, p4 = encoder_block(p3, 512)\n",
    "    \n",
    "    b1 = conv_block(p4, 1024)\n",
    "\n",
    "    d1 = decoder_block(b1, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "\n",
    "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"UNET\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"UNET\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 512, 512, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 512, 512, 64) 256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 512, 512, 64) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 512, 512, 64) 36928       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512, 512, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 512, 512, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 256, 256, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 128 73856       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256, 256, 128 512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 256, 256, 128 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 256, 256, 128 147584      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256, 256, 128 512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 256, 256, 128 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 128 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 256 295168      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128, 128, 256 1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 128, 128, 256 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 256 590080      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128, 128, 256 1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128, 128, 256 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 256)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 512)  1180160     max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 512)  2048        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 512)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 512)  2359808     activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 512)  2048        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 512)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 512)  0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 1024) 4719616     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 1024) 4096        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 1024) 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 1024) 9438208     activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 1024) 4096        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 1024) 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 64, 64, 512)  2097664     activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64, 64, 1024) 0           conv2d_transpose[0][0]           \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 512)  4719104     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 64, 64, 512)  2048        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 64, 64, 512)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 512)  2359808     activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64, 64, 512)  2048        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 64, 64, 512)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 128, 128, 256 524544      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 128, 512 0           conv2d_transpose_1[0][0]         \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 128, 128, 256 1179904     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 128, 128, 256 1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 128, 128, 256 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 128, 128, 256 590080      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 128, 128, 256 1024        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 128, 128, 256 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 256, 256, 128 131200      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256, 256, 256 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 256, 256, 128 295040      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 256, 256, 128 512         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 256, 256, 128 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 256, 256, 128 147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 256, 256, 128 512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 256, 256, 128 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 512, 512, 64) 32832       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 512, 512, 128 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 512, 512, 64) 73792       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 512, 512, 64) 256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 512, 512, 64) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 512, 512, 64) 36928       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 512, 512, 64) 256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 512, 512, 64) 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 512, 512, 1)  65          activation_17[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 31,055,297\n",
      "Trainable params: 31,043,521\n",
      "Non-trainable params: 11,776\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (512, 512, 3)\n",
    "model = build_unet(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 512\n",
    "W = 512\n",
    "\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def load_data(path):\n",
    "    x = sorted(glob(os.path.join(path, \"image\", \"*.jpg\")))\n",
    "    y = sorted(glob(os.path.join(path, \"mask\", \"*.jpg\")))\n",
    "    return x, y\n",
    "\n",
    "def shuffling(x, y):\n",
    "    x, y = shuffle(x, y, random_state=42)\n",
    "    return x, y\n",
    "\n",
    "def read_image(path):\n",
    "    path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    # x = cv2.resize(x, (W, H))\n",
    "    x = x/255.0\n",
    "    x = x.astype(np.float32)\n",
    "    return x\n",
    "\n",
    "def read_mask(path):\n",
    "    path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  ## (512, 512)\n",
    "    # x = cv2.resize(x, (W, H))\n",
    "    x = x/255.0\n",
    "    x = x.astype(np.float32)\n",
    "    x = np.expand_dims(x, axis=-1)              ## (512, 512, 1)\n",
    "    return x\n",
    "\n",
    "def tf_parse(x, y):\n",
    "    def _parse(x, y):\n",
    "        x = read_image(x)\n",
    "        y = read_mask(y)\n",
    "        return x, y\n",
    "\n",
    "    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n",
    "    x.set_shape([H, W, 3])\n",
    "    y.set_shape([H, W, 1])\n",
    "    return x, y\n",
    "\n",
    "def tf_dataset(X, Y, batch_size=2):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
    "    dataset = dataset.map(tf_parse)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(4)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(y_true, y_pred):\n",
    "    def f(y_true, y_pred):\n",
    "        intersection = (y_true * y_pred).sum()\n",
    "        union = y_true.sum() + y_pred.sum() - intersection\n",
    "        x = (intersection + 1e-15) / (union + 1e-15)\n",
    "        x = x.astype(np.float32)\n",
    "        return x\n",
    "    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n",
    "\n",
    "smooth = 1e-15\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true = tf.keras.layers.Flatten()(y_true)\n",
    "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1.0 - dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 528 - 528\n",
      "Valid: 22 - 22\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "create_dir(\"files\")\n",
    "\n",
    "batch_size = 2\n",
    "lr = 1e-4\n",
    "num_epochs = 15\n",
    "model_path = os.path.join(\"files\", \"model.h5\")\n",
    "csv_path = os.path.join(\"files\", \"data.csv\")\n",
    "\n",
    "dataset_path = \"new_data\"\n",
    "train_path = os.path.join(dataset_path, \"train\")\n",
    "valid_path = os.path.join(dataset_path, \"test\")\n",
    "\n",
    "train_x, train_y = load_data(train_path)\n",
    "train_x, train_y = shuffling(train_x, train_y)\n",
    "valid_x, valid_y = load_data(valid_path)\n",
    "\n",
    "print(f\"Train: {len(train_x)} - {len(train_y)}\")\n",
    "print(f\"Valid: {len(valid_x)} - {len(valid_y)}\")\n",
    "\n",
    "train_dataset = tf_dataset(train_x, train_y, batch_size=batch_size)\n",
    "valid_dataset = tf_dataset(valid_x, valid_y, batch_size=batch_size)\n",
    "\n",
    "train_steps = len(train_x)//batch_size\n",
    "valid_setps = len(valid_x)//batch_size\n",
    "\n",
    "if len(train_x) % batch_size != 0:\n",
    "    train_steps += 1\n",
    "if len(valid_x) % batch_size != 0:\n",
    "    valid_setps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=Adam(lr), metrics=[dice_coef, iou, Recall(), Precision()])\n",
    "# model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5, min_lr=1e-6, verbose=1),\n",
    "    CSVLogger(csv_path),\n",
    "    TensorBoard(),\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "264/264 [==============================] - 770s 3s/step - loss: 0.2062 - dice_coef: 0.2789 - iou: 0.1672 - recall: 0.7562 - precision: 0.6059 - val_loss: 0.1630 - val_dice_coef: 0.0953 - val_iou: 0.0502 - val_recall: 0.0653 - val_precision: 0.3401\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16303, saving model to files\\model.h5\n",
      "Epoch 2/15\n",
      "264/264 [==============================] - 503s 2s/step - loss: 0.0659 - dice_coef: 0.4866 - iou: 0.3234 - recall: 0.8154 - precision: 0.9285 - val_loss: 0.0795 - val_dice_coef: 0.3645 - val_iou: 0.2265 - val_recall: 0.5283 - val_precision: 0.8682\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.16303 to 0.07949, saving model to files\\model.h5\n",
      "Epoch 3/15\n",
      "264/264 [==============================] - 491s 2s/step - loss: 0.0443 - dice_coef: 0.5938 - iou: 0.4242 - recall: 0.8386 - precision: 0.9510 - val_loss: 0.0652 - val_dice_coef: 0.5251 - val_iou: 0.3610 - val_recall: 0.7945 - val_precision: 0.6629\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.07949 to 0.06522, saving model to files\\model.h5\n",
      "Epoch 4/15\n",
      "264/264 [==============================] - 494s 2s/step - loss: 0.0320 - dice_coef: 0.6750 - iou: 0.5111 - recall: 0.8469 - precision: 0.9640 - val_loss: 0.0450 - val_dice_coef: 0.6069 - val_iou: 0.4406 - val_recall: 0.7655 - val_precision: 0.8466\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.06522 to 0.04504, saving model to files\\model.h5\n",
      "Epoch 5/15\n",
      "264/264 [==============================] - 490s 2s/step - loss: 0.0242 - dice_coef: 0.7385 - iou: 0.5866 - recall: 0.8535 - precision: 0.9724 - val_loss: 0.0407 - val_dice_coef: 0.6527 - val_iou: 0.4909 - val_recall: 0.7744 - val_precision: 0.8430\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.04504 to 0.04071, saving model to files\\model.h5\n",
      "Epoch 6/15\n",
      "264/264 [==============================] - 490s 2s/step - loss: 0.0192 - dice_coef: 0.7844 - iou: 0.6463 - recall: 0.8579 - precision: 0.9768 - val_loss: 0.0366 - val_dice_coef: 0.6853 - val_iou: 0.5283 - val_recall: 0.7593 - val_precision: 0.8601\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.04071 to 0.03655, saving model to files\\model.h5\n",
      "Epoch 7/15\n",
      "264/264 [==============================] - 493s 2s/step - loss: 0.0162 - dice_coef: 0.8170 - iou: 0.6915 - recall: 0.8580 - precision: 0.9778 - val_loss: 0.0333 - val_dice_coef: 0.7233 - val_iou: 0.5737 - val_recall: 0.7599 - val_precision: 0.8898\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.03655 to 0.03326, saving model to files\\model.h5\n",
      "Epoch 8/15\n",
      "264/264 [==============================] - 492s 2s/step - loss: 0.0137 - dice_coef: 0.8442 - iou: 0.7311 - recall: 0.8599 - precision: 0.9805 - val_loss: 0.0364 - val_dice_coef: 0.7365 - val_iou: 0.5924 - val_recall: 0.7664 - val_precision: 0.8179\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.03326\n",
      "Epoch 9/15\n",
      "264/264 [==============================] - 496s 2s/step - loss: 0.0116 - dice_coef: 0.8672 - iou: 0.7660 - recall: 0.8605 - precision: 0.9840 - val_loss: 0.0364 - val_dice_coef: 0.6761 - val_iou: 0.5203 - val_recall: 0.6884 - val_precision: 0.8943\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.03326\n",
      "Epoch 10/15\n",
      "264/264 [==============================] - 491s 2s/step - loss: 0.0192 - dice_coef: 0.8207 - iou: 0.7001 - recall: 0.8254 - precision: 0.9479 - val_loss: 0.0690 - val_dice_coef: 0.6351 - val_iou: 0.4899 - val_recall: 0.8407 - val_precision: 0.5138\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.03326\n",
      "Epoch 11/15\n",
      "264/264 [==============================] - 494s 2s/step - loss: 0.0108 - dice_coef: 0.8829 - iou: 0.7910 - recall: 0.8577 - precision: 0.9791 - val_loss: 0.0322 - val_dice_coef: 0.7559 - val_iou: 0.6178 - val_recall: 0.6867 - val_precision: 0.9202\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.03326 to 0.03215, saving model to files\\model.h5\n",
      "Epoch 12/15\n",
      "264/264 [==============================] - 495s 2s/step - loss: 0.0089 - dice_coef: 0.9032 - iou: 0.8238 - recall: 0.8609 - precision: 0.9849 - val_loss: 0.0309 - val_dice_coef: 0.7677 - val_iou: 0.6351 - val_recall: 0.7465 - val_precision: 0.8559\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.03215 to 0.03086, saving model to files\\model.h5\n",
      "Epoch 13/15\n",
      "264/264 [==============================] - 497s 2s/step - loss: 0.0079 - dice_coef: 0.9139 - iou: 0.8418 - recall: 0.8625 - precision: 0.9866 - val_loss: 0.0300 - val_dice_coef: 0.8024 - val_iou: 0.6815 - val_recall: 0.7133 - val_precision: 0.9353\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.03086 to 0.02998, saving model to files\\model.h5\n",
      "Epoch 14/15\n",
      "264/264 [==============================] - 486s 2s/step - loss: 0.0072 - dice_coef: 0.9218 - iou: 0.8552 - recall: 0.8631 - precision: 0.9876 - val_loss: 0.0287 - val_dice_coef: 0.8023 - val_iou: 0.6805 - val_recall: 0.7418 - val_precision: 0.8880\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.02998 to 0.02871, saving model to files\\model.h5\n",
      "Epoch 15/15\n",
      "264/264 [==============================] - 494s 2s/step - loss: 0.0069 - dice_coef: 0.9266 - iou: 0.8635 - recall: 0.8625 - precision: 0.9875 - val_loss: 0.0312 - val_dice_coef: 0.7984 - val_iou: 0.6778 - val_recall: 0.7607 - val_precision: 0.8491\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.02871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x227057a3888>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_dataset,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=valid_dataset,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_steps=valid_setps,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
